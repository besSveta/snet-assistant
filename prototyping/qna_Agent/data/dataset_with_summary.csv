Unnamed: 0,path,chuck_text,summary
0,docs/concepts,"[['Ethereum Ethereum is an open source, public, blockchain-based distributed computing platform and operating system featuring smart contract (scripting) functionality. It supports a modified version of Nakamoto consensus via transaction-based state transitions. Ether is the cryptocurrency generated by the Ethereum platform as a reward to mining nodes for computations performed and is the only currency accepted in the payment of transaction fees. Ethereum provides a decentralized virtual machine, the Ethereum Virtual Machine (EVM), which can execute scripts using an international network of public nodes. The virtual machine\'s instruction set, in contrast to others like Bitcoin Script, is Turing-complete. ""Gas"", an internal transaction pricing mechanism, is used to mitigate spam and allocate resources on the network. Read more here and here Blockchain Agnosticism Ethereum is used to host two critical smart contracts: the Registry and the Multi-Party Escrow. While the SingularityNET platform currently depends on the Ethereum blockchain.', 'It may be useful or even necessary to support other existing blockchain technologies in order to broaden adoption, improve scalability, or achieve other goals. The platform architecture is designed with this possibility in mind, and it attempts to concentrate all interactions with the Registry and the MPE contract in small code components. A decision on which other blockchains to support, and when, has not yet been made, but encapsulating the code in libraries will ensure that as the platform evolves, the possibility of supporting other blockchains is preserved and the amount of work required will be manageable.', 'You can read more in our whitepaper'], ['Smart Contracts A Smart Contract is terms, rules and conditions of the agreement established by all counter parties translated as code into Blockchain. The code and logic in the contract is available on the ledger\u200b. On our current context, a “smart contract” is simply a piece of code that is running on Ethereum. It’s called a “contract” because code that runs on Ethereum can control valuable things like ETH or other digital assets. Ethereum is used to host two critical smart contracts: the Registry and the Multi-Party Escrow.  The SingularityNET Registry is an ERC-165–compliant smart contract on the Ethereum blockchain that stores organizations, services, and type repositories. The Multi-Party Escrow smart contract (“MPE”), coupled with our atomic unidirectional payment channels, enables scalable payments in the platform by minimizing the number of on-blockchain transactions needed between clients and AI service owners.'], ['Overview gRPC is a modern open source high performance RPC framework that can run in any environment. It can efficiently connect services in and across data centers with pluggable support for load balancing, tracing, health checking and authentication. It is also applicable in last mile of distributed computing to connect devices, mobile applications and browsers to backend services. By default, gRPC uses protocol buffers as the Interface Definition Language (IDL) for describing both the service interface and the structure of the payload messages. gRPC Docs is the recommended starting point to understand how this works. gRPC and SingularityNet Platform AI Services on the Singularitynet platform need to define their API using protocol buffers and expose a gRPC endpoint. This allows SingularityNET clients to determine the request/response schema programmatically. The first step in getting the AI service ready for the SingularityNet platform is to have a proto definition and expose a gRPC endpoint for it.', 'Once this is done, the service can be integrated with the SingulartiyNet Daemon. Samples  The example service is an example of a Python arthimetic service with gRPC endpoints and a proto definition. These guides are a good starting point to creating gRPC based services'], ['etcd Overview etcd is a distributed reliable key-value store having the following properties:  Simple: well-defined, user-facing API (gRPC) Secure: automatic TLS with optional client cert authentication Fast: benchmarked 10,000 writes/sec Reliable: properly distributed using Raft  etcd is written in Go and uses the Raft consensus algorithm to manage a highly-available replicated log. etcd and SingularityNet Platform etcd is used as storage to store context related to  * Payments * Free Call Usage at an organization level.', 'The section ETCD setup section details how to set up an etcd cluster'], ['Protocol Buffers also know as Protobuf, is a method of data serialization. It provides a simple and efficient way of describing data that is to be stored or exchanged between systems. Its similar to XML and JSON but is much smaller in size thereby improving performance of network communication. The method involves an interface description language that describes the structure of some data and a program that generates source code from that description for generating or parsing a stream of bytes that represents the structured data. Google developed Protocol Buffers and provided a code generator for multiple languages under an open source license. Data structures (called messages) and services are described in a proto definition file (.proto) and compiled with protoc. This compilation generates code that can be invoked by a sender or recipient of these data structures. For example, example.pb.cc and example.pb.h are generated from example.proto. They define C++ classes for each message and service in example.proto.', 'Canonically, messages are serialized into a binary wire format which is compact, forward- and backward-compatible, but not self-describing (that is, there is no way to tell the names, meaning, or full datatypes of fields without an external specification). There is no defined way to include or refer to such an external specification (schema) within a Protocol Buffers file. The officially supported implementation includes an ASCII serialization format,[6] but this format—though self-describing—loses the forward- and backward-compatibility behavior, and is thus not a good choice for applications other than debugging. Protocol buffers are a language-neutral, platform-neutral extensible mechanism for serializing structured data.'], ['What is blockchain Blockchain is a public, open distributed ledger that can record transactions between two parties efficiently and in a verifiable and permanent way Imagine this ledger as a growing list of records called ‘blocks’ linked using a cryptographic hash of the previous block, a timestamp, and transaction data (generally represented as a Merkle tree). The public and decentralized ledger design of Blockchain enables a unified source of data with an audit trail and consistency across the transacting parties without the need of any intermediaries. Core components  How it works  Blockchain and the SingularityNet platform One of the major applications of Blockchain is as a cryptocurrency. Cryptocurrency is a digital asset designed to work as a medium of exchange wherein individual coin ownership records are stored in a digital ledger or using strong cryptography to secure transaction record entries, to control the creation of additional digital coin records, and to verify the transfer of coin ownership.', 'The AGIX token is one such crypto currency that powers all transactions on the SingularityNet platform. The SingularityNET platform brings blockchain and AI together to create a new AI fabric that delivers superior practical AI functionality today while moving toward the fulfillment of Singularitarian artificial general intelligence visions. Blockchain allows us to program economic rules in a digital environment and AI software to seamlessly interact with them. Cryptocurrency is a powerful tool for managing transactions in an economy dominated by machine intelligence. SingularityNET is a blockchain-based framework designed to serve the needs of AI agents as they interact with each other and with external customers. At its core, SingularityNET is a set of smart contract templates that AI agents can use to request that AI work be done, to exchange data, and to supply the results of AI work.'], ['Page settings layout: default keywords: ipfs comments: false  The Interplanetary File System (IPFS) is a synthesis of several new and existing innovations. IPFS is an open-source project. The Interplanetary File System (IPFS) is a peer-to-peer network and a network protocol used to store and share data in a distributed file system. IPFS uses content-addressing to identify each file in a global namespace connecting all computing devices. Organization details and service details are in IPFS and the associated hash is in a Blockchain. The components of Inter-Planetary File system are:  Distributed Hash Tables Block Exchanges Merkle DAG Version Control Systems Self-certifying File System  For details on these components, see IPFS Documentation.'], ['SingularityNET (SNET) is an open and decentralized network of AI services made accessible through the Blockchain. Developers publish their services to the SingularityNET network, where they can be used by anyone with an internet connection. Developers are able to charge for the use of their services using the native AGIX token. Services can span the entire gamut of offerings in artificial intelligence and machine learning. Services can provide inference or model training across myriad domains such as image/video, speech, text, time-series, bio-AI, network analysis, etc. The services can be as simple as wrapping a well-known algorithm such as A* path planning, a complete end-to-end solution for an industry problem, or a standalone AI application. Developers can also deploy autonomous AI agents that interoperate with other services on the network. The SingularityNET platform contains a number of critical components that work together to enable a decentralized network of AI services to flourish.', 'The core components are designed to allow for a functional, scalable, and extensible system. We arrived at the current architecture through a careful process, guided by a few key decisions governing Blockchain interactions, AI service integration, and abstraction and by the goal of building an AI marketplace that is both open and compliant with regulatory and legal requirements. First, we made the conscious choice to minimize our dependence on our current Blockchain, Ethereum. Both conceptual and practical issues motivated this decision. Conceptually, we desire to be Blockchain-agnostic and, if necessary, will consider building our own consensus algorithm based on reputation. The speed, reliability, and costs of Ethereum Blockchain interactions dictate that any scalable system built on top of it must minimize gas costs and the delays introduced by block-mining time.', ""These decisions are reflected in our use of tools to abstract away all Blockchain interactions (the daemon, CLI, and SDK) and in our use of a multi-party escrow contract and atomic unidirectional channels for payments. Second, on AI services integration, we wanted to abstract away as much of the network as possible, in order to reduce the learning curve and minimize the overhead associated with providing AI services via the network. This abstraction is achieved with a single flexible tool, the daemon, that will help us provide scalability, robustness, distribution, and management features to the entire community. Finally, to make our marketplace compliant with regulations without compromising on openness, we implemented it separately from our fully decentralized registry of AI services currently available on the Blockchain. Concepts and Components Here we've broken down the SingularityNET platform and network into its core components. The diagram below depicts the key components along with auxiliary components and their roles."", ""You can jump directly to the thing you'd like to know more about, or use the navigation on each page to read through them in turn.""], ['ERC-20 is a standard interface for tokens. It allows any tokens on Ethereum to be re-used by other applications: from wallets to decentralized exchanges. The ERC-20 standard is documented here It defines a standard interface that all tokens should adhere to. This enables users and developers to understand how the token will work in the Ethereum ecosystem. This standardization enables richer interaction between the various tools and usecases built on top of Ethereum The AGIX Token is an ERC-20 token that powers the SingularityNet platform. Note: While we are aware that the AGIX token is currently being traded on some exchanges, we do not encourage or facilitate this exchange trading in any manner. Speculative secondary trading is against the spirit of the AGIX token and SingularityNET project. We strongly discourage speculative secondary trading and officially ask AGIX token holders to act accordingly.'], ['Ethereum Address An Ethereum address is a 64 character hex string generated subject to various rules defined in the Ethereum yellow paper. It represents a unique account on the Ethereum network and has an associated private key. This private key is requried to prove ownership of the address and has to be kept safe. Ethereum address as an account It is possible to create an ethereum address programatically. Once created this account can be used to send and receive ETH as well as ERC 20 tokens.  The address is composed of the prefix ""0x"", a common identifier for hexadecimal, concatenated with the rightmost 20 bytes of the Keccak-256 hash (big endian) of the ECDSA public key (the curve used is the so-called secp256k1, the same as Bitcoin). In hexadecimal, 2 digits represent a byte, meaning addresses contain 40 hexadecimal digits.', 'An example of an Ethereum address is 0xb794f5ea0ba39494ce839613fffba74279579268. Contract addresses are in the same format, however, they are determined by sender and creation transaction nonce.[36] User accounts are indistinguishable from contract accounts given only an address for each and no blockchain data. The ethereum account is also referred to as a wallet. Common applications to manage the wallet are * Metamask - It is a crypto wallet - available as a browser extension - that can create and manage Ethereum accounts. Metamask is the primary way to interact with DApps on the SingualrityNet platform * Hardware wallet - It is a crypto wallet in the form of specialized hardware to safely store the private key associated with the address.  Ethereum address as a contract The smart contracts deployed on the Ethereum blockchain are also identified by an address.', ""There is no private key associated with this address, rather its based on the code of the smart contract itself. The contact's address is deterministically computed from the address of its creator (sender) and how many transactions the creator has sent (nonce). The sender and nonce are RLP encoded and then hashed with Keccak-256. This address is used to interact with the contract.""]]","The given text provides information about Ethereum, smart contracts, gRPC, etcd, Protocol Buffers, blockchain, IPFS, SingularityNET, ERC-20 tokens, and Ethereum addresses. It explains the functionalities and uses of these technologies and how they are related to the SingularityNET platform."
1,docs/howto,"[['Metamask is a plugin which is used by the SingularityNET platform. How to get metamask To get the metamask plugin install Wallets in Metamask Once you have installed and set up your metamask, Click on the icon on the top right of your metamask window.  you could pick any of the options below   Create a wallet  Import an existing wallet  Connect to a hardware wallet'], ['Ethereum Account How to create an ethereum wallet Just follow the steps myetherwallet to create a new wallet or access an existing wallet Using snet-cli The CLI follows the same guidelines as provided by Ethereum for storing the private keys. When user identities are created and registered with a client, the CLI safely stores the details on the local machine and retrieves them only when it needs to interact with the Blockchain. You will need to install snet-cli as a first step You could use the command line options provided to', 'create an identity']]","The text provides information on how to get and use the Metamask plugin, create an Ethereum wallet, and use the snet-cli tool."
2,docs/platform-dev,"[[], ['The SingularityNET Registry is an ERC-165–compliant smart contract on the Ethereum Blockchain that stores organizations, services, and type repositories. AI developers use the Registry to announce details of their services, and consumers use the Registry to find the services they need. When a user searches for a service in the Marketplace DApp, it reads details of the services from the Registry, which also allows tagging of services and type repositories to enable searching and filtering. The Registry provides all the information needed to find and interact with AI services on the platform, either by listing the information in full or, when it is too long, by listing the IPFS hash. The source, ABI, and deployment information for the Registry is located in the singnet/platform-contracts repo. Interface The Registry interface, IRegistry, is a full specification of the functionality of the Registry. The Registry is published alongside its interface located in IRegistry.sol.', 'The interface contains natspec-compliant documentation on all functions and developers should import and target the interface instead of the implementation. The registry implements the interface and also fully supports ERC-165. Data Model The Registry stores four main pieces of data: Organizations, Services, Type Repositories, and Tags. It supports CRUD on all of these and contains a number of view functions for retrieving data. Organization An organization is an umbrella for services to be grouped under and is at the top of the Registry’s data hierarchy. Service developers can (and should) register an organization and then put all of their services underneath it. An organization registration record has a name, an owner address (in the identity sense), a collection of member addresses, a collection of services. Its Registry entry contains a name,members, and IPFS hash.', 'the IPFS hash is the link to the metadata file on IPFS , this file has all the necessary information about the recipient address for payment and the storage details to keep track of all off-chain channel state. Services and type repositories registered under a given organization are said to be owned by that organization. The list of members is a primitive access-management structure. Members of an organization cannot change the organization owner or delete the organization or even update the metadata, members can however create , update and delete services under an organization. Organization metadata is described in detail here. Service A service represents a single AI algorithm. Its Registry entry contains all the necessary information for a consumer to call that AI service. The entry contains a name, tags, and IPFS hash. The name is an identifier for discoverability, the tags help a customer find a service without knowing its name, and the IPFS hash is the link to the metadata file on IPFS.', 'DApps and smart contracts can use the listServicesForTag view function to discover Services. Contract Addresses Click here Service Metadata All service metadata is stored off-chain in IPFS for performance and gas-cost reasons. This metadata includes * basic information such as version number, service name, description, etc.; * code-level information for calling the service, such as encoding (protobuf or JSON) and request format (gRPC, JSON-RPC or process); * A list of daemon endpoints, aggregated into one or more groups; * pricing information; and * an IPFS hash for the service API model. * Service metata is described in detail here. Type Repository A type repository is a Registry entry where a service developer lists service metadata, such as the service model and the data types used. The entry contains a name, some tags, a path, and a URI.', 'The name and tags are for discoverability, the path is an optional identifier for the organization’s internal management, and the URI allows the client (whether an end user or an application making calls through the SingularityNET SDK) to find the metadata. DApps and smart contracts can use the listTypeRepositoriesForTag view function to discover AI services. The URI is an IPFS hash, and the hosting itself can be done by either SingularityNET, the service developer, or any IPFS pinning service, such as Infura. Tags Tags are completely optional but recommended for discoverability. Services and Type Repositories can be associated with tags by using the relevant Registry methods such as addTagToServiceRegistration. After that, the tags are displayed and searchable on the DApp. Thanks to a reverse index built into the Registry contract, other smart contracts can also search the Registry directly. This is the foundation for the “API of APIs” functionality discussed below.', 'DApp Integration The SingularityNET DApp is essentially a rich Registry explorer. It loads the Registry and generates UI for playing with the Services and Type Repositories registered in it. CLI Integration The SingularityNET CLI has all the tooling necessary to call any of the Registry methods. Please see theCLI documentation'], ['SDK in JAVA SDK in Python SDK in NodeJS  All SDKs provided adhere to the same design standard and strategy Note:  According  to the design pattern for the  SDK modules such as functionality, need to be available in all programming languages, such as Java, Python and NodeJS.  The SDK can include several default funding strategies for payment channels, but allows and supports the developer to implement funding strategies for payment channel of their own, to control over tokens and service payments. The SDK, in combination with the CLI, simplifies the process of fetching the latest service specification for dependent services, and compiles the proto definitions, so that the services can be invoked with minimal fuss. Currently, a fully functional a preliminary version of a Python SDK is available, which forms the basis for the SDK tutorial, but has  some design improvements.', ""Work is in process towards an SDK for Javascript, and intend to support other popular languages and welcome third party contributions for people's favourite languages. As these SDKs become stable the SDK tutorial will be periodically updated to to include details supporting each programming language.""], ['State Service Calls As the name suggests, this call will be used by the client to determine the next amount to sign to make a service call.  Daemon keeps track of the off chain state of the channel Details involve Channel Id Nonce,Amount signed , Signature and the nonce of the channel  , and in order to sign the amount for the next call, the client needs to know the amount it had last signed (X), the new call will be signed with an amount X + P , where X is the last signed amount and P is the price  Daemon also sends back the last signed signature of the old nonce ( in case a claim is in progress or a claim was made)  Pay Per use calls The client signs in for the next cumulative amount ( i.e X+P), where X is the amount last amount signed on the given Channel Id and Nonce  Free Calls How many free Calls are Left ?', 'As a service provider one may wish to provide free calls . However you need some validations to ensure , that only authorized users can make this call and as a service provider you would want to  restrict the number of such free calls made. To even check if free calls are allowed, you need to send in Daemon a signature and a token   Making an Actual Free Call If the Signatures are valid,Daemon increments the usage count by 1. The Signature validations and authentication is exactly the same as  explained , just that the ETCD State is upated with usage accordingly Control Service Calls Please note, Daemon doesnt do any claims on blockchain, it is responsible  ONLY for maintaining the states. Actual claims can done using snet-cli/publisher portal Daemon provides a bunch of grpc calls to retrieve data the service provider needs to make claims on block chain. Keeps track of claims in Progress. One can view all the data using cli commands in snet-daemon', 'No write operation on block chains are done by Daemon (will be take care of by the snet client ), Finish on the claim(reset channel amount used to zero!) should be called only after the payment is successfully claimed and block chain is updated accordingly. One way to determine this is by checking the nonce in the block chain with the nonce in the payment,for a given channel if the block chain nonce is greater than that of the nonce from etcd storage => that the claim is already done in block chain. and the Finish method is called on the claim. List-unclaimed requests As a first step the service provider needs to be aware of all the  unclaimed money Service Provider needs to send the following message (using snet-cli/publisher portal): mpe_address, current_block_number, signature(“__list_unclaimed”, mpe_address, current_block_number)  After receiving this message, daemon does the following: Verify that mpe_address is correct', 'Verify that actual block_number is not very different (+-5 blocks) from the current_block_number from the signature Verify that message was signed by the service provider (“payment_address” in metadata). Send list of unclaimed payments without signatures (we don’t send signatures here just to be safe!!!) Start-claim request/requests using snet-cli the following message: mpe_address, channel_id, signature(“__start_claim”, mpe_address, channel_id, channel_nonce) After receiving this message, daemon does the following: Check that current channel nonce in blockchain is equal to nonce of the channel in etcd. It means that all previous payments on this channel was claimed already. Daemon should remove all payments with nonce < channel_nonce from payment storage. Verify that signature is authentic ( “payment_address” is in metadata !) Increase nonce in storage and send last payment with old nonce to the caller (snet-cli/publisher portal) List-in-progress', 'Get the list of all claims that have been initiated but not completed yet Before sending a list of payments, daemon should remove all payments with nonce < blockchain nonce from payment storage (call finalize on them?). It means that daemon removes all payments which were claimed already.   Concurrent calls Signature Details For exact details on signatures please refer to snet-daemon'], ['To fulfill a request from a client to a service, a snet-daemon needs to store and process information about the service payment. This connection is called the payment channel. If there is only one service and corresponding snet-daemon the process is easy:  When payment passes a validation process, the payment channel is stored in an internal storage to be claimed when the service successfully accomplishes the request. The situation becomes more complicated if a service provides several replicas. In this case it is not possible to have several separated snet-daemons each of which has an independent internal storage.  One drawback of using a separated payment channel for each replica, is that it can be expensive from the gas consumption and time execution point of view, because each operation to open a channel requires it to be processed by the Blockchain. The other one is that such model is subject to an attack where the same payment can be used for services from different replicas.', 'This leads to a model where all snet-daemons for the same service should use the shared storage.  However, if only one instance of a storage is provided it can easily become a single point of failure for the whole system. When it fails, this leads to failure of all payments even when there are live replicas. Therefore, we are using distributed storage. There is plenty of available storage, and we just need to make the optimal choice. We are adhering to several criteria: According to CAP theorem, we only have a choice to select two out of three main guarantees: * Partition tolerance * Availability * Consistency We need a partition tolerance distributed storage to save system from network failures. Furthermore, we also need storage that provides strong consistency guarantees to avoid a situation where the same payment is used twice on different replicas. This does not mean that the availability guarantee is not important.', ""This means that if all but a few nodes of the distributed storage are still available, it will not be possible to read/write requests. This is a price we are paying in exchange for a strong consistency storage system. Lets strike out the availability guarantee and leave only partition tolerance and consistency:  Partition tolerance ~~Availability~~ Consistency  The new design now looks like this:  The current approach is fine, but it requires for a service owner not only to setup a snet-daemon for each replica, but also to deploy a separated distributed storage. This can be a rather tedious and complicated task. To avoid this, it would be good to incorporate the distributed storage nodes into snet-daemons so it would be the snet-daemon's task to run required distributed storage nodes:  Considered storages We are looking for a distributed storage with strong consistency guarantees which can be run by snet-daemon (e.g. be easily integrated into a Go program)."", 'Some of the storages that were considered are: | Distributed Storage                            |Language| Consensus|Embedded Server Support |------------------------------------------------|--------|----------|-------------------------------------------- |Etcd         | Go     | Raft     |native |Consul   | Go     | Raft     |ticket 467 |ZooKeeper| Java   | ZAB      |native Etcd was chosen because it is written in Go, and has out of the box embedded server support. This means that its nodes can be started and stopped by snet-daemon replicas. It is not clear whether it is possible to run a consul server agent from a Go application. A few examples (embedded-consul 1 2 just bundles the Consul as a binary package. Zookeeper is just written in Java and it requires to have an additional support to start Zookeeper nodes from Go. Note: all these storages use a quorum to get a consensus during leader election and values writings.', 'This means that if the number of failed nodes are more than half of all nodes, then the the cluster stops working. As it was described before, this is a cost for a distributed system to provide strong consistency guarantees. Etcd storage Running and accessing embedded etcd cluster Starting an etcd node requires at least the following parameters:  name: human-readable name for the node. listen-client-urls: list of URLs to listen on for client traffic listen-peer-urls: list of URLs to listen on for peer traffic initial-cluster: initial cluster configuration for bootstrapping, for example:   name1=http://AAA.BBB.1.1:2380,name2=http://AAA.BBB.1.2:2380 initial-cluster-token: initial cluster token for the etcd cluster during bootstrap  The following Go code is used to start etcd node and use etcd client: * etcd_storage_server.go * etcd_storage_client.go', 'There are some throughput tests which run several etcd nodes locally and measure number of writes, and compare and set requests per seconds. Note: because all etcd nodes were run locally, the results can be different from when each etcd node is ran on its own separated server. etcd cluster size According to the etcd FAQ it is suggested to have an odd number of etcd nodes in a cluster, usually 3 or 5. It also mentions that ""Although larger clusters provide better fault tolerance, the write performance suffers because data must be replicated across more machines."" Proposed solutions  The following solutions are based on the embedded etcd storage discussed in details in chapters below: * Command line etcd cluster creation * Fixed size etcd cluster * Incremental etcd cluster creation Command line etcd cluster creation This approach is to add a command line option to snet-cli which allows us to start an etcd instance as part of etcd cluster:', 'snet storage init --name name --token unique-token --client-url http://AAA.BBB.1.1:2379 --peer-url http://AAA.BBB.1.1:2380 --initial-cluster name1=http://AAA.BBB.1.1:2380,name2=http://AAA.BBB.1.2:2380  The list of client-urls then needs to be passed to each replica to have access to the etcd cluster storage. Fixed size etcd cluster This approach assumes that etcd nodes are started by replicas and that the size of etcd cluster is fixed. The initial configuration file contains a list of all replicas and information whether it should start etcd node or not: For example: | replica id | start etcd node| etcd node name | etcd node client url    | etcd node peer url     | |------------|----------------|----------------|-------------------------|------------------------|', '|  replica 1 |             yes|          node1 | http://AAA.BBB.1.1:2379 | http://AAA.BBB.1.1:2380| |  replica 2 |             yes|          node2 | http://AAA.BBB.1.2:2379 | http://AAA.BBB.1.2:2380| |  replica 3 |              no| |  replica 4 |             yes|          node3 | http://AAA.BBB.1.4:2379 | http://AAA.BBB.1.4:2380| |  replica 5 |              no| Such a configuration requires that all replicas which maintain an etcd node need to be started first to have a functional etcd cluster. Incremental etcd cluster creation approach Starting etcd cluster requires that initial size of the cluster was defined during cluster bootstrap.', 'It means that the cluster begins to work only when quorum number of nodes join the cluster. Suppose there are 3 replicas and they want to run 3 ectd nodes. When the first replica starts an etcd node, it is not able to write and read from the etcd because 2 more etcd nodes need to join the cluster. As an alternative, it is suggested that the first replica starts with etcd cluster which consists of only one etcd node. In this case it will be able to read and write to the etcd. When the second replica starts it can find the existing etcd cluster (using the address of the first replica) and just adds the second node to the cluster. This allows us to have a working etcd cluster even when only some of the replicas are running. Note: etcd has a Discovery Service Protocol. It is only used in the cluster bootstrap phase, and cannot be used for runtime reconfiguration.', 'The following algorithm describes the creating and updating of the etcd cluster during replica initialization based on an incremental approach. Input Each replica needs to have access to the following info which is provided during the replica starting: * etcd cluster token value * list of all replicas with corresponding values:   * replica id   * etcd node name   * etcd ip address   * ectd client and peer ports Cluster Configuration Table The table with the given columns will be maintained in etcd cluster: * replica id * timestamp * running etcd server node flag The last field indicates that a replica started an etcd server instance and that it had been alive at the time when the record to the Cluster Configuration Table was written. Replicas to etcd nodes correspondence Each replica can use a predefined function which returns the number of etcd nodes that are necessary to run for the given number of live replicas. The function can be described in pseudocode like:', 'numberOfEtcdNodes(numberOfReplicas) {     1, 2   -> 1     3, 4   -> 3     5, ... -> 5 } Detecting added and failed replicas It is suggested to use the heartbeat mechanism to detect failures in replicas. Each replica needs to repeatedly write a timestamp using the replica id as a key to the Cluster Configuration Table. When the difference between the current time and the timestamp of the replica is higher than a certain threshold, the replica is considered dead. Detecting failed etcd nodes etcd Admin API Documentation provides a REST api to check the health of an etcd node. Initial state The first initialized replica detects that there is no etcd cluster and starts an embedded etcd instance. Main loop Each replica reads the Cluster Configuration Table, checks the number of live replicas and calculates the number of required etcd nodes using the numberOfEtcdNodes(numberOfReplicas) function.', 'If the number of required etcd nodes is less than the current number of live etcd nodes, then only one replica with the lowest id that does not have a running embedded etcd node starts it and adds this node to the current cluster. There can be two results: * The embedded etcd is successfully run * The replica which starts the etcd misses the timeout and is considered dead If the etcd node initialization succeeds, the replica adds the record to the Cluster Configuration Table to let it know that it has running ectd node. In both cases the process can be just repeated as is.'], ['Publisher Portal Goal is to assist the developers easily publish and manage their organizations and services using the publisher portal. You can list your services on to the marketplace Dapp easily making it very simple for your users to search and use your service.  *** Publisher portal will be live by March ***   On boarding an Organization Enter all relevant data to publish in your Organization through simple forms, which abstracts all the complexity using command line interface. Once the basic on boarding details are entered, a review is triggered for the Singnet Team, this is to ensure compliance with any legal procedures before on boarding any organization on to market place Dapp   Invite Workflow - Adding members to an Organization The platform provides a simple workflow to add new members, the owner just needs to add the email address of the member, the system sends invitation to the member based on accept invitation   and also ensures all the required details like (Wallet address) of the member are furnished when the invitation is accepted.', 'Publishing an Organization on Block Chain Once details of an Organization are entered, a review is triggered, once approved by the Signet team, you can publish the organization through the portal.    Service listing Screen All services managed under your organization are listed here,  Only members belonging to the  Organization can view / add / modify / delete services.   Service metadata Screen Enter all relevant data required to publish your services  using a simple forms, which abstracts all the complexity experienced through command line interface.    Publishing a Service on a block chain OAfter entering all the details, a review process is triggered for the singularity team, to ensure the details are compliant with  legal procedures before on boarding any service on to market place Dapp.     Claim easily from Publisher portal Claims can now be availed using the publisher portal.'], ['The SingularityNET daemon is the adapter that a service can use to interface with the SingularityNET platform. In software architecture lingo, the daemon is a sidecar proxy, —a process deployed next to a core application (the AI service, in this case) to abstract away some architectural concerns such as logging and configuration as well as entire platform aspects, such as the interaction with smart contracts or even the decision to use the Ethereum Blockchain. The two key abstraction responsibilities of the daemon are payments and request translation.  In order to authorize payments, the daemon interacts with the Multi-Party Escrow contract. Before invoking a service through SingularityNET, a consumer must have 1. funded the Multi-Party Escrow contract (see section on payments below) and 2. opened a payment channel with the recipient as specified by the service definition With each invocation the daemon checks that 1. the signature is authentic, 2. the payment channel has sufficient funds, and 3.', 'the payment channel expiry is beyond a specified threshold (to ensure that the developer can claim the accrued funds). After these successful checks, the request is proxied to the service. The daemon also keeps track of payment states of different clients.  Once the daemon has validated requests, it translates them into the format expected by the AI service. The daemon exposes a gRPC, so all requests are based on gRPC and protocol buffers, but it can translate requests to a few different formats, as expected by the service.  In addition to gRPC/Protobuf, JSON-RPC and process fork–based services (executables to be executed on a per-call basis with the input parameters on standard input) are supported. This translation enables one consistent protocol to be used to communicate with any service on SingularityNET. The daemon and CLI also use gRPC and Protobuf for communication. One can deploy multiple instances of an AI service.', 'Each instance will have its own sidecar daemon, and all daemons will be registered as endpoints in the Registry. When multiple instances exist, they can be put into one or more instance groups (a typical reason for doing so would be to group instances in the same data center or cloud region). Daemons in the same group coordinate to share payment status information through etcd. The daemon provides some additional deployment- and administration-oriented features: * SSL termination. This can be done either with a certificate and keyfile supplied by the service developer or with automatic certificates provided by Let’s Encrypt. * Logging to files, with log rotation and pluggable log hooks. Currently an email hook is provided, and an easy-to-use API is available for other hooks. * Metrics, monitoring, and alerts. The daemon collects metrics about request calls, which service owners can use to optimize their resource usage. It also monitors daemon and service events, providing configurable alerts via email or web services.', '* Rate limiting to prevent DoS attacks and to allow service owners to scale at their own speed and ability. The daemon uses the token bucket algorithm. * Heartbeat. A pull-based heartbeat service is provided, following the gRPC health checking protocol. The daemon will check that the heartbeat of the service is configured; this is used by monitoring services as well as the Marketplace DApp. The latest version is {{ data.versions.snet-daemon }}, and can be downloaded from the release page. Supported Service Types The daemon has been written to support a variety of service implementations. Currently, the daemon supports services that either:  expose a gRPC endpoint, expose a JSON-RPC endpoint, or executables called on a per-request basis with the input parameters on stdin  Note however that the daemon exposes a gRPC/gRPC-Web endpoint regardless of what type of service is paired with the daemon.', ""This means we have one consistent protocol to be used to communicate with any service on the SingularityNET network, while still allowing service authors to have flexibility in their implementations. Certain gRPC features such as streaming require the service itself to expose a gRPC endpoint with streaming RPCs. Also note that bi-directional streaming RPCs are only compatible with some gRPC clients (not gRPC-Web i.e. browser clients). Service Models As noted when discussing Services, the service API is defined using protobuf. SSL The daemon supports SSL termination using a developer-supplied certificate and keyfile. For more information, refer to  SSL guide on how to setup with Let's Encrypt. Authorisation and Payment Prior to invoking a service through the SingularityNET platform, the consumer must have completed the following: - Funded the Multi-Party Escrow contract; - Opened a payment channel with the recipient as specified by the Organization metadata. With each invocation the daemon checks for the following"", ""- that the signature is authentic; - that the payment channel has sufficient funds; and - that the payment channel expiry is beyond specified threshold (to ensure that the service author can claim the accrued funds after delivering the service). After the daemon  performs a successful check, the request is sent to the service. Configuration The daemon's behavior with respect to the service type, SSL, Blockchain interactions, etc. can be controlled via a configuration file, environment variables, and executable flags. See the daemon's README for a description of the available configuration keys and how they map to environment variables and runtime flags. Payment channel state The daemon stores the payment channel state in the etcddb cluster. This cluster can either be an embedded etcd instance that runs in connection with each snetd replica (default) or an externally configured cluster. This is detailed here. ETCD cluster.""], [""Troubleshooting Alerting mechanism - Emails Alerts Mainnet Alerts Alert messages are sent through the email Id : no-reply@signularitynet.io Subject : The service 'service-name' is terminated for Mainnet network Ropsten Alerts Alert messages are sent through the mail id : test-no-reply@singularitynet.io Subject : The service example-service is terminated for ropsten network What to do when I receive an alert?  Check whether the daemon end point heartbeats are healthy, and view the daemon logs Restart the daemon, and analyse why the daemon has suspended. Incorporate the post details in the document here as well.   How much time does it take for the service to become healthy on Dapp again? The platform uses exponential back-off retry to test the health of the service. Each time a health check fails, an email message is sent to Service developer ( progressive delay in the next health check )."", 'Note: The maximum time a test can take on the health service is 12hrs. How to configure service metadata to receive alerts ? Obtain the latest version of snet-cli and run the following command: snet service metadata-add-contributor <CONTACTNAME> <EMAILID> --metadata-file <MD_FILE> Your metadata snippet should look like the following: ``` ""contributors"": [            {                ""name"": ""dummy dummy"",                ""email_id"": ""dummy@dummy.io""            } ``` How to I configure the service heartbeat?  Refer to the documentation provided. or the service heartbeat implementation, follow the standard health checking protocol as defined in [gRPC Health Checking] (https://github.com/grpc/grpc/blob/master/doc/health-checking.md) Protocol link.   Note: The service must use the same proto and implement the heartbeat functionality. How to check or receive notification about certificate expiration ?', 'Prior to the expiration of certificate, an email message is sent and a slack alert within 30 days. The email message is sent frequently until the certificate is renewed.  Note This task is performed once in three days.  Mainnet Alerts on Certificates Alert messages are sent through the email Id : no-reply@signularitynet.io  Subject : certificates are about to expire for service %s for %s network. Ropsten Alerts on Certificates Alert messages are sent through the mail id : test-no-reply@singularitynet.io  Subject : certificates are about to expire for service %s for %s network. Common Setups NGINX Since there is no direct support for grpc-web(dapp)from nginx, we can make a below hack in the config file of the nginx to work with both grpc-web(dapp) and grpc(sdk,snet-cli) calls. server {     listen 1449 ssl http2;', ""server_name domain-name;     ssl_certificate pem-file; # managed by Certbot     ssl_certificate_key key-file; # managed by Certbot     include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot     ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot location / {  # ## Any request with the content-type application/grpc+(json|proto|customType) will not enter the ## if condition block and make a grpc_pass while rest of the requests enters into the if block ## and makes a proxy_prass request. Explicitly grpc-web will also enter the if block. #  if ($content_type !~ 'application\\/grpc(?!-web)(.*)'){     add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS';"", ""add_header 'Access-Control-Allow-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Content-Transfer-Encoding,Custom-Header-1,X-Accept-Content-Transfer-Encoding,X-Accept-Response-Streaming,X-User-Agent,X-Grpc-Web,content-type,snet-current-block-number,snet-free-call-user-id,snet-payment-channel-signature-bin,snet-payment-type,x-grpc-web';         add_header 'Access-Control-Max-Age' 1728000;         add_header 'Content-Type' 'text/plain charset=UTF-8';         add_header 'Content-Length' 0;     proxy_pass http://reroute_url; } grpc_pass grpc://reroute_url; }}  The above config works based on the content-type of the request."", 'Whenever the grpc-web(dapp) makes a call to nginx, the content-type would be application/grpc-web and this content-type is not been handled by nginx with grpc_pass. Hence, only those requests with grpc specified  content-type application/grpc+(proto|json|customType) works with grpc_pass while rest of the requests will work with proxy_pass. Setting up your own ETCD cluster To set up your own ETCD cluster please follow the link Certificates for ETCD To renew the ETCD Client Certificates for SNET Organisation: - Run the [et]cd-client-certificates-generation](https://eu-central-1.console.aws.amazon.com/codesuite/codebuild/projects/etcd-client-certificates-generation/history?region=eu-central-1) job. - This task generates the client-certificates in this path. For other Organizations, follow the below steps to regenerate the etcd client certificates. - Download the cfssl & cfssljson using the below commands', ""[curl -s -L -o cfssl] (https://pkg.cfssl.org/R1.2/cfssl_linux-amd64)  [curl -s -L -o cfssl] (https://pkg.cfssl.org/R1.2/cfssl_linux-amd64)  Copy the ca.pem, ca-key.pem, ca-config.json & client.json that you previously used for generating the etcd certificates. Run the below command to generate the client certificates.  How to deploy an Organization and a Service on Ropsten? Complete the following steps listed in the document  Common issues with Daemon start You need to specify a valid signer address, such as 'free_call_signer_address' as part of the curation process to support free calls” bash  snet service metadata-set-freecall-signer-address default_group $SIGNERADDRESS --metadata-file $MD_FILE"", ""Specify a valid private key 'pvt_key_for_metering' to include during the service publication process.” When you enable the free calls and Metering, specify the private key to initialize the Daemon Otherwise, the  Daemon sends the request to metering, which checks the associated public address mapped in the configuration of that Daemon. bash snet service metadata-add-daemon-addresses default_group $DAEMONADDRESS --metadata-file $MD_FILE Unable to create etcd client To learn about how to configure the etcd certificate, refer to the document for configuration with example.  Metering authentication failed. Please verify the configuration” When you enable the free calls and Metering, specify the private key to initialize the Daemon. The Daemon will initialize, only if the configured Pvt key config matches the public Address of the Daemon registered for metering. Daemon addresses are registered for a given Org, Group id  and service id . You need to re-publish the service again with the correct public address ."", 'Please use the  Following command to do so  snet service metadata-add-daemon-addresses default_group $DAEMONADDRESS --metadata-file $MD_FILE Common errors returned by the Daemon Payment signer is not valid for free calls Check if the port number of your daemon matches exactly to what was deployed on Service metadata. bash  snet service metadata-set-freecall-signer-address default_group $SIGNERADDRESS --metadata-file $MD_FILE Free call limit has been exceeded. You have exceeded the number of permitted free calls. So, calls can now be done only using the paid mode alone   End point deployed from Service metadata should be assigned to the same port / domain the daemon is starting.   Rate limiting, too many requests to handle” The number of request has increased along with the rate limiting, either retry again later or configure your daemon for rate limiting  Unexpected payment type” The supported payment types are free-call / escrow', 'Common Daemon warnings (in the logs) “Unable to publish metrics” If you make calls using SDK / snet-cli, the issue is resolved once if the daemon supports metering. Invalid hex address specified/missing for \'authentication_address\' in configuration , you cannot make remote update to current configurations” Ignore: This was more towards the operator UI use case, need modification in the next release.  msg=""error determining current block"" error=""403 Forbidden Add the the following link:  ""ethereum_json_rpc_endpoint"": ""https://mainnet.infura.io/v3/e7732e1f679e461b9bb4da5653ac3fc2"" In your daemon configuration. Ideally  you should have your own project Id on infura.  How do I set up a new host ? Typically you will need to do the below  - Domain Name  - GPU/Without GPU - RAM Required - HD Required - Ports for public access', '- Public Key to setup the user - Certificates for HTTPS  How do I get the latest version of Daemon All latest released versions of Daemon are available here - Download the latest  - untar You need to manually configure the path to refer to this binary. How do I get the latest version of snet-Client pip install --upgrade snet-cli Note: manually configure the path to refer to this binary. When there is proto change? Ensure that you re deploy the service with the latest proto  snet service metadata-init --metadata-file $MD_FILE `pwd`/$YOURGITREPONAME/$PATHFORSERVICESPEC ""$DISPLAYNAME"" --encoding proto --service-type grpc --group-name default_group Also make sure  your stubs are updated on the Dapp Components DAPP My Service is not visible on Dapp  Ensure the services have been published on the network for testing', 'After curation, the service becomes available on Dapp    Keep the below links for reference  Dapp for Ropsten: http://enhanced-marketplace.s3-website-us-east-1.amazonaws.com/ Dapp for Mainnet: http://beta.singularitynet.io/   How to make a call from the DAPP  Open the respective service’s page. In the Service Demo section, you will notice the Free calls pending count, provided  you have already logged in to the system.  Click on the RUN FOR FREE button. (If your free calls are exhausted, you will find options to create a wallet or to use your existing MetaMask wallet ) You will be taken to the service’s input screen. - Fill in the necessary details. - Click on INVOKE.   Note: Don’t close the application, until the results are displayed  on the same screen after service execution.  Where do I see the components I can reuse on Dapp', 'Check for the reusable components code here  => snet-dapp-monorepo/packages/shared/src/components. You could also run yarn storybook to view the demo of the components. While importing, import the components from => snet-dapp-monorepo/packages/dist/components.  How do I raise a Pull request for DApp  Raise pull requests using “snet-dapp-monorepo/development”. After merging in the development. It will be deployed to the ropsten network:http://enhanced-marketplace.s3-website-us-east-1.amazonaws.com/  When does my Pull request gets merged to Master   If your changes are seen in ropsten.  Inform the concerned authority to merge the changes from development to master. This is then deployed to Mainnet network: http://beta.singularitynet.io/   Whom and How  do I reach out for help/Support Use the email tech-support@singularitynet.io for any questions / issues related to the platform.'], [], ['Introduction to MPE An Escrow contract defines the conditional transaction between two transacting parties through an Escrow account.  The Multi-party Escrow (MPE) smart contract API and the payment channel together enable payments in the SingularityNet platform with a minimal number of on-Blockchain interactions between AI Consumers and AI service providers. The MPE contract has two main functionalities which includes:  A wallet with a deposit and withdraw function.   A set of the simple (“atomic”) unidirectional payment channels between clients and service providers and support functions for controlling these channels. Note: Any one can deposit and withdraw their AGIX tokens into a Multi-Party Escrow, (which have not been escrowed at the moment).   What is Payment Channel? Whenever the sender and the receiver enter into an contract, a channel is created. A payment channel is a tool that enables off-chain transactions between parties without the delay imposed by Blockchain block formation and without compromising the transactional security.', 'Atomic unidirectional payment channel You can ignore this section, if you are familiar with the concept of payment channels. The core logical building block of the Multi-Party Escrow is a simple (“Atomic”) unidirectional payment channel. To learn more about the details of how to implement the Escrow contract for unidirectional payment channel, click on this link SimpleEscrow.sol file here.  It is understood that the payment channel is on the Blockchain. So, in order to prevent direct updating on the Blockchain regularly, the payment channel state is maintained in the storage. Daemon maintains the channel state off chain as block operations involve gas cost and are slow between parties without imposing any delay by the Blockchain block formation times and compromising on transactional security.  Let us consider the simple unidirectional payment channel, the main logic is as follows:  The sender creates an Escrow contract with a given expiration date, and funds it with a desired amount of tokens.', 'The sender then needs to send a small amount of tokens to the recipient each time (to the recipient) with signed authorization The recipient must verify whether the signed authorization and the amount required is correct, and that amount specified does not exceed the funds being escrowed. The channel nonce is incremented, whenever a claim happens, Actually, the channel is not closed and the task can still continue off line, but a new nonce need to be used. The sender can perform the following: Can collect all funds remaining after the expiration date.   -or- Extend the expiration date and add funds to the contract at any moment in time.    Note: The receiver can withdraw from the channel (same as claim) only using the authorized amount by the sender.  Whenever a signature is made on a certain format which should be signed by the private key of Kevin, Jack then verifies whether the signature was authentic to Kevin, based on the agreed format.  MPE Use cases Consider the following', '- Kevin  - is our Client  Consumer/Buyer  - Jack - is our Service Provider/Seller If Kevin is buying services from the Jack, they both need to enter in to a formal agreement with each other.A channel is created. Note: Each channel is unique to a combination of client identity (sender), service identity (recipient),Organization Id and the daemon group identity.   Kevin deposits tokens to the Multi-Party Escrow account and uses this as a wallet for their AGIX tokens. JKevin creates and opens a Payment Channel.  Note: Kevin is the sender of tokens and Kevin is the receiver of tokens. Every channel created has a unique ID, which begins from 0. Kevin funds the channel     Kevin suggests Jack to deposit a bare amount ( cost of the service) and mentions that the amount can never been withdrawn for a predetermined period of time. This period is configurable.', 'Based on how much Kevin wants to use a service, Kevin deposits the amount in to the channel accordingly, so if the cost is 1 cog, and Jack needs to use it 10 times, he will deposit 10 cogs. Nonce is always zero when you create the channel for the first time.     Note: Unless and until Jack authorises, the Kevin cannot withdraw the money.     Jack and Kevin come in to agreement to perform operation Off chain. The daemon manages the off chain state of the channel.  Kevin needs to authorize using the signature (using his private key to sign) to let Kevin withdraw Jack verifies the following Signature is authentic; Amount of AGIX tokens specified is correct (last Authorized Amount from Kevin + Cost of the Service being called) ; Amount does not exceed the value of the channel Channel is not very close to expiring or has expired.   Kevin makes a call; Jack now sends the signed authorization to Kevin to “withdraw”.', 'The effective balance is 1. Jack can now make a claim with the amount authorized.     Note: Nonce increments to 1, when claim is performed.  Diagram showcasing how Kevin and Jack Communicate   State management of the channel  Kevin (Buyer) and Jack (Service provider) enter into a contract for the first time, they create a channel details in the Blockchain is as follows:   |Channel ID       | 1       |The channel ID created is 1 on Chain| |---------------------|-------- |----------------------------------| |Nonce            | 0       |Initially the Nonce is 0| |Full amount      | 100 Cogs|Amount Kevin has put into the channel is 100 Cogs| |Authorized Amount| 0       |The Authorized amount is zero, because no services has been used for the first time.| |Signature        | Nil     |No signature is required to be sent.|', 'Kevin makes a call and authorizes for 1 cog to Kevin, (assuming the cost of the service is 1 cog) ,the status of the channel is now maintained offchain by the storage mechanism used by Daemon :  |Channel ID       | 1       |The channel ID 1 is now updated off chain| |-------------------- |-------- |----------------------------------| |Nonce            | 0       |Initially the Nonce is 0| |Full amount      | 100 Cogs|Amount Kevin has put into the channel is 100 Cogs| |Authorized Amount| 1       |The Authorized amount is zero.| |Signature        | 1       |No signature is required to be sent.|  Kevin makes a call and authorizes for 2 cogs, to Jack, now the status changes as follows:  |Channel ID       | 1       |The channel ID 1 is now updated off chain| |---------------------|---------|----------------------------------|', '|Nonce            | 0       |Initially the Nonce is 0| |Full amount      | 100 Cogs|Amount Kevin has put into the channel is 100 Cogs| |Authorized Amount| 2 Cogs  |The Authorized amount is two.| |Signature        | 2 Cogs  |Signature is required for two.|  Jack makes a claim using the signature from Kevin, this transaction is considered on-chain transaction.  please note the effective balance in Blockchain for this channel is now 98 and its nonce is 1,The same channel state is updated as follows even in the off chain state:  |Channel ID       | 1       |The channel ID created is 1| |---------------------|---------|----------------------------------| |Nonce            | 1       |Initially the Nonce was 0 but now it is 1| |Full amount      | 98 Cogs|Amount signed by Jack was for two cogs.', 'The full amount in the channel is 98.| |Authorized Amount| 0       |The Authorized amount is two.| |Signature        | 0       |No signature is required to be sent| Note: Claims are always on-chain transaction and the Nonce gets incremented when claims are made.  The same process follows for future calls authorizations of cogs. Postponing the Expiration Time of the Channel With the following functions the client can postpone the expiration time of the channel and can add funds to the channel at any time and can also claim all funds from the channel after the expiration time is reached. function channelExtend(uint256 channel_id, uint256 new_expiration); function channelAddFunds(uint256 channel_id, uint256 amount); function channelExtendAndAddFunds(uint256 channel_id, uint256 new_expiration, uint256 amount); function channelClaimTimeout(uint256 channel_id); Claiming your funds back after Expiration', 'The Sender can claim the funds after the expiry date function channelClaimTimeout(uint256 channel_id); How the recipient Claims funds from the Channel With the following function, the recipient can claim funds from the channel function channelClaim(uint256 channelId, uint256 amount, uint8 v, bytes32 r, bytes32 s, bool isSendback) It should be noted that v, r, s are parts of the signature. The recipent should present the signature for the following message [MPEContractAdress, channelId, nonce, amount]. It should be noted that [MPEContractAdress, channel_id, nonce] is the full ID of the ""atomic"" channel. The recipient has two possibilities: * (is_sendback==true) - ""close"" the channel and send the remainder back to the sender. * (is_sendback==false) - ""close/reopen"".', ""We transfer the claimed amount to the recipient, but instead of sending the remainder back to the sender we simple change the nonce of the channel. By doing this we close the old atomic channel [MPEContractAdress, channel_id, old_nonce] and open the new one [MPEContractAdress, channel_id, new_nonce]. Remarks  The service provider can use the same Ethereum address for all payment groups or can use a different address. In any case, the daemons very rarely need to send an on-chain transaction. This means that we actually don't need to provide the daemons with direct access to the private key. Instead, a centralized server could sign the transactions from the daemons (in some cases it even can be done in semi-manual manner by the service owner). We call such a server a treasurer server. In the current implementation, the client signs off-chain authorization messages with the signer's private key."", ""This means that the client doesn't necessarily need to sign transactions with his Ethereum identity. Instead, he can use other key pairs. The server does not need to wait for a confirmation from the Blockchain after it sends on-chain requests to close/reopen channels (channelClaim). It can inform the client that the nonce of the channel has changed, and it can start accepting calls from the client with a new nonce. It can be shown that it is secure for both the client and the server if the transaction is accepted by the Blockchain before the expiration date of the channel. Similarly, the client doesn't need to wait for a confirmation from the Blockchain after sending the channelExtendAndAddFunds call. It makes the Multi-Party Escrow functional, even on a very slow Ethereum network.   The nonce in the channel prevents a race between the channelExtendAndAddFunds and channelClaim. If the client sends the channelExtendAndAddFunds request and at the same time the"", 'server sends a channelClaim request, they can continue to work without receiving confirmation from the Blockchain. In this case it also does not matter which request will be accepted first (as channelClaim can only change the nonce, and cannot create a new Payment Channel structure).  Contract Addresses Click here MPE Stateless Client The Client does not have to maintain the state of the last amount it had signed  The client can request the last state of the given payment channel from the server.     * The server is not able to forge this state, because it was signed by the client (of course the client should check its own signature).     * The server is obviously interested in saving and sending the last state, otherwise it loses money. This section describes how the client communicates with the SingularityNET services using the Multi-Party Escrow payment channels without storing state of the payment channel.  The client needs to store the Ethereum identity as follows: 1.', 'The client obtains the list of payment channels (payment channels with ""sender==client"") from the Multi-Party Escrow (see EventChannelOpen).      Considering the situation in which the request to open the channel had been sent, but not yet mined. This can occur when the client request has not received any acknowledgement or the session is disconnected (it ""lost"" its state). 2.  The client requests the last state of the given payment channel from the server  The server can never duplicate the state of the payment channel signed by the client (off course the client should check its own signature). The server saves and sends the last state, otherwise the money lost.  Note: A unique gRPC method is available in the daemon helps return the state of the channel (see: https://github.com/singnet/snet-cli/blob/master/snet_cli/resources/proto/state_service.proto).', ""The client does not necessarily require a special call request to know the last state of the channel from the daemon.  The daemon can return the state of the channel in the response to any non-authorized call. The client receives the following information from the daemon:  current_nonce Current nonce of the payment channel. current_signed_amount   Last amount which were signed by client with current_nonce. If no messages were signed with the current_nonce, then this value is an empty byte string (b''), which we should interpret as 0. **current_signature **   Last signature sent by the client with current_nonce, it could be absent (empty string) if no message was signed with current nonce. oldnonce_signed_amount last amount which was signed by client with nonce=current_nonce - 1. oldnonce_signature last signature sent by client with nonce = current_nonce - 1."", 'Note: The two last values are not available in current version, if implemented, can calculate the unspent_amount in the case that current_nonce != |Blockchain_nonce. Example Assume that the server performs a close/reopen procedure for the channel. The client can proceed without confirmation from the Blockchain, because the server does not need to be dependent, or the client ensures that the request is mined before expiration of the channel. Before considering the above scenario, define the following parameters - |Blockchain_nonce - nonce of the channel in the Blockchain - |Blockchain_value - value of the channel in the Blockchain It is known that the daemon starts the close/reopen procedure only after the previous channelClaim request was mined. This means that the current_nonce, at maximum, is one point ahead of the |Blockchain_nonce. In each case, the client can verify their signature is authentic and considers the following two numbers:', ""Next amount which has to be signed (next_signed_amount), taking into account the price for the current call (price). This value can be easily calculated as we interpret current_signed_amount = b'' as 0. next_signed_amount = current_signed_amount + price   The amount of tokens which haven't been already spent (unspent_amount).  Simple case current_nonce == |Blockchain_nonce - unspent_amount = |Blockchain_value - current_signed_amount Complex casecurrent_nonce != |Blockchain_nonce Taking into account our assumptions, we know that current_nonce = |Blockchain_nonce + 1. - unspent_amount = |Blockchain_value - oldnonce_signed_amount - current_signed_amount"", 'Note: The server can send smaller oldnonce_signed_amount (not the actually last one which was used for channelClaim), But the server trust that the money available is actually more in the channel, which means that a likely attack has occurred through unspent_amount, which lead us  believe that there are less tokens than the actuals, and therefore the future calls need be rejected instantly (or force us to call channelAddFunds).'], [], ['Introduction to SingularityNET Marketplace The The SingularityNET Marketplace  is a decentralized application (DApp), which lists the available AI services and helps you to interact with those services through web interface abstracting all the complexity in invoking a service. It also processes payment for services (through MetaMask/General Wallet)  and conduct service ratings. Whenever transaction happens on Blockchain, an event is created. The marketplace monitors all those events.  For example, if you publish a new organization, a new service, the marketplace receives an alert notification about published information in the Blockchain. The marketplace reads the organization metadata, the service metadata and the stores this into its database. This application efficiently displays all the details quickly without relying on the slow performance of the Blockchain The following image shows the contents from the marketplace.    The decentralized application (DApp) does the following: - Reads data from the on-chain Registry and pairs it with off-chain metadata.', 'This allows for searching, filtering, and discovering AI services.   Integrates the SingularityNET curation service, and displays from the registry.     Whenever an event comes from Blockchain, the details are stored in the local database, the review process is done on that data, and then when approved, the information is made available in the marketplace.      Note: Displays those services that have been vetted, and owners who have experienced due diligence and signed legal agreements that protects user and data privacy.   Displays custom UI components for interactions with AI services.     It enables you to quickly build the UI components and host the component on the platform, and also you can determine what inputs need to be chosen for service execution, and is the expected output, without understanding the complexity of knowing the gRPC protocol, the proto that is associated with the service and how to call the service and so on.   Integrates with Multi-Party Escrow, to allow consumers to pay for service usage;', ""Allows consumers to rate about the utilized services     Note: This rating services will be part of the SingularityNET's Reputation System (currently under development). Currently, it is very difficult to rate services on Blockchain. Therefore all rating mechanism are performed off chain and managed in the market place. So you can share your opinion and reviews at marketplace.   Captures usage metrics at a consumer level.   Note: Although, the SingularityNET platform is open and decentralized, the Marketplace is the SingularityNET Foundation's curated view. This allows the foundation to adhere to legal requirements of different legislative regions. Currently, the Marketplace and SingularityNET is in beta stage. For more information about the current status, refer to  current status page for changes, or follow the git-repo Marketplace Requirements If you are a service author, for the service to be visible to others and listed on the marketplace you must: 1.  Build and publish your service  2."", ""Use SSL with the snet-daemon.      Note: if you don't already have an SSL certificate for your domain, it is recommend you use certbot and letsencrypt . 3.  Fork the snet-dapp repo, build a react component as the user interface for your service, and submit a pull request.      Note: Identify the services on your networks, organization and service names being used. For more details, refer to dapp repo README.md. 4.  Last is some paperwork that we are still finalising, and we'll update this list when we have that. If you are itching to get your service listed, reach out to us via one of our community groups.     Note that your service can be published to SingularityNET without being listed on the marketplace, but your service may be less discoverable to potential customers if it is not listed.""], ['Overview SingularityNET (SNET) is an open and decentralized network of AI services made accessible through the Blockchain. Developers publish their services to the SingularityNET network, where they can be used by anyone with an internet connection. Developers are able to charge for the use of their services using the native AGIX token. Services can span the entire gamut of offerings in artificial intelligence and machine learning. Services can provide inference or model training across myriad domains such as image/video, speech, text, time-series, bio-AI, network analysis, etc. The services can be as simple as wrapping a well-known algorithm such as A* path planning, a complete end-to-end solution for an industry problem, or a standalone AI application. Developers can also deploy autonomous AI agents that interoperate with other services on the network. The SingularityNET platform contains a number of critical components that work together to enable a decentralized network of AI services to flourish.', 'The core components are designed to allow for a functional, scalable, and extensible system. We arrived at the current architecture through a careful process, guided by a few key decisions governing Blockchain interactions, AI service integration, and abstraction and by the goal of building an AI marketplace that is both open and compliant with regulatory and legal requirements. First, we made the conscious choice to minimize our dependence on our current Blockchain, Ethereum. Both conceptual and practical issues motivated this decision. Conceptually, we desire to be Blockchain-agnostic and, if necessary, will consider building our own consensus algorithm based on reputation. The speed, reliability, and costs of Ethereum Blockchain interactions dictate that any scalable system built on top of it must minimize gas costs and the delays introduced by block-mining time.', ""These decisions are reflected in our use of tools to abstract away all Blockchain interactions (the daemon, CLI, and SDK) and in our use of a multi-party escrow contract and atomic unidirectional channels for payments. Second, on AI services integration, we wanted to abstract away as much of the network as possible, in order to reduce the learning curve and minimize the overhead associated with providing AI services via the network. This abstraction is achieved with a single flexible tool, the daemon, that will help us provide scalability, robustness, distribution, and management features to the entire community. Finally, to make our marketplace compliant with regulations without compromising on openness, we implemented it separately from our fully decentralized registry of AI services currently available on the Blockchain. Concepts and Components Here we've broken down the SingularityNET platform and network into its core components. The diagram below depicts the key components along with auxiliary components and their roles."", ""You can jump directly to the thing you'd like to know more about, or use the navigation on each page to read through them in turn.  The Request for AI Portal (RFAI): is a DApp through which end users and application developers can request specific AI services they would like added to the network and stake AGIX tokens as a reward for high-quality solutions.""], ['IPFS: The Inter-Planetary File System (IPFS) is a peer-to-peer network and a network protocol used to store and share data in a distributed file system. IPFS uses content-addressing to uniquely identify each file in a global namespace connecting all computing devices. Organization details and service details are stored in IPFS and the hash associated with them are stored in a Blockchain. Registry The SingularityNET Registry is an ERC-165–compliant smart contract on the Ethereum Blockchain that stores organizations, services, and type repositories. Registry provides all the information needed to find and interact with AI services on the platform, either by listing the information in full, or  when it is too long, by listing the IPFS hash. Contract Contract: Contracts are smart programs or algorithms, executes when certain conditions are met successfully. MultipPartyEscrow Contract An Escrow contract defines the conditional transaction between two transacting parties through an Escrow account. Channel', 'A payment channel is a tool that enables off-chain transactions between parties without the delay imposed by Blockchain block formation and without compromising the transactional security. Daemon Daemon maintains the channel state off chain, so in order to  constrain operations involving gas cost (such as compensation or incentive or commission or any other facility charges levied) and allow transaction  between parties without imposing any delay by the Blockchain block formation times and compromising on transactional security. The SingularityNET daemon is an adapter that a service uses to interface with the SingularityNET platform. In software architecture lingo, the daemon is referred to sidecar proxy, — a process deployed next to a core application (the AI service, in this case) to abstract architectural details, such as logging and configuration, and the platform - interaction with smart contracts or even the decision to use the Ethereum Blockchain.  SDK SDK is a tool for AI customers to make calls to service.', 'The SDK simplifies the process of integrating with SingularityNET services and provides tooling to automatically augment gRPC client stubs with the necessary authorizations.  The SDK is available in NodeJS, Python and Java languages. The  Snet-Cli The SingularityNET command line interface (CLI) is the primary tool for interacting with the platform’s smart contracts, managing deployed services, and managing funds.  OffChain & On Chain Transaction All transaction between the two parties are done in offchain mode in order to bring down the dependencies such as , gas cost, and disconnection from Blockchain.  Only when a claim is performed the nonce gets incremented the transaction becomes on Chai  transaction. Signature Authorization given by the signer   Wallet/Address Wallet is where you hold your crypto currencies , every wallet is associated to an address.  Dapp The SingularityNET DApp is essentially a rich Registry explorer.', 'It loads the Registry and generates UI for managing the  Services and Type Repositories registered in it. Metamask MetaMask is an internet browser extension that allows users to interact with the Ethereum Blockchain and its decentralized applications. MetaMask serves as your access portal for both the Ethereum Mainnet and Ropsten. AGIX AGIX is the proprietary cryptocurrency token used by the SingularityNET platform. SingularityNET (AGIX) is an Ethereum based token complying with ERC-20 standards. The AGIX token will be used to settle a transaction over the Blockchain.  AGIX Token Tokens can be staked for voting rights and to become an Agent or spent on goods and services on the platform. Cogs It is the unit of measurement transacted between parties.  ETCD ETCD is a local database that store all the events as table, when an event is triggered from Blockchain ETCD is also considered as a Deamon.', ""ETCD was chosen because it is written in Go, and has out of the box embedded server support. This means that its nodes can be started and stopped by snet-daemon replicas Gas and Gas Cost The speed, reliability, and costs of Ethereum Blockchain interaction dictates that any system built on top of this must be scalable , and the block-mining time introduce minimize gas costs and delay.  These decisions are used in tools to abstract away all Blockchain interactions (the daemon, CLI, and SDK) and in our use of a multi-party escrow contract and atomic unidirectional channels for payments. Gas Strategy ( Slow , Medium and Fast) Ethereum gas price is a time based gas price strategy ('fast' ~1min, 'medium' ~5min or 'slow' ~60min) (defaults to session.default_gas_price). Infura DApps and smart contracts can use function to discover AI services."", 'The Universal Resource Identifier (URI) is specified as a IPFS hash, - can be a file an image and so on, which points to the location in the IPFS system, and this hosting itself can be done by either SingularityNET, the service developer, or any IPFS pinning service, such as Infura. Infura DApps and smart contracts can use function to discover AI services. The Universal Resource Identifier (URI) is specified as a IPFS hash, - can be a file an image and so on, which points to the location in the IPFS system, and this hosting itself can be done by either SingularityNET, the service developer, or any IPFS pinning service, such as Infura.'], ['SDK Architecture']]","The SingularityNET Registry is a smart contract on the Ethereum Blockchain that stores information about organizations, services, and type repositories. The Registry allows AI developers to announce their services and consumers to find the services they need. The SingularityNET DApp is a user interface that allows users to interact with the services listed on the Registry. The SingularityNET daemon is an adapter that allows AI services to interface with the SingularityNET platform. The daemon handles tasks such as payment processing and request translation. The SingularityNET SDK provides tools for developers to integrate their services with the platform. The Multi-Party Escrow contract enables secure and efficient payments between consumers and service providers. The SingularityNET Marketplace is a decentralized application that lists and facilitates interactions with AI services. The marketplace integrates with the Multi-Party Escrow and allows users to rate and review services."
3,docs/review-content,"[['The SingularityNET Marketplace provides an easy way for people to browse available AI services and interact with them via a web interface.  The SingularityNET marketplace is a decentralized application (DApp) and provides a front-end for exploring available AI services and interacting with them through a web-UI. It also handles payment for services (through MetaMask) and service ratings. The DApp   * reads data from the on-chain Registry and pairs it with off-chain metadata, allowing AI services to be searched, filtered, and discovered;   * integrates the SingularityNET curation service, displaying from the Registry only those services that have been vetted and whose owners have undergone due diligence and signed legal agreements that protect user privacy and data;   * allows AI services to display custom UI components for user interactions (gathering inputs for service execution and displaying results);   * integrates with Multi-Party Escrow, enabling the user to pay for service usage;', ""* allows consumers to rate services they have used, this simple consumer rating will eventually be integrated with SingularityNET's Reputation System (currently under development); and   * captures usage metrics at a consumer level. While SingularityNET the platform is open and decentralised, the Marketplace is the SingularityNET Foundation's curated view of it. This allows the foundation to provide oversight and adhere to legal requirements requirements in different legislative regions. The Marketplace and SingularityNET is in beta, but still under heavy development. See our current status page for ways to to stay informed of changes, or follow the github repo. Calling a Service The Marketplace is a DApp, which means in order to use it you need to install a ethereum browser extension like MetaMask. This extension carries out interactions with the Blockchain on your behalf, allows you to transfer tokens between wallets, and invoke contracts."", ""In the context of the marketplace it lets you query what services are available, transfer AGIX funds into escrow, and setup payment channels that allow you to call any of the listed services. For a full guide on getting your wallet and browser setup, see our Setup Guide. Marketplace Requirements If you are a service author, we mandate a number of requirements for the marketplace before your service will be visible to others. To get your service listed on the marketplace you must:  Build and publish your service ;-) Ensure you are using SSL with the snet-daemon. We recommend using certbot and letsencrypt if you don't already have a SSL certificate for your domain. Fork the snet-dapp repo, build a react component as the user interface for your service, and submit a pull request. Let us know what networks your service is on, and the organisation and service names used. More details are in the dapp repo README.md."", ""Last is some paperwork that we are still finalising, and we'll update this list when we have that. If you are itching to get your service listed, reach out to us via one of our community groups.  Note that your service can be published to SingularityNET without being listed on the marketplace, but your service may be less discoverable to potential customers if it is not listed.""], ['In this guide, you will find the guidelines to help you write and integrate new AI services to the platform. Supported languages SingularityNET services use gRPC, which is an open-source universal RPC framework. Any new service must provide its API in the gRPC standard. gRPC supports several programming languages such as: - C++ - Java - Python - Go - Ruby - C# - Node.js - Android Java - Objective-C - PHP - Haskell  A guide for each of them is available here. We have created tutorials with step-by-step instructions for implementing a new service in a number of these languages:  How to write a SingularityNET service in C++ How to write a SingularityNET service in Python How to write a SingularityNET service in Java How to write a SingularityNET service in Go  If you already have a gRPC service, please check out this tutorial to learn how to publish a service.', 'Make sure you follow our naming standardization guidelines as well when naming your services. AI frameworks There are a couple of AI frameworks integrated to SingularityNET so you can just add new functionalities to services which are already published.  OpenCog: an open-source software project aimed at directly confronting the AGIX challenge, using mathematical and biological inspiration and professional software engineering techniques. It currently ranks in the top 10 in Github for most popular AI projects!  There are tutorials with step-by-step instructions on how to extend the existing AI framework service in order to implement new functionalities: - How to write an OpenCog service for SingularityNET Service documentation All the following documentation is recommended for any service.  README describing the structure of the repository and how to build/test the service. This is a sort of ""developer\'s guide"" aimed at people interested in extending or reusing the service. docs/index.html pointed by standard Github Pages describing how to use the service.', 'This is the ""user\'s guide"" of your service. LICENSE with an MIT license, the license of choice SingularityNET usually uses as well.  If you are extending an existing service. Follow any particular guidelines of the specific project and make sure you update all the aforementioned documents accordingly. See this example of service documentation which is fully compliant with these guidelines. Contributing to existing projects SingularityNET has several AI service integration projects. See our github for a list of them. Before contributing to any of these, please read our contribution guidelines.'], ['Page settings layout: default keywords: intro concepts comments: false    Python 3.6+   Create a Virtual env   Node 8+ with npm   SNET CLI  libudev libusb 1.0    SNET Daemon   For example, installing the requirements using Ubuntu 18.04: ```sh sudo apt-get update sudo apt-get install wget git sudo apt-get install python3 python3-pip sudo apt-get install nodejs npm sudo apt-get install libudev-dev libusb-1.0-0-dev sudo pip3 install snet-cli #( installs snet-cli) sudo pip3 install snet-sdk #( this also installs snet-cli) !!! Get the latest snet-daemon from Github releases SNETD_VERSION=curl -s https://api.github.com/repos/singnet/snet-daemon/releases/latest | grep -oP \'""tag_name"": ""\\K(.*)(?="")\'', 'cd /tmp wget https://github.com/singnet/snet-daemon/releases/download/${SNETD_VERSION}/snet-daemon-${SNETD_VERSION}-linux-amd64.tar.gz tar -xvf snet-daemon-${SNETD_VERSION}-linux-amd64.tar.gz sudo mv snet-daemon-${SNETD_VERSION}-linux-amd64/snetd /usr/bin/snetd ```'], ['Publishing Organization on Blockchain Setting Metadata Create an Identity in snet-cli for mainnet , if you already have an account with ether , then you can use it , as an example sh snet identity create test-user key --private-key <PVT-KEY> --network mainnet Add in the organization name , id and the type of organization test-org-name is the organization name and test-org-id is the organization id.  sh snet organization metadata-init test-org-name test-org-id individual the below will be added to the metadata file  ```json     ""org_name"": ""test-org-name"",     ""org_id"": ""test-org-id"",     ""org_type"": ""individual"", ``` Add in description about your organization sh snet organization metadata-add-description [-h] [--description DESCRIPTION]                                            [--short-description SHORT_DESCRIPTION]                                            [--url URL]                                            [--metadata-file METADATA_FILE] Example  sh', 'snet organization metadata-add-description --description ""Describe your organization details here "" --short-description  ""This is short description of your organization"" --url ""https://anyurlofyourorganization"" the below will be added in to the metadata file  json     ""description"": {         ""description"": ""Describe your organization details here "",         ""short_description"": ""This is short description of your organization"",         ""url"": ""https://anyurlofyourorganization""     }, Add in Recipient and group details The etcd cluster has been set up from the previous step and you need to use the same endpoint  groups : Multiple groups can be associated with an organization, one payment type is associated with every group. payment_address : Address of the Service provider who would receive the payment payment_channel_storage_type : Type of storage to manage payments ( For Example ETCD ) endpoints : Storage end points for the clients to connect. sh', 'snet organization add-group <group_name> <wallet_address> <etcd-end-point> Example  sh snet organization add-group default_groups 0x06A1D29e9FfA2415434A7A571235744F8DA2a514 https://your-etcdendpont:2379 This would append the below to the json ```json ""groups"": [         {             ""group_name"": ""default_groups"",             ""group_id"": ""gz/+/M9l/qxpfNzPn+T2XmTSPMKyphYyxSsQSPhEJXA="",             ""payment"": {                 ""payment_address"": ""0x06A1D29e9FfA2415434A7A571235744F8DA2a514"",                 ""payment_expiration_threshold"": 100,                 ""payment_channel_storage_type"": ""etcd"",', '""payment_channel_storage_client"": {                     ""connection_timeout"": ""100s"",                     ""request_timeout"": ""5s"",                     ""endpoints"": [                         ""https://your-etcdendpont:2379""                     ]                 }             }         }     ] ``` Add in any images related to your organization sh snet organization metadata-add-assets [-h] [--metadata-file METADATA_FILE] ASSET_FILE_PATH ASSET_TYPE Example sh snet organization metadata-add-assets image.png  hero_image the below will be appended to the json ```json     ""assets"": {         ""hero_image"": ""QmT3WWHEVsdQw5dD9TB4e1Xej2MfcQNrQS8FAHwBepG3HD/image.png""     }, ``` Add in any contact details related to your organization sh', 'snet organization metadata-add-contact [-h] [--phone PHONE] [--email EMAIL]                                        [--metadata-file METADATA_FILE]                                        contact_type Example sh  snet organization metadata-add-contact --phone 123456789 --email yourorg@yourorg support the below will be appended to the json ```json     ""contacts"": [         {             ""contact_type"": ""support"",             ""email_id"": ""yourorg@yourorg"",             ""phone"": ""123456789""         }     ], ``` Now check the metadata file created  sh cat organization_metadata.json Publish the organization Please note you will need an account with Ether to do the below Members can update/delete/add services under the given organization , however only the owner can modify the metadata of an organization. sh snet organization create mozi <addressofMember1>,<addressOfMember2> See the CLI documentation for full details of actions the tool allows.'], ['Page settings layout: default keywords: intro concepts comments: false  Publishing Service Setting Metadata Let us define the values as below ```sh ORGID=test-org SERVICEID=test-service_id; DISPLAYNAME=Display Name; DOMAINNAME=https://daemondomainname; PORT=8088; ENDPOINT=$DOMAINNAME:$PORT   PRICE=0.00000001 #for the sake of an example HELPURL=https://helpurl; PATHFORSERVICESPEC=/pathtoyourproto/; SERVICEDESCRIPTION=Service Description; SHORTDESCRIPTION=Short Description of your service; CONTACTNAME=Name1; EMAILID=Nam1@yourorg; #Address to be registered for your Daemons DAEMONADDRESS=""0xDBb9b2499c283cec176e7C707Ecb495B7a961ebf"" FREECALLS=15', '#The address is of the Signer , who would issue you free tokens #Please note , if you are using market place Dapp , then we recommend to set the below #for free call Support  #for Ropsten the Signer Address is 0x7DF35C98f41F3Af0df1dc4c7F7D4C19a71Dd059F #for mainnet the Signer Address is 0x3Bb9b2499c283cec176e7C707Ecb495B7a961ebf SIGNERADDRESS=""0x7DF35C98f41F3Af0df1dc4c7F7D4C19a71Dd059F"" #Tags should be in small letters  TAGS=image-recognition;  #create a metadata file with the same name as the service id. MD_FILE=""your_service.json"";  ```', 'Run the snet-cli commands as below ```sh  snet service metadata-init --metadata-file $MD_FILE pwd/$YOURGITREPONAME/$PATHFORSERVICESPEC ""$DISPLAYNAME"" --encoding proto service-type grpc --group-name default_group snet service metadata-set-fixed-price default_group $PRICE --metadata-file $MD_FILE snet service metadata-add-endpoints default_group $DOMAINNAME:$PORT --metadata-file $MD_FILE snet service metadata-add-description --metadata-file $MD_FILE --description ""$SERVICEDESCRIPTION""  --short-description ""$SHORTDESCRIPTION"" --url ""$HELPURL"" \u200b if you want to support free calls , you will need to do the below snet service metadata-set-free-calls default_group $FREECALLS --metadata-file $MD_FILE snet service metadata-set-freecall-signer-address default_group $SIGNERADDRESS --metadata-file $MD_FILE', 'snet service metadata-add-contributor ""$CONTACTNAME"" $EMAILID --metadata-file $MD_FILE snet service metadata-add-daemon-addresses default_group $DAEMONADDRESS --metadata-file $MD_FILE snet service metadata-add-assets service_metadata1.json hero_image ``` Publish Service on Blockchain You need to have some ether in your wallet to publish a service You must be either the owner or a member to have permission to publish/delete/Modify a service sh', 'snet service publish $ORG_ID $SERVICE_ID --metadata-file $MD_FILE'], [""The platform's primary reason for existence is to allow a diverse collection AI services to be bought and sold via a distributed marketplace. Anyone can publish the availability of their machine learning method, or integrated AI solution, and allow clients to interact with and pay for them directly. Groups are logical bucketing of managing payments ( same recipient for each group across all the services in an organization) As part of Supporting a single channel per Organization per Group (Payment Group across the services) we will need all the services to share the same channel state,We need to standardize what this state is across all services belonging to the same group.""], ['The SDK simplifies the process of integrating with SingularityNET services and provides tooling to automatically augment gRPC client stubs with the necessary authorizations.  Note: SDK uses gRPC protocol for communication. The SDK can comprise of several default funding strategies for payment channels. It can also allow the developer to implement their strategies, providing completely control over tokens and service payments. The SDK, along with the CLI, simplifies the process of fetching the latest service specification for dependent services, and compiles the proto definitions for efficient use of service. The preliminary version of a Python SDK, which is functional and is the basis for the SDK tutorial has resulted in number of design constrains. Note: Work is also proceeding on an SDK for Javascript. We intend to support most popular languages and welcome third party contributions for people’s favourite languages. As these SDKs become stable we’ll update the SDK tutorial to include details for each programming language.'], ['How to update? Firstly, when a new update is available you have to download the files with the updated content from our Github. You can go ahead and build the site again locally as usual. If you only want the theme updates, simply delete your old theme folder and replace it with the new one.'], ['What is the SingularityNET Developer Portal Theme? The SingularityNET Developer Portal Theme is Jekyll theme created for project documentations. You can use it with GitHub and GitLab Pages as well as a standalone project.  Full Jekyll documentation  You can find full Jekyll documentation here.  Starting a local SingularityNET Developer Portal Installation and setup Please follow the setup section of the SingularityNET Developer Portal repository. Credits List of vendor assets we used to create this theme:  Bootstrap (MIT License) normalize.css (MIT License) jQuery (MIT License) jquery-match-height (MIT License) simple-icons (CC0-1.0 License) feather (MIT License) Montserrat (SIL Open Font License, 1.1) Noto Sans (Apache License, version 2.0) Source Code Pro (SIL Open Font License, 1.1)'], ['Add content Content should be in Markdown format and you shouldn’t remove .yml comments on top of the .md files, errors may occur if you remove them. Homepage In main index.md file you add your homepage documentation content. Don’t forget to setup variables on top of the file. We’ve already added all variables, all you have to do is to update them. Pages To add new pages just create new .md file with proper .yml comments on top of the file. Pages use default layout template. Basic example of default layout template can be found in default.md. 404 error page We have a custom 404 error page template. You can edit its content in 404.md. If you’re hosting your site on Apache Web Servers, we’ve already added custom .htaccess file to update path to your 404 error page.  Full 404 error page setup guide.  You can find full 404 error page setup guide here.', 'External and internal links All links on your website should link to internal pages. There’s few exception to this rule:  In content you can use an external links. On homepage header buttons you can use an external links but you have to set external_url to true. Same applies to author box on default and homepage layouts. In footer social list you have to use an external links.  Relative URLs If you link internal pages in your content you have to add baseurl prefix to your links. This applies only to sites which will not be deployed in root directory of your server.  Relative URLs configuration.  In ""Configuration"" section you can read more about relative URLs configuration.  Syntax Highlighting You can call out code or a command within a sentence with single backticks. The text within the backticks will not be formatted. To format code or text into its own distinct block, use triple backticks. Best example of this can be found here.', 'Furthermore, you can add an optional language identifier to enable syntax highlighting in your fenced code block. Best example of this can be found here. Examples To add example bar add following html above your code block. ```  Preview  ``` Callouts To add callout to your documentation simply add following html code. Choose between few variations:  Info: callout--info Warning: callout--warning Danger: callout--danger Success: callout--success  ```  Lorem ipsum dolor sit amet! Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.   Lorem ipsum dolor sit amet! Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.', 'Lorem ipsum dolor sit amet! Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.   Lorem ipsum dolor sit amet! Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.  ```  Lorem ipsum dolor sit amet!  Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.   Lorem ipsum dolor sit amet! Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.   Lorem ipsum dolor sit amet! Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.', 'Lorem ipsum dolor sit amet! Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.   Lorem ipsum dolor sit amet! Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.'], ['Introduction SingularityNET hosts the public community developer portal using Github pages, and Github automatically builds and deploys the site from the master branch. If you want to deploy a local or private copy, there are several options available. Web hosting providers (FTP) To upload a Jekyll site to a web host using FTP, simply run the JEKYLL_ENV=production jekyll build command and copy the generated _site folder to the root folder of your hosting account. GitHub Pages What are GitHub Pages?  GitHub Pages are public web pages for users, organisations, and repositories, that are freely hosted on GitHub’s github.io domain or on a custom domain name of your choice. Full GitHub Pages deployment guide.  We recommend you to read full GitHub Pages deployment guide here.  Set relative URLs properly!  Please take a look at Relative URLs part of ""Configuration"" section before you deploy your site.', 'Build site with environment variable!  Please build your site with proper environment variable before you deploy. Your build command should look like this JEKYLL_ENV=production jekyll build.  User and Organisation Pages User and organisation pages live in a special GitHub repository dedicated to only the GitHub Pages files. This repository must be named after the account name. For example, @mojombo’s user page repository has the name mojombo.github.io. Content from the master branch of your repository will be used to build and publish the GitHub Pages site, so make sure your _site directory content is stored there. Project Pages Unlike user and organisation pages, project pages are kept in the same repository as the project they are for, except that the website content is stored in a specially named gh-pages branch or in a /docs folder on the master branch.', 'Content from the gh-pages branch or /docs folder on your master branch of your repository will be used to build and publish the GitHub Pages site, so make sure your _site directory content is stored there. Output will become available under a subpath of your user pages subdomain, such as username.github.io/project (unless a custom domain is specified). GitLab Pages What are GitLab Pages?  With GitLab Pages you can create static websites for your GitLab projects, groups, or user accounts. Connect as many customs domains as you like and bring your own TLS certificate to secure them. Full GitLab Pages deployment guide.  We recommend you to read full GitLab Pages deployment guide here.  Set relative URLs properly!  Please take a look at Relative URLs part of ""Configuration"" section before you deploy your site. Build site with environment variable!  Please build your site with proper environment variable before you deploy.', 'Your build command should look like this JEKYLL_ENV=production jekyll build.  User and Organisation Pages User and organisation pages live in a special GitLab repository dedicated to only the GitLab Pages files. This repository must be named after the account name. For example, if you create a project called john.gitlab.io under your username, john, your project URL will be https://gitlab.com/john/john.gitlab.io. Once you enable GitLab Pages for your project, your website will be published under https://john.gitlab.io. Content from the gl-pages branch of your repository will be used to build and publish the GitLab Pages site, so make sure your _site directory content is stored there. Project Pages Unlike user and organisation pages, project pages are kept in the same repository as the project they are for, except that the website content is stored in a specially named gl-pages branch.', 'Content from the gl-pages branch of your repository will be used to build and publish the GitLab Pages site, so make sure your _site directory content is stored there. Output will become available under a subpath of your user pages subdomain, such as username.gitlab.io/project (unless a custom domain is specified).'], [""Are you ready to contribute to SingularityNET? We'd love to have you on board, and we will help you as much as we can.  Questions and help This is our guideline for Issues and Bugs and for Feature Requests. You can meet and chat with other developers via the following channels: * Developer Telegram * Developer Forum Read more about our developer community here Issues and Bugs If you find a bug in the source code or a mistake in the documentation, you can help us by submitting a ticket to our GitHub issues. Even better, you can decide to submit a pull request to our projects if you decide to fix it. Please see the Submission Guidelines below. Feature Requests You can request a new feature by submitting a ticket to any of our repositories in the issues tab. For example, if you would like to give feedback about our Developer Portal, please do that here. If you would like to implement a new feature then consider what kind of change it is:"", '-   Major Changes that you wish to contribute to the project should be discussed first. Please open a ticket which clearly states that it is a feature request in the title and explain clearly what you want to achieve in the description, and the developers team will discuss with you what should be done in that ticket. You can then start working on a Pull Request. -   Small Changes can be proposed without any discussion. Open up a ticket which clearly states that it is a feature request in the title. Explain your change in the description, and you can propose a Pull Request straight away. Submission Guidelines Submitting an Issue Before you submit your issue, please first search the archive. It could be that your question was already answered or the issue was already reported. If your issue appears to be a bug, and has not been reported, open a new issue. Help us minimize the effort we need to take to fix issues and adding new features by not reporting duplicate issues.', ""Providing the following information will increase the chances of your issue being dealt with quickly:  Overview of the issue - If an error is being thrown, a stack trace helps. Motivation for or Use Case - Explain why this is a bug for you. Reproduce the error - An unambiguous set of steps to reproduce the error. Related issues - Has a similar issue been reported before? Suggest a Fix - If you can't fix the bug yourself, perhaps you can point to what might be causing the problem (line of code or commit). Project Version(s) - Is it a regression? Operating System - Indicate the used operating system.  Submitting a Pull Request Before you submit your pull request consider the following guidelines:  Search GitHub for an open or closed Pull Request that relates to your submission. Fork our repository and make your changes. Include appropriate test cases. Follow our Coding Rules. Ensure that all tests pass.  Commit your changes using a descriptive commit message that follows our"", 'commit message conventions. shell git commit -a Note: the optional commit -a command line option will automatically ""add"" and ""rm"" edited files.   In GitHub, send a pull request to the original repository.   If we suggest changes then:  Make the required updates. Re-run all the tests on your sample generated project to ensure tests are still passing. Rebase your branch and force push to your GitHub repository (this will update your Pull Request).    That\'s it! Thank you for your contribution! Resolving pull request conflicts Sometimes your PR will have merge conflicts with the original repository\'s master branch. There are several ways to solve this but if not done correctly this can end up as a true nightmare. So here is one method that works quite well.   First, fetch the latest version from the original repository sh git fetch original_repository_git_url   Merge your changes with the latest changes from the original repository. sh git merge FETCH_HEAD   Commit and push your changes.', 'sh git add. git commit -a git push   Coding Rules To ensure consistency throughout the source code, keep these rules in mind as you are working:  All features or bug fixes must be tested by one or more tests. The project must have unit tests and integration tests to all features. Code files must be formatted using default code style of each used language. All code files must be well documented.  Git Commit Guidelines Please ensure to squash unnecessary commits so that your commit history is clean. Commit Message Format We prefer well formatted commit messages - it makes it easier to understand what was done and why it was done, and it helps inform our decisions to accept your PRs or to request for a change. Each commit message consists of a header, a body and a footer. ```      ```  Any line of the commit message cannot be longer 100 characters! This allows the message to be easier to read on GitHub as well as in various git tools.  ### Header', 'The header contains a succinct description of the change:  -   use the imperative, present tense: ""change"" not ""changed"" nor ""changes"" -   don\'t capitalize first letter -   no dot (.) at the end  ### Body If your change is simple, the body is optional. Just as in the header, use the imperative, present tense: ""change"" not ""changed"" nor ""changes"". The body should include the motivation for the change and contrast this with previous behavior.  ### Footer The footer is the place to reference GitHub issues that this commit **Closes**.  You **must** use the [GitHub keywords](https://help.github.com/articles/closing-issues-via-commit-messages) for automatically closing the issues referenced in your commit.  ### Example For example, here is a good commit message:  ``` upgrade to Python 3.6.1  upgrade the project builds to use the new Python 3.6.1,', 'see https://www.python.org/download/releases/  Fix #1234 ```  ## Developer Portal If you would like to contribute by helping us improve, expand, or otherwise enhance the SingularityNET Developer Portal you are welcome to do so. You can send a PR for simple changes, or first open an issue for big changes [here](https://github.com/singnet/dev-portal/issues). To find an overview of how this developer portal works, please click [here](/docs/contribute).'], [], ['Introduction _config.yml stores configuration data. Many of these options can be specified from the command line executable but it’s easier to specify them here so you don’t have to remember them.  Please stop and re-run jekyll serve command after you change configuration file!  Master configuration file contains global configurations and variable definitions that are read once at execution time. Changes made to config.yml during automatic regeneration are not loaded until the next execution.  Hosting If you’re deploying to server where your site is not going to be in root directory, you should setup baseurl variable. For example, if your site is going to be stored on URL that looks like this http://example.com/project, you’ll have to update your baseurl variable and it should look like this: yml snet:   baseurl: /project  Build site with environment variable!  When you run jekyll serve, your baseurl variable shouldn’t render at all in any pages.', 'We’ll set Jekyll to only render baseurl variable when its environment is set to production. So then, how do you get the baseurl variable to only show up on a production environment? When building your Jekyll project with jekyll build, you’ll want to prefix it with JEKYLL_ENV=production so the complete command looks like this one: JEKYLL_ENV=production jekyll build Color themes The SingularityNET Developer Portal Theme supports a few color themes:  blue (default SingularityNET theme) green purple red yellow  You can update your color_theme variable in _config.yml to see changes. ```yml snet:   color_theme: green ``` Header Logo with text If you need logo as text, update text variable and leave image empty. yml snet:   header:     logo:         text: Project name         image: Logo with image', ""If you need logo as image, update image variable and set it to true and leave text empty. To set your custom logo image just upload it in place of logo.png here /theme/assets/images/layout/logo.png. ```yml snet:   header:     logo:         text:         image: true ```  Recommended logo image size.  Recommended logo image size is 400px x 178px. With this size you are sure you'll have retina ready logo image.  Navigation To add new items in main navigation you have to setup nav variable in _config.yml. Add as many items as you need. ```yml snet:   header:     nav:         - item_name: Item 1           item_url: /example-url-1         - item_name: Item 2           item_url: /example-url-2 ``` Footer Logo with text"", ""If you need logo as text, update text variable and leave image empty. ```yml snet:   footer:     content:         logo:             text: Project name             image: ``` Logo with image If you need logo as image, update image variable and set it to true and leave text empty. To set your custom logo image just upload it in place of logo-footer.png here /theme/assets/images/layout/logo-footer.png. ```yml snet:   footer:     content:         logo:             text:             image: true ```  Recommended logo image size.  Recommended logo image size is 400px x 178px. With this size you are sure you'll have retina ready logo image.  Copyright If you need to setup new footer copyright text, update copyright variable in your _config.yml file. ```yml snet:   footer:     content:         copyright: Copyright © 2017."", '- Project name All rights reserved. ``` Social list To properly setup social list update social_list variable in _config.yml. Add as many items as you need. At the bottom of the “Getting Started” section you can find a list of icons you can use in this list. Update network_name variable to add a proper icon. ```yml snet: footer:   social_list:       - network_name: facebook         profile_url: http://example.com       - network_name: twitter         profile_url: http://example.com       - network_name: instagram         profile_url: http://example.com       - network_name: youtube         profile_url: http://example.com ``` Google Analytics To activate Google Analytics you have to update _config.yml with GA tracking code. You can do that with tracking_code variable. ```yml snet:   google_analytics:     tracking_code: UA-XXXXXX-X ```', 'Build site with environment variable!  When you run jekyll serve, your Google Analytics tracking code shouldn’t render at all in any pages.  The reason for this is if you visit your Google Analytics account, you’ll see a bunch of visits from localhost:4000 or 127.0.0.1:4000 depending on the type of operating system you’re developing your Jekyll project on. This can potentially muddy up your analytics, so to mitigate this problem, we’ll set Jekyll to only render Google Analytics when its environment is set to production. So then, how do you get the analytics to only show up on a production environment? When building your Jekyll project with jekyll build, you’ll want to prefix it with JEKYLL_ENV=production so the complete command looks like this one: JEKYLL_ENV=production jekyll build Disqus comments To activate Disqus commenting system you have to update _config.yml with the Disqus forum shortname.', 'You can do that with disqus_forum_shortname variable. Comments are available only on default page layout and you have to enable them on new pages with comments: true variable. Currently, we have integrated Discourse comments into our SingularityNET Developer Portal which link directly to topics created on our forum. ```yml snet:   comments:     disqus_forum_shortname: ```  Build site with environment variable!  When you run jekyll serve, your Disqus commenting system shouldn’t render at all in any pages.  We’ll set Jekyll to only render Disqus commenting system when its environment is set to production. So then, how do you get the Disqus commenting system to only show up on a production environment? When building your Jekyll project with jekyll build, you’ll want to prefix it with JEKYLL_ENV=production so the complete command looks like this one: JEKYLL_ENV=production jekyll build Favicon To change favicon just replace /favicon.', ""with your new icon. Make sure it is in .ico format. Dimensions should be 16px x 16px.  Favicon .psd file included!  We've included .psd file with pre-made favicon in /designs folder of your theme.""]]","The SingularityNET Marketplace is a decentralized application that allows users to browse and interact with AI services through a web interface. It handles payment, service ratings, and integrates with the SingularityNET curation service. The Marketplace is curated by the SingularityNET Foundation and is currently in beta. Users can call services through the Marketplace by installing an Ethereum browser extension like MetaMask. The Marketplace has requirements for service authors to ensure their services are visible to others. SingularityNET supports multiple programming languages and AI frameworks. The Developer Portal provides documentation and guidelines for writing and integrating new AI services. The SingularityNET Developer Portal Theme is a Jekyll theme for project documentation. Users can contribute to SingularityNET by submitting issues, bug reports, or feature requests. The platform can be deployed on GitHub Pages or GitLab Pages. The configuration file (_config.yml) contains various settings for customization, including color themes, logos, navigation, footer, Google Analytics, Disqus comments, and favicon."
4,docs/ai-developers,"[['Naming standards Currently, a lot of flexibility is provided as to how entities in SingularityNET are defined by naming standards. Initially, the naming standard can result in difficulty to recognize between capitalization and separation of words in names. But these named standard is proposed to be implemented within the code, so that the smart contracts and the software can enforce the named standard definition efficiently in SingularityNET. This following section describes the naming standards for your reference. Service URI A service URI consists of three things:  Organization name Service name  e.g. snet/face-detect Here snet is the organization, and face-detect is the service name. Service authors should use lowercase alphanumerics, for each of these components. Multiple word components should be slugified with dashes (wikipedia definition of ""slug"") (i.e. dashes should separate the words). This is analogous to a URL on the web.', 'A domain name is case insensitive, and while a URL path can use capitalisation, many web applications will treat these paths as case insensitive. Service Display Name The service metadata can specify a display name for showing in the Marketplace and in other UIs and it should remain similar to the service name used in the URI. Internationalization and UTF-8 These fields are 8bit characters compliance, and can support UTF-8. These fields are not currently tested and supported in the tooling yet. Note Naming standard for other languages are required, when you attempt to support these fields. Service Tags Tags should follow the style of popular sites like Stack Overflow). The service tags are defined in  lowercase slugified words, e.g. example-tag tags-are-great opencog artificial-neural-network etc.'], [""Platform Development This documentation is intended for developers who want to work on the SingularityNET platform itself. While we'll happily engage with constructive suggestions for improvement, if you're submitting a substantial change of how things work you'd be best off submitting an issue with your proposal to see if it aligns with the direction we're planning to take SingularityNET in.  Deploying a local development instance of SingularityNET Full multiparty escrow example - #1a Full multiparty escrow example - #1b Full multiparty escrow example - #2""], ['../../tutorials/client/java/index.md'], ['The SingularityNET Registry is an ERC-165–compliant smart contract on the Ethereum Blockchain that stores organizations, services, and type repositories. AI developers use the Registry to announce details of their services, and consumers use the Registry to find the services they need. When a user searches for a service in the Marketplace DApp, it reads details of the services from the Registry, which also allows tagging of services and type repositories to enable searching and filtering. The Registry provides all the information needed to find and interact with AI services on the platform, either by listing the information in full or, when it is too long, by listing the IPFS hash. The source, ABI, and deployment information for the Registry is located in the singnet/platform-contracts repo. Interface The Registry interface, IRegistry, is a full specification of the functionality of the Registry. The Registry is published alongside its interface located in IRegistry.sol.', 'The interface contains natspec-compliant documentation on all functions and developers should import and target the interface instead of the implementation. The registry implements the interface and also fully supports ERC-165. Data Model The Registry stores four main pieces of data: Organizations, Services, Type Repositories, and Tags. It supports CRUD on all of these and contains a number of view functions for retrieving data. Organization An organization is an umbrella for services to be grouped under and is at the top of the Registry’s data hierarchy. Service developers can (and should) register an organization and then put all of their services underneath it. An organization registration record has a name, an owner address (in the identity sense), a collection of member addresses, a collection of services. Its Registry entry contains a name, members, and IPFS hash.', 'The IPFS hash is the link to the metadata file on IPFS, this file has all the necessary information about the recipient address for payment and the storage details to keep track of all off-chain channel state. Services and type repositories registered under a given organization are said to be owned by that organization. The list of members is a primitive access-management structure. Members of an organization cannot change the organization owner or delete the organization or even update the metadata, members can however create, update and delete services under an organization. Organization metadata is described in detail here. Service A service represents a single AI algorithm. Its Registry entry contains all the necessary information for a consumer to call that AI service. The entry contains a name, tags, and IPFS hash. The name is an identifier for discoverability, the tags help a customer find a service without knowing its name, and the IPFS hash is the link to the metadata file on IPFS.', 'DApps and smart contracts can use the listServicesForTag view function to discover Services. Contract Addresses Click here Service Metadata All service metadata is stored off-chain in IPFS for performance and gas-cost reasons. This metadata includes * basic information such as version number, service name, description, etc.; * code-level information for calling the service, such as encoding (protobuf or JSON) and request format (gRPC, JSON-RPC or process); * A list of daemon endpoints, aggregated into one or more groups; * pricing information; and * an IPFS hash for the service API model. * Service metadata is described in detail here. Type Repository A type repository is a Registry entry where a service developer lists service metadata, such as the service model and the data types used. The entry contains a name, some tags, a path, and a URI. The name and tags are for discoverability, the path is an optional identifier for the', 'organization’s internal management, and the URI allows the client (whether an end user or an application making calls through the SingularityNET SDK) to find the metadata. DApps and smart contracts can use the listTypeRepositoriesForTag view function to discover AI services. The URI is an IPFS hash, and the hosting itself can be done by either SingularityNET, the service developer, or any IPFS pinning service, such as Infura. Tags Tags are completely optional but recommended for discoverability. Services and Type Repositories can be associated with tags by using the relevant Registry methods such as addTagToServiceRegistration. After that, the tags are displayed and searchable on the DApp. Thanks to a reverse index built into the Registry contract, other smart contracts can also search the Registry directly. This is the foundation for the “API of APIs” functionality discussed below. DApp Integration The SingularityNET DApp is essentially a rich Registry explorer.', 'It loads the Registry and generates UI for playing with the Services and Type Repositories registered in it. CLI Integration The SingularityNET CLI has all the tooling necessary to call any of the Registry methods. Please see the CLI documentation'], ['Publishing Organization on Blockchain using snet-cli Setting Metadata Create an Identity in snet-cli for Mainnet, if you already have an account with ether , then you can use it , as an example sh snet identity create test-user key --private-key <PVT-KEY> --network mainnet Add the organization name, id and the type of organization test-org-name is the organization name and test-org-id is the organization id.  sh snet organization metadata-init test-org-name test-org-id individual The following code snippet is included in the metadata file: ```json     ""org_name"": ""test-org-name"",     ""org_id"": ""test-org-id"",     ""org_type"": ""individual"", ``` Add in description about your organization sh snet organization metadata-add-description [-h] [--description DESCRIPTION]                                            [--short-description SHORT_DESCRIPTION]                                            [--url URL]                                            [--metadata-file METADATA_FILE] Example', 'sh snet organization metadata-add-description --description ""Describe your organization details here "" --short-description  ""This is short description of your organization"" --url ""https://anyurlofyourorganization"" the below will be added in to the metadata file  json     ""description"": {         ""description"": ""Describe your organization details here "",         ""short_description"": ""This is short description of your organization"",         ""url"": ""https://anyurlofyourorganization""     }, Add in Recipient and group details Use the same endpoint mentioned in the previous step, to setup the etcd cluster.   groups : Multiple groups can be associated with an organization, one payment type is associated with every group. payment_address : Address of the Service provider who would receive the payment payment_channel_storage_type : Type of storage to manage payments ( For Example ETCD ) endpoints : Storage end points for the clients to connect. sh', 'snet organization add-group <group_name> <wallet_address> <etcd-end-point> Example  sh snet organization add-group default_groups 0x06A1D29e9FfA2415434A7A571235744F8DA2a514 https://your-etcdendpont:2379 This would append the below to the json ```json ""groups"": [         {             ""group_name"": ""default_groups"",             ""group_id"": ""gz/+/M9l/qxpfNzPn+T2XmTSPMKyphYyxSsQSPhEJXA="",             ""payment"": {                 ""payment_address"": ""0x06A1D29e9FfA2415434A7A571235744F8DA2a514"",                 ""payment_expiration_threshold"": 100,                 ""payment_channel_storage_type"": ""etcd"",', '""payment_channel_storage_client"": {                     ""connection_timeout"": ""100s"",                     ""request_timeout"": ""5s"",                     ""endpoints"": [                         ""https://your-etcdendpont:2379""                     ]                 }             }         }     ] ``` Add in any images related to your organization sh snet organization metadata-add-assets [-h] [--metadata-file METADATA_FILE] ASSET_FILE_PATH ASSET_TYPE Example sh snet organization metadata-add-assets image.png  hero_image Appends the following snippet code to the json script ```json     ""assets"": {         ""hero_image"": ""QmT3WWHEVsdQw5dD9TB4e1Xej2MfcQNrQS8FAHwBepG3HD/image.png""     }, ``` Add in any contact details related to your organization sh', 'snet organization metadata-add-contact [-h] [--phone PHONE] [--email EMAIL]                                        [--metadata-file METADATA_FILE]                                        contact_type Example sh  snet organization metadata-add-contact --phone 123456789 --email yourorg@yourorg support Appends the following snippet code to the json script ```json     ""contacts"": [         {             ""contact_type"": ""support"",             ""email_id"": ""yourorg@yourorg"",             ""phone"": ""123456789""         }     ], ``` Now check the metadata file created  sh cat organization_metadata.json Publish the organization Ensure that you have an account with Ether to perform update/delete/add services for a particular organization. Note Only the owner is eligible to modify the metadata of an organization. sh snet organization create mozi <addressofMember1>,<addressOfMember2> See the CLI documentation for full details of actions the tool allows.'], ['SDK in JAVA SDK in Python SDK in NodeJS  All SDKs provided adhere to the same design standard and strategy Note:  According  to the design pattern for the  SDK modules such as functionality, need to be available in all programming languages, such as Java, Python and NodeJS.  The SDK can include several default funding strategies for payment channels, but allows and supports the developer to implement funding strategies for payment channel of their own, to control over tokens and service payments. The SDK, in combination with the CLI, simplifies the process of fetching the latest service specification for dependent services, and compiles the proto definitions, so that the services can be invoked with minimal fuss. Currently, a fully functional a preliminary version of a Python SDK is available, which forms the basis for the SDK tutorial, but has  some design improvements.', ""Work is in process towards an SDK for Javascript, and intend to support other popular languages and welcome third party contributions for people's favourite languages. As these SDKs become stable the SDK tutorial will be periodically updated to to include details supporting each programming language.""], ['Earnings Once your service has been published on the Marketplace its available for all to use. You will start earning AGIX tokens as people interact and purchase your service. The AGIX tokens thus earned are captured in the payment channel set up between the user of the service and the Payment Address that has been configured in the organization The payment channel storage section has in depth explantion of how this works. Claiming AGIX Tokens  AGIX tokens earned are availabe in the channel created between the user and the Payment address configured in the Organization Only the user who operates the Payment address can claim tokens Tokens can be claimed by using the snet-cli or the publisher portal'], ['Overview The SingularityNET network allows developers to register their AI services on an open marketplace and charge for access. Though the expectation is that service consumers will primarily call services from code, the SingularityNET Dapp offers a rich UI/UX for people to explore the services offered on the network.  Providing an interface for consumers to interact with the service on the marketplace is a big driver for demand.  Core Tenets  Service developers are able to craft a custom UI locally Service developers are able to register their custom UIs thru the publisher portal Custom UIs handle collecting parameters and displaying results, while the SingularityNET Dapp itself handles the service request/response flow SingularityNet storybook enables custom UIs to match the overall style and aesthetic of the SingularityNET Marketplace.   Approach Explore SingularityNet storybook SingularityNet storybook is a UI component explorer for service developers.', 'This lists all common components used in the marketplace and can be reused for your service. Build component locally   Download the snet-dapp code sh     git clone git@github.com:singnet/snet-dapp.git     cd snet-dapp     npm install     cp .env.sandbox .env   Update .env file  REACT_APP_SANDBOX_SERVICE_ENDPOINT - The endpoint of the service running locally. snetd defaults to http://localhost:8088. REACT_APP_SANDBOX_ORG_ID - The org_id to which the service belongs. This value will be used for registering the custom UI REACT_APP_SANDBOX_SERVICE_ID - The service_id of the service. This value will be used for registering the custom UI      Start the AI service locally along with the snet daemon. Make sure the blockchain is disabled in the daemon configuration.    Building the custom UI  Make sure you are inside the repo directory.', 'Check if you have an executable file protoc-gen-ts in the path ./node_modules/.bin/. Else run npm i -D ts-protoc-gen  Generate js stubs from .proto files.      For the custom UI to talk to the services on SingularityNET platform via the DApp, we are using gRPC-web by improbable-eng. Apart from the steps mentioned at the official documentation to generate js stubs from .proto definitions, you also need to provide the namespace_prefix flag to the generator. Here is an example which illustrates the usage     sh     protoc \\     --plugin=protoc-gen-ts=./node_modules/.bin/protoc-gen-ts \\     --js_out=import_style=commonjs,binary,namespace_prefix=<uniq_name_space>:. \\     --ts_out=service=true:. \\     example_service.proto uniq_name_space should be a combination of package_name + org_id + service_id.', ""For the following proto file with org_id=snet and service_id=example-service the namespace_prefix would be example_service_snet_example_service.  PS: All the - should be replaced by _ The above script will generate four files. Copy the files *pb.js and *pb_service.js into your component's folder and ignore the rest. Also at the top of generated files, add /**eslint-disable */ You need to build the custom UI following the steps Create a new directory named after the org-id to which this service belongs inside src/assets/thirdPartyServices. It could be possible that the directory already exists, in which case you can use it instead of creating a new one. Create a new directory named after the service-id under the newly created directory in the above step e.g. for a service with org-id: snet and service-id: example-service you will have to do the following assuming you are at the root of the snet-dapp sh"", 'cd src/assets/thirdPartyServices     mkdir snet     cd snet     mkdir example_service     cd example_service Put the all the resources used by the custom UI under this directory including the js stubs       Register the custom UI - Add an entry for the new service in src/assets/thirdPartyServices/index.js if it does not already exist. Add the following line towards the end of the file. Make sure to replace orgId, serviceId and CustomUIComponent accordingly.      sh         thirdPartyCustomUIComponents.addCustomUIComponent(orgId, serviceId, CustomUIComponent);   Run the DApp - Assuming that the snet daemon is running on port 8088, running the bellow commands should bring up the DApp in sandbox mode for local development.     sh     npm run sandbox'], ['Page settings layout: default keywords: intro concepts comments: false  Service The platform\'s primary reason for existence is to allow a diverse collection of AI services to be bought and sold via a distributed marketplace. Anyone can publish the availability of their machine learning method, or integrated AI solution, and allow clients to interact with and pay for them directly. These services are primarily meant to be AI or machine learning related, but there is no intrinsic limitation to what type of service can be offered. Indeed, the foundation or the community may end up implementing utility and adaptor services (such as image conversion) to allow services be composed more easily. A ""service"" is defined through it\'s specification and it\'s metadata. Service Specification (Protocol Buffer Definition)  Services define their API using protocol buffers. This allows SingularityNET clients to determine the request/response schema programmatically. The first step in setting up a service on the SingularityNet Platform is to define the service definition via protocol buffers.', 'A sample proto file is available here  Service Metadata The service metadata is the off-chain description of a SingularityNET service and is, by default, hosted on the SingularityNET IPFS cluster. To use a service, the client needs to know the following: - The service metadata - The address of Multi-Party Escrow (MPE) contract Fortunately, the latter is included in the metadata. The daemon which allows access to the service, needs information about the metadata to configure the payment systems. There are three ways of providing metadata details to the clients and the daemons: - Simple JSON file - IPFS hash that points to the JSON metadata - Name of service in the Registry - this can be resolved to an IPFS hash, pointing to the metadata, through the Registry’s getMetadataIPFSHash method. Note: The client using the mpe_address from the metadata should not adhere to this as a primary source of information, for the sake of security.', 'The client should check that this address corresponds to the expected mpe_address. Important: Client must check that the hash of the metadata corresponds to the IPFS hash. Otherwise, If the IPFS client is compromised, the client system can become vulnerable to attack. Note: By default, the snet-cli adheres to this verification. Note: The service provider needs to publish the details about the service in the Blockchain. As a consumer, you may go the Blockchain or the Marketplace portal where the services are deployed. Details like the price of the service, image depicting/related to the service, service type, description, the endpoint and how to make a request. Please note that - Singularity platform works on gRPC. Whenever you need to call you need a protofile. - File management system such as IPFS stores the location of the hash and points to the associated protofile.     The IPFS can include a file and the same file returns same hash. Metadata Overview ```', '{     ""version"": 1,     ""display_name"": ""Entity Disambiguation"",     ""encoding"": ""proto"",     ""service_type"": ""grpc"",     ""model_ipfs_hash"": ""Qmd21xqgX8fkU4fD2bFMNG2Q86wAB4GmGBekQfLoiLtXYv"",     ""mpe_address"": ""0x34E2EeE197EfAAbEcC495FdF3B1781a3b894eB5f"",     ""groups"": [         {             ""group_name"": ""default_group"",             ""free_calls"": 12,             ""free_call_signer_address"": ""0x7DF35C98f41F3Af0df1dc4c7F7D4C19a71Dd059F"",             ""daemon_address "": [""0x1234"", ""0x345""],', '""pricing"": [                 {                     ""price_model"": ""fixed_price"",                     ""price_in_cogs"": 1,                     ""default"": true                 }             ],             ""endpoints"": [                 ""https://tz-services-1.snet.sh:8005""             ],             ""group_id"": ""EoFmN3nvaXpf6ew8jJbIPVghE5NXfYupFF7PkRmVyGQ=""         }     ],     ""assets"": {         ""hero_image"": ""Qmb1n3LxPXLHTUMu7afrpZdpug4WhhcmVVCEwUxjLQafq1/hero_named-entity-disambiguation.png""     },     ""service_description"": {         ""url"": ""https://singnet.github.io/nlp-services-misc/users_guide/named-entity-disambiguation-service.html"",', '""description"": ""Provide further clearity regaridng entities named within a piece of text. For example, \\""Paris is the capital of France\\"", we would want to link \\""Paris\\"" to Paris the city not Paris Hilton in this case."",         ""short_description"": ""text of 180 chars""     },     ""contributors"": [             {                 ""name"": ""dummy dummy"",                 ""email_id"": ""dummy@dummy.io""             }         ] } ```', 'For more information about how to viewing the metadata using the python module, CLI documentation'], [""This tool is used extensively in our tutorials and guides, to install it, follow the setup guide. See the CLI documentation for full details of actions the tool allows. Making a call to a SingularityNET service Step 1. Get some Ether Ether is used to pay for interactions on the block chain (known as gas). The transactions you make a call to SingularityNET are: - Transfer AGIX into the multi-party escrow account, - Create a payment channel for a service published in the SingularityNET registry, and - Transfer AGIX into the payment channel and set the timeout After that, you interact with the service directly and won't need to pay for further transactions unless you want add more AGIX or extend the timeout for the payment channel. So how do you get Ether? The mainnet requires you to buy or mine it, but we're going to use a test net for now. Specifically Ropsten."", 'Luckily for test networks you can go to a faucet to request some Ether for free. To use the faucet you need to create a wallet, and then provide them with your wallet\'s public address. Step 2. Get some AGIX We provide a faucet to get AGIX for either Ropsten or Kovan networks You\'ll need a github account to authenticate, and there after you can request AGIX every 24 hours.  Set an identity sh snet identity create user-ropsten mnemonic --mnemonic ""YOUR MNEMONICS"" --network ropsten snet identity user-ropsten Deposit in Escrow and Create a Channel sh snet account balance # check balance (all tokens belongs to this idenity) snet account deposit 0.000001 # Deposit Token to MPE and Open a payment channel to the new service: snet channel open-init <org_id> <group_name> 0.', '000001 +2days # Now open a Channel and transfer AGIX in to the Channel Make a call to a Service JSON parameters While protocol buffers are used for communication, call parameters are represented as JSON on the command line. There are three ways of passing this JSON: * via a cmdline parameter; * via JSON file; and * via stdin. For example, in this platform example we need to pass the following JSON as a parameter for the ""add"" method to our service: json {""a"": 10, ""b"": 32} We can use three ways: via cmdline parameter sh snet client call <org_id> <service_id> <group_name> add \'{""a"":10,""b"":32}\' via json file sh echo \'{""a"":10,""b"":32}\' > p.txt snet client call <org_id> <service_id> <group_name> add p.txt via stdin', 'echo \'{""a"":10,""b"":32}\' | snet client call <org_id> <service_id> <group_name> add Modifiers We\'ve implemented several modifiers for this JSON parameter in order to simplify passing big files and to have the possibility to pass binary data (and not only base64 encoded data). There are 3 possible modifiers: * file      - read from file; * b64encode - encode to base64; and * b64decode - decode from base64. For example, if you pass the following JSON as a parameter, then as an ""image"" parameter we will use the base64 encoded content of ""1.jpeg"" sh \'{""image_type"": ""jpg"", ""file@b64encode@image"": ""1.jpeg""}\' If we remove the b64encode modifier from the previous example, then we will pass 1.jpeg image in binary format without base64 encoding.   Modifiers', 'We\'ve implemented several modifiers for this JSON parameter in order to simplify passing big files and to have the possibility to pass binary data (and not only base64 encoded data). There are 3 possible modifiers: * file      - read from file; * b64encode - encode to base64; and * b64decode - decode from base64. For example, if you pass the following JSON as a parameter, then as an ""image"" parameter we will use the base64 encoded content of ""1.jpeg"" sh \'{""image_type"": ""jpg"", ""file@b64encode@image"": ""1.jpeg""}\' If we remove the b64encode modifier from the previous example, then we will pass 1.jpeg image in binary format without base64 encoding.'], ['To fulfill a request from a client to a service, a snet-daemon needs to store and process information about the service payment. This connection is called the payment channel. If there is only one service and corresponding snet-daemon the process is easy:  When payment passes a validation process, the payment channel is stored in an internal storage to be claimed when the service successfully accomplishes the request. The situation becomes more complicated if a service provides several replicas. In this case it is not possible to have several separated snet-daemons each of which has an independent internal storage.  One drawback of using a separated payment channel for each replica, is that it can be expensive from the gas consumption and time execution point of view, because each operation to open a channel requires it to be processed by the Blockchain. The other one is that such model is subject to an attack where the same payment can be used for services from different replicas.', 'This leads to a model where all snet-daemons for the same service should use the shared storage.  However, if only one instance of a storage is provided it can easily become a single point of failure for the whole system. When it fails, this leads to failure of all payments even when there are live replicas. Therefore, we are using distributed storage. There is plenty of available storage, and we just need to make the optimal choice. We are adhering to several criteria: According to CAP theorem, we only have a choice to select two out of three main guarantees: * Partition tolerance * Availability * Consistency We need a partition tolerance distributed storage to save system from network failures. Furthermore, we also need storage that provides strong consistency guarantees to avoid a situation where the same payment is used twice on different replicas. This does not mean that the availability guarantee is not important.', ""This means that if all but a few nodes of the distributed storage are still available, it will not be possible to read/write requests. This is a price we are paying in exchange for a strong consistency storage system. Lets strike out the availability guarantee and leave only partition tolerance and consistency:  Partition tolerance ~~Availability~~ Consistency  The new design now looks like this:  The current approach is fine, but it requires for a service owner not only to setup a snet-daemon for each replica, but also to deploy a separated distributed storage. This can be a rather tedious and complicated task. To avoid this, it would be good to incorporate the distributed storage nodes into snet-daemons so it would be the snet-daemon's task to run required distributed storage nodes:  Considered storages We are looking for a distributed storage with strong consistency guarantees which can be run by snet-daemon (e.g. be easily integrated into a Go program)."", 'Some of the storages that were considered are: | Distributed Storage                            |Language| Consensus|Embedded Server Support |------------------------------------------------|--------|----------|-------------------------------------------- |Etcd         | Go     | Raft     |native |Consul   | Go     | Raft     |ticket 467 |ZooKeeper| Java   | ZAB      |native Etcd was chosen because it is written in Go, and has out of the box embedded server support. This means that its nodes can be started and stopped by snet-daemon replicas. It is not clear whether it is possible to run a consul server agent from a Go application. A few examples (embedded-consul 1 2 just bundles the Consul as a binary package. Zookeeper is just written in Java and it requires to have an additional support to start Zookeeper nodes from Go. Note: all these storages use a quorum to get a consensus during leader election and values writings.', 'This means that if the number of failed nodes are more than half of all nodes, then the the cluster stops working. As it was described before, this is a cost for a distributed system to provide strong consistency guarantees. Etcd storage Running and accessing embedded etcd cluster Starting an etcd node requires at least the following parameters:  name: human-readable name for the node. listen-client-urls: list of URLs to listen on for client traffic listen-peer-urls: list of URLs to listen on for peer traffic initial-cluster: initial cluster configuration for bootstrapping, for example:   name1=http://AAA.BBB.1.1:2380,name2=http://AAA.BBB.1.2:2380 initial-cluster-token: initial cluster token for the etcd cluster during bootstrap  The following Go code is used to start etcd node and use etcd client: * etcd_storage_server.go * etcd_storage_client.go', 'There are some throughput tests which run several etcd nodes locally and measure number of writes, and compare and set requests per seconds. Note: because all etcd nodes were run locally, the results can be different from when each etcd node is ran on its own separated server. etcd cluster size According to the etcd FAQ it is suggested to have an odd number of etcd nodes in a cluster, usually 3 or 5. It also mentions that ""Although larger clusters provide better fault tolerance, the write performance suffers because data must be replicated across more machines."" Proposed solutions  The following solutions are based on the embedded etcd storage discussed in details in chapters below: * Command line etcd cluster creation * Fixed size etcd cluster * Incremental etcd cluster creation Command line etcd cluster creation This approach is to add a command line option to snet-cli which allows us to start an etcd instance as part of etcd cluster:', 'snet storage init --name name --token unique-token --client-url http://AAA.BBB.1.1:2379 --peer-url http://AAA.BBB.1.1:2380 --initial-cluster name1=http://AAA.BBB.1.1:2380,name2=http://AAA.BBB.1.2:2380  The list of client-urls then needs to be passed to each replica to have access to the etcd cluster storage. Fixed size etcd cluster This approach assumes that etcd nodes are started by replicas and that the size of etcd cluster is fixed. The initial configuration file contains a list of all replicas and information whether it should start etcd node or not: For example: | replica id | start etcd node| etcd node name | etcd node client url    | etcd node peer url     | |------------|----------------|----------------|-------------------------|------------------------|', '|  replica 1 |             yes|          node1 | http://AAA.BBB.1.1:2379 | http://AAA.BBB.1.1:2380| |  replica 2 |             yes|          node2 | http://AAA.BBB.1.2:2379 | http://AAA.BBB.1.2:2380| |  replica 3 |              no| |  replica 4 |             yes|          node3 | http://AAA.BBB.1.4:2379 | http://AAA.BBB.1.4:2380| |  replica 5 |              no| Such a configuration requires that all replicas which maintain an etcd node need to be started first to have a functional etcd cluster. Incremental etcd cluster creation approach Starting etcd cluster requires that initial size of the cluster was defined during cluster bootstrap.', 'It means that the cluster begins to work only when quorum number of nodes join the cluster. Suppose there are 3 replicas and they want to run 3 ectd nodes. When the first replica starts an etcd node, it is not able to write and read from the etcd because 2 more etcd nodes need to join the cluster. As an alternative, it is suggested that the first replica starts with etcd cluster which consists of only one etcd node. In this case it will be able to read and write to the etcd. When the second replica starts it can find the existing etcd cluster (using the address of the first replica) and just adds the second node to the cluster. This allows us to have a working etcd cluster even when only some of the replicas are running. Note: etcd has a Discovery Service Protocol. It is only used in the cluster bootstrap phase, and cannot be used for runtime reconfiguration.', 'The following algorithm describes the creating and updating of the etcd cluster during replica initialization based on an incremental approach. Input Each replica needs to have access to the following info which is provided during the replica starting: * etcd cluster token value * list of all replicas with corresponding values:   * replica id   * etcd node name   * etcd ip address   * ectd client and peer ports Cluster Configuration Table The table with the given columns will be maintained in etcd cluster: * replica id * timestamp * running etcd server node flag The last field indicates that a replica started an etcd server instance and that it had been alive at the time when the record to the Cluster Configuration Table was written. Replicas to etcd nodes correspondence Each replica can use a predefined function which returns the number of etcd nodes that are necessary to run for the given number of live replicas. The function can be described in pseudocode like:', 'numberOfEtcdNodes(numberOfReplicas) {     1, 2   -> 1     3, 4   -> 3     5, ... -> 5 } Detecting added and failed replicas It is suggested to use the heartbeat mechanism to detect failures in replicas. Each replica needs to repeatedly write a timestamp using the replica id as a key to the Cluster Configuration Table. When the difference between the current time and the timestamp of the replica is higher than a certain threshold, the replica is considered dead. Detecting failed etcd nodes etcd Admin API Documentation provides a REST api to check the health of an etcd node. Initial state The first initialized replica detects that there is no etcd cluster and starts an embedded etcd instance. Main loop Each replica reads the Cluster Configuration Table, checks the number of live replicas and calculates the number of required etcd nodes using the numberOfEtcdNodes(numberOfReplicas) function.', 'If the number of required etcd nodes is less than the current number of live etcd nodes, then only one replica with the lowest id that does not have a running embedded etcd node starts it and adds this node to the current cluster. There can be two results: * The embedded etcd is successfully run * The replica which starts the etcd misses the timeout and is considered dead If the etcd node initialization succeeds, the replica adds the record to the Cluster Configuration Table to let it know that it has running ectd node. In both cases the process can be just repeated as is.'], ['Publisher Portal Goal is to assist the developers easily publish and manage their organizations and services using the publisher portal. You can list your services on to the marketplace Dapp easily making it very simple for your users to search and use your service. On boarding an Organization Enter all relevant data to publish in your Organization through simple forms, which abstracts all the complexity using command line interface. Once the basic on boarding details are entered, a review is triggered for the Singnet Team, this is to ensure compliance with any legal procedures before on boarding any organization on to market place Dapp   Invite Workflow - Adding members to an Organization The platform provides a simple workflow to add new members, the owner just needs to add the email address of the member, the system sends invitation to the member based on accept invitation   and also ensures all the required details like (Wallet address) of the member are furnished when the invitation is accepted.    Publishing an Organization on Block Chain', 'Once details of an Organization are entered, a review is triggered, once approved by the Signet team, you can publish the organization through the portal.    Service listing Screen All services managed under your organization are listed here,  Only members belonging to the  Organization can view / add / modify / delete services.   Service metadata Screen Enter all relevant data required to publish your services  using a simple forms, which abstracts all the complexity experienced through command line interface.    Publishing a Service on a block chain OAfter entering all the details, a review process is triggered for the singularity team, to ensure the details are compliant with  legal procedures before on boarding any service on to market place Dapp.     Claim easily from Publisher portal Claims can now be availed using the publisher portal.'], ['The SingularityNET daemon is the adapter that a service can use to interface with the SingularityNET platform. In software architecture lingo, the daemon is a sidecar proxy, —a process deployed next to a core application (the AI service, in this case) to abstract away some architectural concerns such as logging and configuration as well as entire platform aspects, such as the interaction with smart contracts or even the decision to use the Ethereum Blockchain. The two key abstraction responsibilities of the daemon are payments and request translation. In order to authorize payments, the daemon interacts with the Multi-Party Escrow contract. Before invoking a service through SingularityNET, a consumer must have 1. funded the Multi-Party Escrow contract (see section on payments below) and 2. opened a payment channel with the recipient as specified by the service definition With each invocation the daemon checks for the following: 1. the signature is authentic, 2. the payment channel has sufficient funds, and', '3. the payment channel expiry is beyond a specified threshold (to ensure that the developer can claim the accrued funds). After performing the above checks, the request is proxied to the service. Besides, the daemon monitors the payment states of different clients.  After the requests are validated by the daemon, they are translated into the format recognizable by AI service. The daemon exposes a gRPC, so all requests are based on gRPC and protocol buffers, but it can translate requests to a few different formats, as expected by the service: in addition to gRPC/Protobuf, JSON-RPC and process fork–based services (executables to be executed on a per-call basis with the input parameters on standard input) are supported. This translation enables the usage of one consistent protocol  to communicate with any service on SingularityNET. The daemon and CLI also use gRPC and Protobuf for communication. One can deploy multiple instances of an AI service.', 'Each instance can have its own sidecar daemon, and all daemons are registered as endpoints in the Registry. When multiple instances are available, they can be grouped in to multiple instance groups (a typical reason for doing so would be to group instances in the same data center or cloud region). Daemons within the group coordinate to share payment status information through etcd. The daemon provides some additional deployment- and administration-oriented features: * SSL termination. This can be done either with a certificate and keyfile supplied by the service developer or with automatic certificates provided by Let’s Encrypt. * Logging to files, with log rotation and pluggable log hooks. Currently an email hook is provided, and an easy-to-use API is available for other hooks. * Metrics, monitoring, and alerts. The daemon collects metrics about request calls, which service owners can use to optimize their resource usage. It also monitors daemon and service events, providing configurable alerts via email or web services.', '* Rate limiting to prevent DoS attacks and to allow service owners to scale at their own speed and ability. The daemon uses the token bucket algorithm. * Heartbeat. A pull-based heartbeat service is provided, following the gRPC health checking protocol. The daemon will check that the heartbeat of the service is configured; this is used by monitoring services as well as the Marketplace DApp. The latest version is {{ data.versions.snet-daemon }}, and can be downloaded from the release page. Supported Service Types The daemon has been written to support a variety of service implementations. Currently, the daemon supports services that either:  expose a gRPC endpoint, expose a JSON-RPC endpoint, or executables called on a per-request basis with the input parameters on stdin  Note however that the daemon exposes a gRPC/gRPC-Web endpoint regardless of what type of service is paired with the daemon.', ""This means we have one consistent protocol to be used to communicate with any service on the SingularityNET network, while still allowing service authors to have flexibility in their implementations. Certain gRPC features such as streaming require the service itself to expose a gRPC endpoint with streaming RPCs. Also note that bi-directional streaming RPCs are only compatible with some gRPC clients (not gRPC-Web i.e. browser clients). Service Models As noted when discussing Services, the service API is defined using protobuf. SSL The daemon supports SSL termination using a developer-supplied certificate and keyfile. See our SSL guide for step-by-step instructions on how to set this up with Let's Encrypt. Authorisation and Payment Prior to invoking a service through the SingularityNET platform, a consumer must have: - Funded the Multi-Party Escrow contract; and - Opened a payment channel with the recipient as specified by the Organization metadata. With each invocation the daemon checks:"", ""- that the signature is authentic; - that the payment channel has sufficient funds; and - that the payment channel expiry is beyond specified threshold (to ensure that the service author can claim the accrued funds after delivering the service). After these checks are successful the request is proxied to the service. Configuration The daemon's behavior with respect to the service type, SSL, Blockchain interactions, etc. can be controlled via a configuration file, environment variables, and executable flags. See the daemon's README for a description of the available configuration keys and how they map to environment variables and runtime flags. Payment channel state The daemon stores the payment channel state in an etcddb cluster. This cluster can either be an embedded etcd instance that runs in connection with each snetd replica (default) or an externally configured cluster. This is detailed here. ETCD cluster.""], [""Troubleshooting Alerting mechanism - Emails Alerts Mainnet Alerts Alert messages are sent through the email Id : no-reply@signularitynet.io Subject : The service 'service-name' is terminated for Mainnet network What to do when I receive an alert?  Check whether the daemon end point heartbeats are healthy, and view the daemon logs Restart the daemon, and analyse why the daemon has suspended. Incorporate the post details in the document here as well.   How much time does it take for the service to become healthy on Dapp again? The platform uses exponential back-off retry to test the health of the service. Each time a health check fails, an email message is sent to Service developer ( progressive delay in the next health check ).  Note: The maximum time a test can take on the health service is 12hrs. How to configure service metadata to receive alerts ? Obtain the latest version of snet-cli and run the following command:"", 'snet service metadata-add-contributor <CONTACTNAME> <EMAILID> --metadata-file <MD_FILE> Your metadata snippet should look like the following: ``` ""contributors"": [            {                ""name"": ""dummy dummy"",                ""email_id"": ""dummy@dummy.io""            } ``` How to I configure the service heartbeat?  Refer to the documentation provided. or the service heartbeat implementation, follow the standard health checking protocol as defined in [gRPC Health Checking] (https://github.com/grpc/grpc/blob/master/doc/health-checking.md) Protocol link.   Note: The service must use the same proto and implement the heartbeat functionality. How to check or receive notification about certificate expiration ? Prior to the expiration of certificate, an email message is sent and a slack alert within 30 days. The email message is sent frequently until the certificate is renewed.  Note This task is performed once in three days.  Mainnet Alerts on Certificates', 'Alert messages are sent through the email Id : no-reply@signularitynet.io  Subject : certificates are about to expire for service %s for %s network. Ropsten Alerts on Certificates Alert messages are sent through the mail id : test-no-reply@singularitynet.io  Subject : certificates are about to expire for service %s for %s network. Common Setups NGINX Since there is no direct support for grpc-web(dapp)from nginx, we can make a below hack in the config file of the nginx to work with both grpc-web(dapp) and grpc(sdk,snet-cli) calls. server {     listen 1449 ssl http2;     server_name domain-name;     ssl_certificate pem-file; # managed by Certbot     ssl_certificate_key key-file; # managed by Certbot     include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot', ""ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot location / {  # ## Any request with the content-type application/grpc+(json|proto|customType) will not enter the ## if condition block and make a grpc_pass while rest of the requests enters into the if block ## and makes a proxy_prass request. Explicitly grpc-web will also enter the if block. #  if ($content_type !~ 'application\\/grpc(?!-web)(.*)'){     add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS';"", ""add_header 'Access-Control-Allow-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Content-Transfer-Encoding,Custom-Header-1,X-Accept-Content-Transfer-Encoding,X-Accept-Response-Streaming,X-User-Agent,X-Grpc-Web,content-type,snet-current-block-number,snet-free-call-user-id,snet-payment-channel-signature-bin,snet-payment-type,x-grpc-web';         add_header 'Access-Control-Max-Age' 1728000;         add_header 'Content-Type' 'text/plain charset=UTF-8';         add_header 'Content-Length' 0;     proxy_pass http://reroute_url; } grpc_pass grpc://reroute_url; }}  The above config works based on the content-type of the request."", 'Whenever the grpc-web(dapp) makes a call to nginx, the content-type would be application/grpc-web and this content-type is not been handled by nginx with grpc_pass. Hence, only those requests with grpc specified  content-type application/grpc+(proto|json|customType) works with grpc_pass while rest of the requests will work with proxy_pass. Setting up your own ETCD cluster To set up your own ETCD cluster please follow the link Certificates for ETCD To renew the ETCD Client Certificates for SNET Organisation: - Run the [et]cd-client-certificates-generation](https://eu-central-1.console.aws.amazon.com/codesuite/codebuild/projects/etcd-client-certificates-generation/history?region=eu-central-1) job. - This task generates the client-certificates in this path. For other Organizations, follow the below steps to regenerate the etcd client certificates. - Download the cfssl & cfssljson using the below commands', ""[curl -s -L -o cfssl] (https://pkg.cfssl.org/R1.2/cfssl_linux-amd64)  [curl -s -L -o cfssl] (https://pkg.cfssl.org/R1.2/cfssl_linux-amd64)  Copy the ca.pem, ca-key.pem, ca-config.json & client.json that you previously used for generating the etcd certificates. Run the below command to generate the client certificates.  How to deploy an Organization and a Service on Ropsten? Complete the following steps listed in the document  Common issues with Daemon start You need to specify a valid signer address, such as 'free_call_signer_address' as part of the curation process to support free calls” bash  snet service metadata-set-freecall-signer-address default_group $SIGNERADDRESS --metadata-file $MD_FILE"", ""Specify a valid private key 'pvt_key_for_metering' to include during the service publication process.” When you enable the free calls and Metering, specify the private key to initialize the Daemon Otherwise, the  Daemon sends the request to metering, which checks the associated public address mapped in the configuration of that Daemon. bash snet service metadata-add-daemon-addresses default_group $DAEMONADDRESS --metadata-file $MD_FILE Unable to create etcd client To learn about how to configure the etcd certificate, refer to the document for configuration with example.  Metering authentication failed. Please verify the configuration” When you enable the free calls and Metering, specify the private key to initialize the Daemon. The Daemon will initialize, only if the configured Pvt key config matches the public Address of the Daemon registered for metering. Daemon addresses are registered for a given Org, Group id  and service id . You need to re-publish the service again with the correct public address ."", 'Please use the  Following command to do so  snet service metadata-add-daemon-addresses default_group $DAEMONADDRESS --metadata-file $MD_FILE Common errors returned by the Daemon Payment signer is not valid for free calls Check if the port number of your daemon matches exactly to what was deployed on Service metadata. bash  snet service metadata-set-freecall-signer-address default_group $SIGNERADDRESS --metadata-file $MD_FILE Free call limit has been exceeded You have exceeded the number of permitted free calls. So, calls can now be done only using the paid mode alone   End point deployed from Service metadata should be assigned to the same port / domain the daemon is starting.   Rate limiting, too many requests to handle” The number of request has increased along with the rate limiting, either retry again later or configure your daemon for rate limiting  Unexpected payment type” The supported payment types are free-call / escrow ETCD client connection issues', '```bash github.com/singnet/snet-daemon/etcddb.getTlsConfig(0xc4207800c0, 0x1, 0x4)         /ext-go/1/src/github.com/singnet/snet-daemon/etcddb/etcddb_client.go:107 +0x3f6 ``` Please re check the etcd end point in organization metadata ,if the end point is valid , please check if you have the correct certificates ( for https connection) on your daemon config gRPC message size (RESOURCE_EXHAUSTED) If one (or more) of your components shows these kind of log: Daemon: level=warning msg=""gRPC handler returned error"" error=""rpc error: code = ResourceExhausted desc = Received message larger than max (5937252 vs. 4194304)"" SNET-CLI and/or your service\'s gRPC server: ```', 'Error: <_InactiveRpcError of RPC that terminated with:     status = StatusCode.RESOURCE_EXHAUSTED     details = ""Received message larger than max (5937252 vs. 4194304)""     debug_error_string = ""{""created"":""@1585584826.407968689"",""description"":""Received message larger than max (5937252 vs. 4194304)"",""file"":""src/core/ext/filters/message_size/message_size_filter.cc"",""file_line"":191,""grpc_status"":8}""  ```  Then you need to increase the MAX_MESSAGE_SIZE of the gRPC components, first set it in your Daemon by adding this key to its snetd.config.json: ""max_message_size_in_mb"": 10, Note: You can find out more about this key here. Next step is to increase the message size in your service\'s gRPC server: go server : = grpc.NewServer(         grpc.', 'SendMsgSize(10 * 1024 * 1024),         grpc.MaxRecvMsgSize(10 * 1024 * 1024), ) python server = grpc.server(futures.ThreadPoolExecutor(max_workers=max_workers), options=[         (\'grpc.max_send_message_length\', 10 * 1024 * 1024),         (\'grpc.max_receive_message_length\', 10 * 1024 * 1024)]) A practical python example can be found here. Common Daemon warnings (in the logs) “Unable to publish metrics” If you make calls using SDK / snet-cli, the issue is resolved once if the daemon supports metering. Invalid hex address specified/missing for \'authentication_address\' in configuration , you cannot make remote update to current configurations” Ignore: This was more towards the operator UI use case, need modification in the next release.  msg=""error determining current block"" error=""403 Forbidden Add the the following link:', '""ethereum_json_rpc_endpoint"": ""https://mainnet.infura.io/v3/e7732e1f679e461b9bb4da5653ac3fc2"" In your daemon configuration. Ideally  you should have your own project Id on infura.  How do I set up a new host ? Typically you will need to do the below  - Domain Name  - GPU/Without GPU - RAM Required - HD Required - Ports for public access - Public Key to setup the user - Certificates for HTTPS  How do I get the latest version of Daemon All latest released versions of Daemon are available here - Download the latest  - untar You need to manually configure the path to refer to this binary. How do I get the latest version of snet-Client pip install --upgrade snet-cli Note: manually configure the path to refer to this binary. When there is proto change?', 'Ensure that you re deploy the service with the latest proto  snet service metadata-init --metadata-file $MD_FILE `pwd`/$YOURGITREPONAME/$PATHFORSERVICESPEC ""$DISPLAYNAME"" --encoding proto --service-type grpc --group-name default_group Also make sure  your stubs are updated on the Dapp Components DAPP My Service is not visible on Dapp  Ensure the services have been published on the network for testing  After curation, the service becomes available on Dapp    Keep the below links for reference  Dapp for Ropsten: http://enhanced-marketplace.s3-website-us-east-1.amazonaws.com/ Dapp for Mainnet: http://beta.singularitynet.io/   How to make a call from the DAPP  Open the respective service’s page. In the Service Demo section, you will notice the Free calls pending count, provided  you have already logged in to the system.', 'Click on the RUN FOR FREE button. (If your free calls are exhausted, you will find options to create a wallet or to use your existing MetaMask wallet ) You will be taken to the service’s input screen. - Fill in the necessary details. - Click on INVOKE.   Note: Don’t close the application, until the results are displayed  on the same screen after service execution.  Where do I see the components I can reuse on Dapp  Check for the reusable components code here  => snet-dapp-monorepo/packages/shared/src/components. You could also run yarn storybook to view the demo of the components. While importing, import the components from => snet-dapp-monorepo/packages/dist/components.  How do I raise a Pull request for DApp  Raise pull requests using “snet-dapp-monorepo/development”. After merging in the development. It will be deployed to the ropsten network:http://enhanced-marketplace.', '3-website-us-east-1.amazonaws.com/  When does my Pull request gets merged to Master   If your changes are seen in ropsten.  Inform the concerned authority to merge the changes from development to master. This is then deployed to Mainnet network: http://beta.singularitynet.io/   Whom and How  do I reach out for help/Support Use the email tech-support@singularitynet.io for any questions / issues related to the platform.'], ['Page settings layout: default keywords: intro concepts comments: false  Set up  Python 3.6+ Node 8+ with npm SNET CLI libudev libusb 1.0   SNET Daemon  For example, installing the requirements using Ubuntu 18.04: ```sh sudo apt-get update sudo apt-get install wget git sudo apt-get install python3 python3-pip sudo apt-get install nodejs npm sudo apt-get install libudev-dev libusb-1.0-0-dev sudo pip3 install snet-cli !!! Get the latest snet-daemon from Github releases SNETD_VERSION=curl -s https://api.github.com/repos/singnet/snet-daemon/releases/latest | grep -oP \'""tag_name"": ""\\K(.*)(?="")\' cd /tmp wget https://github.', '/singnet/snet-daemon/releases/download/${SNETD_VERSION}/snet-daemon-${SNETD_VERSION}-linux-amd64.tar.gz tar -xvf snet-daemon-${SNETD_VERSION}-linux-amd64.tar.gz sudo mv snet-daemon-${SNETD_VERSION}-linux-amd64/snetd /usr/bin/snetd ``` Publishing Service Setting Metadata Let us define the values as below ```sh ORGID=test-org SERVICEID=test-service_id; DISPLAYNAME=Display Name; DOMAINNAME=https://daemondomainname; PORT=8088; ENDPOINT=$DOMAINNAME:$PORT   PRICE=0.00000001 #for the sake of an example HELPURL=https://helpurl; PATHFORSERVICESPEC=/pathtoyourproto/; SERVICEDESCRIPTION=Service Description; SHORTDESCRIPTION=Short Description of your service; CONTACTNAME=Name1;', 'EMAILID=Nam1@yourorg; #Address to be registered for your Daemons DAEMONADDRESS=""0xDBb9b2499c283cec176e7C707Ecb495B7a961ebf"" FREECALLS=15 #The address is of the Signer , who would issue you free tokens #Please note , if you are using market place Dapp , then we recommend to set the below #for free call Support  #for Ropsten the Signer Address is 0x7DF35C98f41F3Af0df1dc4c7F7D4C19a71Dd059F #for mainnet the Signer Address is 0x3Bb9b2499c283cec176e7C707Ecb495B7a961ebf', 'SIGNERADDRESS=""0x7DF35C98f41F3Af0df1dc4c7F7D4C19a71Dd059F"" #Tags should be in small letters  TAGS=image-recognition;  #create a metadata file with the same name as the service id. MD_FILE=""your_service.json"";  ``` Run the snet-cli commands as below ```sh  snet service metadata-init --metadata-file $MD_FILE pwd/$YOURGITREPONAME/$PATHFORSERVICESPEC ""$DISPLAYNAME"" --encoding proto service-type grpc --group-name default_group snet service metadata-set-fixed-price default_group $PRICE --metadata-file $MD_FILE snet service metadata-add-endpoints default_group $DOMAINNAME:$PORT --metadata-file $MD_FILE snet service metadata-add-description --metadata-file $MD_FILE --description ""$SERVICEDESCRIPTION""  --short-description ""$SHORTDESCRIPTION"" --url ""$HELPURL"" \u200b', 'if you want to support free calls , you will need to do the below snet service metadata-set-free-calls default_group $FREECALLS --metadata-file $MD_FILE snet service metadata-set-freecall-signer-address default_group $SIGNERADDRESS --metadata-file $MD_FILE snet service metadata-add-contributor ""$CONTACTNAME"" $EMAILID --metadata-file $MD_FILE snet service metadata-add-daemon-addresses default_group $DAEMONADDRESS --metadata-file $MD_FILE snet service metadata-add-assets service_metadata1.json hero_image ``` Publish Service on Blockchain You need to have some ether in your wallet to publish a service You must be either the owner or a member to have permission to publish/delete/Modify a service sh', 'snet service publish $ORG_ID $SERVICE_ID --metadata-file $MD_FILE'], [], [""Our Developer Portal contains documentation about the SingularityNET Platform and Marketplace.  As a service developer, you can learn how to build and access AI services that are published onto the network. As a client of SingularityNET services, you learn to integrate your software with SingularityNET services that other people have published. The beta Marketplace is available online at beta.singularitynet.io, and allows you to browse a curated set of services available in the registry. If you're new to SingularityNET, it is recommended that you follow this order to explore the developer portal. For everyone else, it's hopefully a good index to find the information you need. First Steps if you want to be a consumer of SingularityNET services, the follow first three relevant links. if you prefer publishing, testing and understanding the customer requirements, then it is worth the efforts and value. - Prerequisites - Certain conditions that need to be full-filled. prior to using decentralised AI services."", ""- Create a Wallet - You'll need a wallet with some funds to perform transactions . - How to call a service using snet-cli - Invoke the service using the command line tool. - How to call a service using Dapp  - Invoke the service using the Market Place Dapp - Using the SDK - Invoking a AI service using the Python SDK. To create a service, and upload that service on our marketplace, follow these instructions:  Publish and run your own example service Marketplace Requirements for Services - How to submit your service for inclusion in the Singularity marketplace?   The marketplace is a curated view of services available in the registry. Tutorials across languages We Support popular language-specific tutorials  Tutorials Build a service in C++ Build a service in Go Build a service in Java Build a service in Python Build an Opencog service  Community  Workshops - For workshop resources, click on this workshop link.""], ['Calling a Service All complexity of invoking a service is abstracted from the users. For example it becomes easy for the user to Input the values that need to be sent and view the computed expected result in the Output field, even without knowing the complexity of the gRPC calls/generating signatures for authorization to call a  service.   Please note that the the Marketplace offers a free trial version, where registered users can access service(s) for a specified number of calls.   Once your freecalls are exhausted , you will need to pay for any new calls to the service. for this you need need a wallet, some ethers in your wallet , some AGIX in your wallet  You can either pay through Metamask or through a General wallet(paypal)  Select a Wallet -   Lets look at each of the wallet options in detail below Using Metamask Important: Metamask is a plugin which is used by the SingularityNET platform.', 'This extension, allows you to perform the following in the context of the marketplace:  Transfer AGIX funds into escrow,  Setup payment channels to enable calls to any of the listed services.  As a first step you will need to Authorize the Dapp to connect to your metamask account - Authorize Metamask -  Depositing tokens from Metamask to the Escrow Wallet. Steps 1.  Let start by depositing some tokens from Metamask to the Singularity Escrow Wallet. So you can pay for service 2.  On the Home page click on Account link 3.  Confirm you have sufficient balance in your Metamask Wallet 4.  In your Account details, check the Total Balance, This is the number AGIX token you have in Metamask wallet 5.  In the Manage your Escrow account section, Enter the amount of money you want to deposit to the Escrow wallet 6.  Click Deposit.', 'A Metamask Window should pop-up. If it Metamask Window does not pop-up, click on the Metamask icon on the top of your browser. 7.  Check the transaction and click confirm. 8.  Wait for the transactions to be mined. 9.  This is two step transactions; you will need to confirm both steps.(Gas fee and Total) 10. Wait for the transactions to be mined again 11. Confirmation message show that the token has been deposited to the Escrow wallet  12. You might need to refresh if your token still appears as authorized. If you dont have money on Escrow account, you will be asked to Deposit into Escrow  Now click on Deposit You need to confirm every Blockchain transaction when using metamask as your mode of payment  Based on the number of calls you wish to invoke ,select the option and the channel will be  funded accordingly', ""Once the funds are in the channel, you are all set to invoke the service ! Using General Wallet Select the 'General Wallet' Option  To call a service  View a list of service from the home page. Filter the list by using the search text box. Look for  image recognition service Click on Demo.      This will take you to the corresponding service details page.  If you are using General Wallet and you have sufficient funds , you will see the continue button    Now you have the access to the invoke section of the service      The interface will change according to the input need for each service. Choose a Method to identify the service -  An Image After setting-up all that you need,  click the Invoke button. If you are using Metamask , then the transaction will need to be signed again using metamask before invoking  Wait for the response You are now eligible to write a review"", 'You can now continue to use the Service till you have sufficient funds before the expiry date of the channel claim back the reserved fund  Go the Account page     If there is any expired channel it displays under the Expired Channel Details section Select the channel you want to claim Click Claim Channel Confirm this transaction on Metamask Wait for it to mined     Displays the message confirming that funds have been successfully claimed.  Once you do this, the payment channel you claimed is unlisted.  Withdraw tokens from Escrow wallet to Metamask  Go to the Account page In theManage your Escrow account section, select  Withdraw Confirm that you have sufficient funds in the Escrow wallet. Enter the money you want to withdraw and click Withdraw Confirm this transaction on the Metamask Wait for it to be mined     A message displays that the withdraw has been successful Refresh the page to see the balance is updated.', ""You will be able to see the token back in to your Metamask wallet.   Marketplace Requirements If you are a service author, need the service to be visible to others and listed on the marketplace you must: 1.  Build and publish your service  2.  Use SSL with the snet-daemon.      Note: if you don't already have an SSL certificate for your domain, it is recommend you use certbot and letsencrypt . 3.  Fork the snet-dapp repo, build a react component as the user interface for your service, and submit a pull request.      Note: Identify the services on your networks, organization and service names being used. For more details, refer to dapp repo README.md. 4.  Last is some paperwork that we are still finalising, and we'll update this list when we have that. If you are itching to get your service listed, reach out to us via one of our community groups."", 'Note that your service can be published to SingularityNET without being listed on the marketplace, but your service may be less discoverable to potential customers if it is not listed.'], ['Introduction This section provides steps on securing your SingularityNet Daemon with Certbot from Let’s Encrypt. Let’s Encrypt is a nonprofit Certificate Authority (CA) that provides an easy way to obtain and install free TLS/SSL certificates, thereby enabling encrypted HTTPS on web servers. It simplifies the process by providing a software client, Certbot, that attempts to automate most (if not all) of the required steps. Currently, the entire process of obtaining and installing a certificate is fully automated. The Lets Encryptgetting started guide gives a detailed explanation on using Lets Encrypt. Prerequisites  A fully registered domain name. This guide uses daemon_domain as an example throughout.   Step 1 — Installing Certbot Install certbot using the guide here     - Install certbot on the server that will host the certificate     - For software, select ""None of the Above"", and choose your OS to get detail install intructions.     - If you are using Ubuntu 18.', '04 LTS you can go direct to: https://certbot.eff.org/lets-encrypt/ubuntubionic-other Step 2 — Obtaining an SSL Certificate We use the certbot authenticator to obtain an SSL Certificate. The certbot authenticator validates that you control the domain(s) you are requesting a certificate for, obtains a certificate for the specified domain(s), and places the certificate in the /etc/letsencrypt directory on your machine. The authenticator does not install the certificate (it does not edit any of your server’s configuration files to serve the obtained certificate). If you specify multiple domains to authenticate, they will all be listed in a single certificate. To obtain multiple separate certificates you will need to run Certbot multiple times. Here is an example of the running the sudo certbot certonly command, for <daemon_domain> ``` $ sudo certbot certonly Saving debug log to /var/log/letsencrypt/letsencrypt.log', ""How would you like to authenticate with the ACME CA?  1: Spin up a temporary webserver (standalone) 2: Place files in webroot directory (webroot)  Select the appropriate number [1-2] then [enter] (press 'c' to cancel): 1  Plugins selected: Authenticator standalone, Installer None Enter email address (used for urgent renewal and security notices) (Enter 'c' to cancel): joe@daemon_domain.sh  Please read the Terms of Service at https://letsencrypt.org/documents/LE-SA-v1.2-November-15-2017.pdf. You must agree in order to register with the ACME server at https://acme-v02.api.letsencrypt.org/directory  (A)gree/(C)ancel: A  Would you be willing to share your email address with the Electronic Frontier Foundation, a founding partner of the Let's Encrypt project and the non-profit"", 'organization that develops Certbot? We\'d like to send you email about our work encrypting the web, EFF news, campaigns, and ways to support digital freedom.  (Y)es/(N)o: n Please enter in your domain name(s) (comma and/or space separated)  (Enter \'c\' to cancel):  Obtaining a new certificate Performing the following challenges: http-01 challenge for  Waiting for verification... Cleaning up challenges IMPORTANT NOTES:  - Congratulations! Your certificate and chain have been saved at:    /etc/letsencrypt/live//fullchain.pem    Your key file has been saved at:    /etc/letsencrypt/live//privkey.pem    Your cert will expire on 2019-05-22. To obtain a new or tweaked    version of this certificate in the future, simply run certbot    again. To non-interactively renew all of your certificates, run    ""certbot renew""', ""- Your account credentials have been saved in your Certbot    configuration directory at /etc/letsencrypt. You should make a    secure backup of this folder now. This configuration directory will    also contain certificates and private keys obtained by Certbot so    making regular backups of this folder is ideal.  - If you like Certbot, please consider supporting our work by: Donating to ISRG / Let's Encrypt:   https://letsencrypt.org/donate    Donating to EFF:                    https://eff.org/donate-le ``` Step 3 — Getting the certificate path Get the certificate path and key using the command: sudo certbot certificates. This is needed for configuring the SingularityNet daemon ``` $ sudo certbot certificates Saving debug log to /var/log/letsencrypt/letsencrypt.log  Found the following certs:   Certificate Name:      Domains:"", ""Expiry Date: 2019-05-22 23:22:26+00:00 (VALID: 89 days)     Certificate Path: /etc/letsencrypt/live//fullchain.pem     Private Key Path: /etc/letsencrypt/live//privkey.pem  ``` Step 4 — Mount certificate path (Only required if the daemon is being run in a docker container) Based on the certificate paths from above, mount the certificate dir as a volume in your docker container. Note that the certificates may be symbolic links, so you can't just mount /etc/letsencrypt/live/<daemon_domain>/. $ sudo ls -la /etc/letsencrypt/live/<daemon_domain>/ total 12 drwxr-xr-x 2 root root 4096 Feb 22 00:22 . drwx------ 3 root root 4096 Feb 22 00:22 .."", 'lrwxrwxrwx 1 root root   42 Feb 22 00:22 cert.pem -> ../../archive/<daemon_domain>/cert1.pem lrwxrwxrwx 1 root root   43 Feb 22 00:22 chain.pem -> ../../archive/<daemon_domain>/chain1.pem lrwxrwxrwx 1 root root   47 Feb 22 00:22 fullchain.pem -> ../../archive/<daemon_domain>/fullchain1.pem lrwxrwxrwx 1 root root   45 Feb 22 00:22 privkey.pem -> ../../archive/<daemon_domain>/privkey1.pem -rw-r--r-- 1 root root  692 Feb 22 00:22 README Directory listing shows us that the link is relative and jumps two directories above.  This means we need to mount /etc/letsencrypt (or mount where it points, e.g.', ""/etc/letsencrypt/archive/<daemon_domain>,  but this could break if certbot changes how it stores certs and manages renewals) $ docker run -v /etc/letsencrypt:/etc/letsencrypt [...] Step 5 — Schedule renewal of certificates Let's Encrypt certificates are valid for 90 days and need to be renewed post that.  Check cron or systemd timer is in place for renewal of certificates: cat /etc/cron.d/certbot or systemctl show certbot.timer (Ubuntu 18.04 uses systemd, so the latter command is the important one on that platform). When the certificate updates, you'll have to restart your services so that snet daemon uses the new certificate. To do this, you can add a script to /etc/letsencrypt/renewal-hooks/deploy ``` $ sudo bash -c 'cat > /etc/letsencrypt/renewal-hooks/deploy/restart_services.sh' !/bin/bash"", 'docker restart [SERVICE_CONTAINER_NAME] ^D $ chmod u+x /etc/letsencrypt/renewal-hooks/deploy/restart_services.sh ```'], ['Introduction to MPE An Escrow contract defines the conditional transaction between two transacting parties through an Escrow account. The Multi-Party Escrow (MPE) smart contract API and the payment channel together enable payments in the SingularityNet platform with a minimal number of on-Blockchain interactions between AI Consumers and AI service providers. The MPE contract comprises two main functions, which includes:  A wallet with a deposit and withdraw function.  A set of the simple (“atomic”) unidirectional payment channels between clients and service providers and support functions for controlling these channels. Note: Any one can deposit and withdraw their AGIX tokens into a Multi-Party Escrow, (which have not been escrowed at the moment).   What is Payment Channel? Whenever the sender and the receiver enter into an contract, a channel is created. A payment channel is a tool that enables off-chain transactions between parties without the delay imposed by Blockchain block formation and without compromising the transactional security.', 'Atomic unidirectional payment channel If you are familiar with the concept of payment channels, ignore this section. The core logical building block of the Multi-Party Escrow is a simple (“Atomic”) unidirectional payment channel. To learn more about the details of how to implement the Escrow contract for unidirectional payment channel, click on this link SimpleEscrow.sol file here. It is understood that the payment channel is on the Blockchain. So, in order to prevent direct updating on the Blockchain regularly, the payment channel state is maintained in the storage. Daemon maintains the channel state off-chain as block operations involve gas cost and are slow between parties without imposing any delay by the Blockchain block formation times and compromising on transactional security. Let us consider the simple unidirectional payment channel, the main logic is as follows:  The sender creates an Escrow contract with a given expiration date, and funds it with a desired amount of tokens.', 'The sender then needs to send a small amount of tokens to the recipient each time (to the recipient) with signed authorization. The recipient must verify whether the signed authorization and the amount required is correct, and that amount specified does not exceed the funds being escrowed. The channel nonce is incremented, whenever a claim happens, Actually, the channel is not closed and the task can still continue off line, but a new nonce need to be used. The sender can perform the following: Can collect all funds remaining after the expiration date.   -or- Extend the expiration date and add funds to the contract at any moment in time.    Note: The receiver can withdraw from the channel (same as claim) only using the authorized amount by the sender.  Whenever a signature is made on a certain format which should be signed by the private key of the sender, the receiver then verifies whether the signature was authentic to the sender, based on the agreed format. MPE Use cases Consider the following', '- Kevin - is our Client  Consumer/Buyer - Jack - is our Service Provider/Seller If Kevin is buying services from Jack, they both need to enter in to a formal agreement with each other. A channel is created. Note: Each channel is unique to a combination of client identity (sender), service identity (recipient), Organization Id and the daemon group identity.  Kevin deposits tokens to the Multi-Party Escrow account and uses this as a wallet for their AGIX tokens.  Kevin creates and opens a Payment Channel.  Note: Kevin is the sender of tokens and Jack is the receiver of tokens. Every channel created has a unique ID, which starts from 0.   Kevin funds the channel. Jack suggests Kevin to deposit a bare amount (cost of the service) and mentions that the amount can never been withdrawn for a predetermined period of time. This period is configurable.', 'Based on how much Kevin wants to use a service, Kevin deposits the amount in to the channel accordingly, so if the cost is 1 cog, and Kevin needs to use it 10 times, he will deposit 10 cogs. Nonce is always zero when you create the channel for the first time.  Note: Unless and until Kevin authorises, Jack cannot withdraw the money.     Kevin and Jack come into agreement to perform operation off-chain. The daemon manages the off-chain state of the channel.  Kevin needs to authorize using the signature (using his private key to sign) to let Jack withdraw Jack verifies the following: Signature is authentic. Amount of AGIX tokens specified is correct (last Authorized Amount from Kevin + Cost of the Service being called). Amount does not exceed the value of the channel. Channel is not very close to expiring or has expired.   Kevin makes a call; Kevin now sends the signed authorization to Jack to “withdraw”. The effective balance is 1.', 'Jack can now make a claim with the amount authorized.     Note: Nonce increments to 1, when claim is performed.  Diagram showcasing how Kevin and Jack Communicate  State management of the channel  Kevin (Buyer) and Jack (Service provider) enter into a contract for the first time, they create a channel in the Blockchain detailed as follows:  |Channel ID       | 1       |The channel ID created is 1 on Chain| |---------------------|-------- |----------------------------------| |Nonce            | 0       |Initially the Nonce is 0| |Full amount      | 100 Cogs|Amount Kevin has put into the channel is 100 Cogs| |Authorized Amount| 0       |The Authorized amount is zero, because no services has been used for the first time.| |Signature        | Nil     |No signature is required to be sent.|', 'Kevin makes a call and authorizes for 1 cog to Jack, (assuming the cost of the service is 1 cog), the status of the channel is now maintained off-chain by the storage mechanism used by Daemon :  |Channel ID       | 1       |The channel ID 1 is now updated off-chain| |-------------------- |-------- |----------------------------------| |Nonce            | 0       |Initially the Nonce is 0| |Full amount      | 100 Cogs|Amount Kevin has put into the channel is 100 Cogs| |Authorized Amount| 1       |The Authorized amount is one.| |Signature        | 1       |No signature is required to be sent.|  Kevin makes a call and authorizes for 2 cogs, to Jack, now the status changes as follows:  |Channel ID       | 1       |The channel ID 1 is now updated off-chain| |---------------------|---------|----------------------------------|', '|Nonce            | 0       |Initially the Nonce is 0| |Full amount      | 100 Cogs|Amount Kevin has put into the channel is 100 Cogs| |Authorized Amount| 2 Cogs  |The Authorized amount is two.| |Signature        | 2 Cogs  |Signature is required for two.|  Jack makes a claim using the signature from Kevin, this transaction is considered on-chain transaction.  Please note the effective balance in Blockchain for this channel is now 98 and its nonce is 1.  The same channel state is updated as follows even in the off-chain state:  |Channel ID       | 1       |The channel ID created is 1| |---------------------|---------|----------------------------------| |Nonce            | 1       |Initially the Nonce was 0 but now it is 1| |Full amount      | 98 Cogs|Amount signed by Kevin was for two cogs.', 'The full amount in the channel is 98.| |Authorized Amount| 0       |The Authorized amount is zero.| |Signature        | 0       |No signature is required to be sent| Note: Claims are always on-chain transaction and the Nonce gets incremented when claims are made. The same process follows for future calls authorizations of cogs. Postponing the Expiration Time of the Channel With the following functions the client can postpone the expiration time of the channel and can add funds to the channel at any time and can also claim all funds from the channel after the expiration time is reached. function channelExtend(uint256 channel_id, uint256 new_expiration); function channelAddFunds(uint256 channel_id, uint256 amount); function channelExtendAndAddFunds(uint256 channel_id, uint256 new_expiration, uint256 amount); function channelClaimTimeout(uint256 channel_id); Claiming your funds back after Expiration', 'The Sender can claim the funds after the expiry date function channelClaimTimeout(uint256 channel_id); How the recipient Claims funds from the Channel With the following function, the recipient can claim funds from the channel function channelClaim(uint256 channelId, uint256 amount, uint8 v, bytes32 r, bytes32 s, bool isSendback) It should be noted that v, r, s are parts of the signature. The recipent should present the signature for the following message [MPEContractAdress, channelId, nonce, amount]. It should be noted that [MPEContractAdress, channel_id, nonce] is the full ID of the ""atomic"" channel. The recipient has two possibilities: * (is_sendback==true) - ""close"" the channel and send the remainder back to the sender. * (is_sendback==false) - ""close/reopen"".', ""We transfer the claimed amount to the recipient, but instead of sending the remainder back to the sender we simple change the nonce of the channel. By doing this we close the old atomic channel [MPEContractAdress, channel_id, old_nonce] and open the new one [MPEContractAdress, channel_id, new_nonce]. Remarks  The service provider can use the same Ethereum address for all payment groups or can use a different address. In any case, the daemons very rarely need to send an on-chain transaction. This means that we actually don't need to provide the daemons with direct access to the private key. Instead, a centralized server could sign the transactions from the daemons (in some cases it even can be done in semi-manual manner by the service owner). We call such a server a treasurer server. In the current implementation, the client signs off-chain authorization messages with the signer's private key."", ""This means that the client doesn't necessarily need to sign transactions with his Ethereum identity. Instead, he can use other key pairs. The server does not need to wait for a confirmation from the Blockchain after it sends on-chain requests to close/reopen channels (channelClaim). It can inform the client that the nonce of the channel has changed, and it can start accepting calls from the client with a new nonce. It can be shown that it is secure for both the client and the server if the transaction is accepted by the Blockchain before the expiration date of the channel. Similarly, the client doesn't need to wait for a confirmation from the Blockchain after sending the channelExtendAndAddFunds call. It makes the Multi-Party Escrow functional, even on a very slow Ethereum network. The nonce in the channel prevents a race between the channelExtendAndAddFunds and channelClaim. If the client sends the channelExtendAndAddFunds request and at the same time the"", 'server sends a channelClaim request, they can continue to work without receiving confirmation from the Blockchain. In this case it also does not matter which request will be accepted first (as channelClaim can only change the nonce, and cannot create a new Payment Channel structure).  Contract Addresses Click here MPE Stateless Client The client does not have to maintain the state of the last amount it had signed. The client can request the last state of the given payment channel from the server. * The server is not able to forge this state, because it was signed by the client (of course the client should check its own signature). * The server is obviously interested in saving and sending the last state, otherwise it loses money. This section describes how the client communicates with the SingularityNET services using the Multi-Party Escrow payment channels without storing state of the payment channel. The client needs to store the Ethereum identity as follows: 1.', 'The client obtains the list of payment channels (payment channels with ""sender==client"") from the Multi-Party Escrow (see EventChannelOpen).     Considering the situation in which the request to open the channel had been sent, but not yet mined. This can occur when the client request has not received any acknowledgement or the session is disconnected (it ""lost"" its state). 2.  The client requests the last state of the given payment channel from the server  The server can never duplicate the state of the payment channel signed by the client (off course the client should check its own signature). The server saves and sends the last state, otherwise the money is lost.  Note: A unique gRPC method is available in the daemon to return the state of the channel (see: https://github.com/singnet/snet-cli/blob/master/packages/snet_cli/snet/snet_cli/resources/proto/state_service.proto).', ""The client does not necessarily require a special call request to know the last state of the channel from the daemon. The daemon can return the state of the channel in the response to any non-authorized call. The client receives the following information from the daemon:  current_nonce Current nonce of the payment channel. current_signed_amount Last amount which were signed by the client with current_nonce. If no messages were signed with current_nonce, then this value is an empty byte string (b''), which we should interpret as 0. current_signature Last signature sent by the client with current_nonce, it could be absent (empty string) if no message was signed with current_nonce. oldnonce_signed_amount Last amount which was signed by the client with nonce=current_nonce - 1. oldnonce_signature Last signature sent by client with nonce = current_nonce - 1."", 'Note: The two last values are not available in current version, if implemented, can calculate the unspent_amount in the case that current_nonce != |Blockchain_nonce. Example Assume that the server performs a close/reopen procedure for the channel. The client can proceed without confirmation from the Blockchain, because the server does not need to be dependent, or the client ensures that the request is mined before expiration of the channel. Before considering the above scenario, let us define the following parameters - |Blockchain_nonce - nonce of the channel in the Blockchain - |Blockchain_value - value of the channel in the Blockchain It is known that the daemon starts the close/reopen procedure only after the previous channelClaim request was mined. This means that the current_nonce, at maximum, is one point ahead of the |Blockchain_nonce. In each case, the client can verify their signature is authentic and considers the following two numbers:', ""Next amount which has to be signed (next_signed_amount), taking into account the price for the current call (price). This value can be easily calculated as we interpret current_signed_amount = b'' as 0. next_signed_amount = current_signed_amount + price   The amount of tokens which haven't been already spent (unspent_amount).  Simple case current_nonce == |Blockchain_nonce - unspent_amount = |Blockchain_value - current_signed_amount Complex casecurrent_nonce != |Blockchain_nonce Taking into account our assumptions, we know that current_nonce = |Blockchain_nonce + 1. - unspent_amount = |Blockchain_value - oldnonce_signed_amount - current_signed_amount"", 'Note: The server can send smaller oldnonce_signed_amount (not the actually last one which was used for channelClaim), But the server trust that the money available is actually more in the channel, which means that a likely attack has occurred through unspent_amount, which lead us to believe that there are less tokens than the actuals, and therefore the future calls need be rejected instantly (or force us to call channelAddFunds).'], ['There are many ways to create an ethereum identity. A few a listed below.   In all cases the private key has to be stored securely as thats the only way to access the corresponding account. Using snet-cli snet-cli is the command line utility to interact with the SIngularityNet platform. The following command can be used to create an identity sh snet identity create test-user key --private-key <PVT-KEY> --network mainnet See the CLI documentation for full details of actions the tool allows. Using Metamask Metamask is a browser extension for interacting with Blockchain enabled websites, such as marketplace. Install Metamask from their website. In the initial startup, Metamask will prompt you to create an identity, which can be used in Blockchain transactions and for storing tokens. To learn more about this, watch the video uploaded on the website or read about how to use the extension on their website. What are the different networks?', 'All real value transactions occur in either ""Main Ethereum Network"" or ""Mainnet Network"". The other available networks are for testing purposes, and the tokens on those networks are essentially value-less and are only useful for testing code and software. Important The major releases will be over the main network. NOTE: Use the SingularityNET Marketplace in Mainnet Mode whenever you want to integrate an AI service into your software. Use the SingularityNET Marketplace in Ropsten Mode whenever you want to test the platform as a developer. Do not integrate AI services from the Ropsten Network in your software, as their continuous availability is not guaranteed. Ethereum Faucet (Ropsten Test Network Only) Ethereum Ropsten coins are free to claim and can be used to test the platform. Ropsten Ethereum is needed to cover the Gas costs associated with transactions on the platform.', 'Users are required to visit a Ropsten Faucet, which is a per-request Ropsten Ethereum distribution hub. Users provide their Ropsten Ethereum wallet address from MetaMask to the faucet and it issues a set amount of Ropsten Ethereum to the requesting wallet. AGIX Faucet (Ropsten Test Network Only) In order to have Ropsten AGIX to test the platform, users are required to visit the AGIX XFaucet, which is a per-request Ropsten AGIX distribution hub. In this case, users provide their Ropsten Ethereum wallet addresses to the Faucet, and a set amount of Ropsten AGIX will be transferred to the requesting wallet. In order to receive these tokens, the user must log in via GitHub to access the AGIX Ropsten Faucet.'], ['Introduction to AGIX Tokens The AGIX Token is an ERC-20 token, which is hosted on the Ethereum Blockchain. SingularityNET uses the AGIX Token for any paid calls to a service. To learn more about how to obtain Kovan or Ropsten Testnet AGIX, click on the link here. Testnet AGIX vs Mainnet AGIX If you are unfamiliar with  Ethereum, it might be hard to understand between Testnet and Mainnet tokens.  However, to understand the different network tokens, you can follow principles listed below: * Testnet tokens are used to test software applications with, try out demos, or in our case the Beta. * Mainnet tokens are used for officially deployed software. * Testnet tokens never have a monetary value. * Mainnet tokens could have a monetary value. * Both tokens can be used to add extra utility to the software.', 'We only use Kovan and Ropsten Testnet AGIX and the current beta stage.  To learn more about  Mainnet AGIX Token (to be used in a later stage) refer to this link here with the address 0x8eb24319393716668d768dcec29356ae9cffe285.  NOTE Currently, AGIX token is traded on some exchanges, and also the speculative secondary trading is considered against the ethics of AGIX token and SingularityNET project. Therefore, it is not recommended to exchange trading in any manner.  AGIX Faucet To understand how automated faucet is used in distribution of Kovan and Ropsten Testnet AGIX Tokens, click on the link here. Use GitHub account to login and type in the Ethereum address to receive the AGIX token. Ensure this address belongs Kovan Ethereum Address.  Note: You can request for 10 AGIX token every 24 hours.', 'In order to add the Kovan Testnet AGIX, you may need the following details: * Symbol: AGIX * Decimals: 8 * Kovan Token Address: 0x3b226ff6aad7851d3263e53cb7688d13a07f6e81'], ['SingularityNET’s Decentralized AI Marketplace Integration with PayPal The integration of SingularityNET’s decentralized AI marketplace with PayPal represents a significant step in the direction of wide adoption of the platform. It makes it easier for more AI users to leverage the platform, thus increasing the likelihood that data scientists and developers will feel incentivized to consider SingularityNET a viable alternative pathway to monetize their expertise. This integration represents a large opportunity for SingularityNET and our community. Whatever happens on Blockchain, an event is created, and the Marketplace listens to all events.  When there is an event notification, the Marketplace reads the Organization metadata and serviice metadata for example, and retrives the data from the Blockchain and stores them in the local tables, or database.  The Markplace URL page which is designed by the SingularityNET, manages and displays all the information available from Marketplace database.', ""the SingularityNET platform is open and decentralized, the Marketplace is the SingularityNET Foundation's curated view.  This allows the foundation to adhere to legal requirements of different legislative regions. So whenever an events resides in the local table, they need to be reviewed and approved.  This waiting period is known as Curative process. Only after the successful it has been approved; the service becomes available in the Marketplace.  Note: You can also go to the Marketplace and pay the price through Paypal. I such case, the entire process is managed at the background automatically for you. The protofile  information associated IPFS hash are so complex to understand. But because they are part of the UI, it becomes user-friendly way to build the  UI components around a service and host it on SingularityNET platform."", 'This becomes easy for the user to the Input values that need to be sent and view the computed expected result in the Output field, even without knowing the complexity of the gRPC call and the proto that is associated to the service and so.  So when you click the Invoke button the AI service computes the result  This service is integrated with the Multiparty Escrow, allowing the user to pay for the service uisng Paypal, that allows the  application to manage. For example, If you look at the Sample service under the Organization in the Marketplace, you will notice that it shows that you have utilized the free trial service period.  You can choose an option from the following list :  Select a Walley General Account Wallet  = Metamask  Choose a Metamask. By selecting this option,yYou are Authorizing SingularityNET to use Metamask. Metamask is a plugin which can be used as an Wallet.', 'It is coming from Ethereum Blockchain, so you can add money, any crypto currency or tokens to this Wallet.   For example if I want to move the money into my account, you need to do a Blockchain Operation. Or need to move money from your account to channel, into my account, which involves some additional charges,  As an AI consumer you can choose to: - create a Wallet - use a Metamask The Marketplace offers a free trial version, where registered users can access service(s) for a specified time period. After the expiration time period of the trial version, install an Ethereum browser extension, such as MetaMask.  This extension mediates with the Blockchain on behalf, and helps you in transferring of tokens between wallets, and invoke contracts. Note: Service metadata is a place where the price of the service is set and it is on the Blockchain. The service provider needs to publish the details about the service in the Blockchain.', 'As a consumer, you may go the Blockchain or the Marketplace portal where the services are deployed. All service metadata details are stored in the the JSON file - Create a JSON file - information about the image, service type, description, price of the service, the endpoint and how to make a request. - Singularity platform works on gRPC. Whenever you need to call you need a protofile. - File management system such as IPFS stores the location of the hash and points to the associated protofile     The IPFS can include a file and the same file returns same hash.  How to use service by paying through PayPal  Go to the Marketplace portal Pay service through your Paypal  Use Faucet to convert to crypto currency details The application send the equal token in to wallet and then to Channel Now you can make a call now - the call is based on proto.  Depositing  tokens from Metamask to the Singularity Escrow Wallet. Steps', '1.  Let start by depositing some tokens from Metamask to the Singularity Escrow Wallet. So you can pay for service 2.  On the Home page click on Account link 3.  Confirm you have sufficient balance in your Metamask Wallet 4.  In your Account details, check the Total Balance, This is the number AGIX token you have in Metamask wallet 5.  In the Manage your Escrow account section, Enter the amount of money you want to deposit to the Escrow wallet 6.  Click Deposit. A Metamask Window should pop-up. If it Metamask Window does not pop-up, click on the Metamask icon on the top of your browser. 7.  Check the transaction and click confirm. 8.  Wait for the transactions to be mined. 9.  This is two step transactions; you will need to confirm both steps.(Gas fee and Total) 10.', 'Wait for the transactions to be mined again 11. Confirmation message show that the token has been deposited to the Escrow wallet  12. You might need to refresh if your token still appears as authorized. To  call a service  View a list of service from the home page. Filter the list by using the search text box. Look for  image recognition service Click on Details.      An overview dialog box displays on the right. On the top you can view a brief description of the service. The below section shows the amount that will be deposited in the payment channel and the blocknumber when the block will expire Click on the Start job     This will ask for a signature on the Metamask, since you will be opening a Payment channel Click Sign, followed by reserved funds.      You must edit the Amount and Expiration before confirming this step. And wait for it to be mined. Now you have the access to the invoke section of the service', 'The interface will change according to the input need for each service. Choose a Method to identify the service -  An Image After setting-up all that you need,  click the Invoke. Sign the Metamask transaction to send the service to the Blockchain Wait for the response You can up vote or down vote hope on the decentralized market curation  Not only have bought service, you have also opened a Payment channel with it and continue to use until it expires.  claim back the reserved fund  Go the Account page     If there is any expired channel it displays under the Expired Channel Details section Select the channel you want to claim Click Claim Channel Confirm this transaction on Metamask Wait for it to mined     Displays the message confirming that funds have been successfully claimed.  Once you do this, the payment channel you claimed is unlisted.  Withdraw tokens from Escrow wallet to Metamask  Go to the Account page', 'In theManage your Escrow account section, select  Withdraw Confirm that you have sufficient funds in the Escrow wallet. Enter the money you want to withdraw and click Withdraw Confirm this transaction on the Metamask Wait for it to be mined     A message displays that the withdraw has been successful Refresh the page to see the balance is updated.     You will be able to see the token back in to your Metamask wallet.'], ['Why support for Training on platform ? Currently all calls on the market place dapp are Inference call SingularityNET is solving this difficulty for AI systems on the Platform and Marketplace by allowing developers to offer multiple training models of their algorithm. The end-user can pick whether it wants to use the model trained on chest x-rays or the one trained on dental x-rays. The end-user can even provide their own training data to create a unique training model specifically suited to their exact data. This multi-model opportunity will allow developers to offer flexible, trainable, and customizable AI’s through our decentralized Marketplace, to better serve AI consumers - and enable access to high-quality AI services for all. This Platform upgrade is well underway, with functionality added to the Platform daemon already. The next step will be to upgrade the SDK, Marketplace front-end, publisher, and other systems to support multi-model AIs and model training calls. Please note:The Model Is stored at the AI developers end', 'Daemon / platform only controls metadata of the  model Id and who has access to these models and the status of these models  MetaData of Model -  CREATE/UPDATE/DELETE/GETDETAILS AI consumer can call any of the below from marketplace dapp/ platform componetns like SDKs/snet-cli  Please note that calls made for any change on metadata of the model is free. Platform gives you a tools to ONLY to update the metadata associated with the model  metadata of a model  Create model Service Request to create a model, please note as part of MVP1, there will not be any workflows associated with model request approval Here all the complexity of creating a training is abstracted from the users. It become easy for the user to create and edit their trainings.   If the training is available inside the model then the Models tab will appear.   The first step in requesting a custom model is to create a project.', 'The REQUEST A NEW MODEL button will help the users to create the model. The models you create in this project inherit the name of the project. Once the REQUEST A NEW MODEL button is clicked it will open a new window where the user can enter the details.  AI consumers , will pass the below details    list of addresses that can access this model ( applicable if model is not public)    if model is public    Description of the model   In return the AI conusmer will get back a model ID  The available training models are displayed under the training method drop down box.  Training a model Once the model is created , AI consumer can invoke training methods , of course the expectation here is to pass the model Id as part of the request  training methods are identified by special method annotations ,  just like any other method calls training calls  will be chargable , please not how the trainig  input is passed is very specific to the method being trained !!!', 'For example it can be a link to a public folder of images / music / or a plain input of many texts    Please note this is entirely in control of the AI developer and expose services on how to receive data to train models    The onus of Storing the actual Model and training it is the responsibility of the AI developer   AI developer can mark  training methods ( a method is marked as a trainign method through method level options from GRPC) , this way the AI developer has full control on the request message to the trainign methods .   AI consumer will pay for training a methods, AI developer needs to define these methods as part of the service proto !! UpdateModelAccess AI consumer can add/remove addresses associated with a given model , can also make this public from private and viceversa. Existing model Service Important: Metamask is a plugin which is used by the SingularityNET platform. This plugin allows the user to connect with the existing models.', 'Under the existing model, it will provide the details regarding the models created with model name, model Id, model description, status, access and the last update details. Edit model Service The Edit button provide a new scope to change the details in the existing models.  Delete model Service AI consumer had created and can request that the model be deleted. The delete button provide a service to delete the models.  GetModelStatus Pass the model Id and get back the training status of this model  GetAllAccessibleModels An AI consumer can always call back this method to determine the list of models associated to a given address , this can be used while making inference calls , the AI consumer can pick the model of their choice if multiple models are available  Complete process video'], ['Page settings layout: default keywords: intro concepts comments: false  SETTING UP ETCD CLUSTER Starting an etcd cluster normally requires each member to be familiar with other members in the cluster. Also, you need to determine in advance the public and private IP addresses of the system before setting up the cluster. To generate the server, client and peer certificates, use the public and private IP addresses of these machines. Using these certificates, the cluster will be setup with Transport Layer Service (TLS) Authentication enabled. This document considers deploying three node etcd cluster. Following are the example nodes for our reference. |Name    |Private Ip|  Public Ip  |    Hostname      | |-----   |--------- |------------ |----------------- | |member-1|10.0.1.10 |54.93.140.146|member-1.example.com| |member-2|10.0.1.11 |54.93.140.', ""76 |member-2.example.com| |member-3|10.0.1.12 |54.93.140.30 |member-3.example.com| Infrastructure Diagram Infrastural diagram of ETCD Cluster setup on AWS.  ETCD set up Script Download script For detailed explanation on every step , reference the sections below Generating Certificates To setup the cluster, use three types of certificate, such as: - Client certificate : Server uses to authenticate client. For example etcdctl, etcd proxy, or docker clients. - Server certificate : Server uses and client verifies for server identity. For example docker server or kube-apiserver. - Peer certificate   : etcd cluster  members uses this certificate to communicate both ways. Download cfssl Let's use cfssl on your local x86_64 Linux host, and walk through the process, of generating all required certificates. bash mkdir ~/bin"", 'curl -s -L -o ~/bin/cfssl https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 curl -s -L -o ~/bin/cfssljson https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 chmod +x ~/bin/{cfssl,cfssljson} export PATH=$PATH:~/bin Initialize a certificate authority First of all we have to save default cfssl options for future substitutions: bash mkdir ~/cfssl cd ~/cfssl cfssl print-defaults config > ca-config.json cfssl print-defaults csr > ca-csr.json Configure CA options Update the generated ca-config.json config file with the below content in order to generate three set of certificates. json {     ""signing"": {         ""default"": {             ""expiry"": ""43800h""         },         ""profiles"": {             ""server"": {', '""expiry"": ""43800h"",                 ""usages"": [                     ""signing"",                     ""key encipherment"",                     ""server auth""                 ]             },             ""client"": {                 ""expiry"": ""43800h"",                 ""usages"": [                     ""signing"",                     ""key encipherment"",                     ""client auth""                 ]             },             ""peer"": {                 ""expiry"": ""43800h"",                 ""usages"": [                     ""signing"",                     ""key encipherment"",                     ""server auth"",                     ""client auth""                 ]             }         }     } } Note: You can specify a particular expiry date for each certificate based on the requirement. Also, you could modify the ca-csr.json Certificate Signing Request (CSR): json {     ""CN"": ""My own CA"",     ""key"": {         ""algo"": ""rsa"",         ""size"": 2048     },     ""names"": [', '{             ""C"": ""US"",             ""L"": ""CA"",             ""O"": ""My Company Name"",             ""ST"": ""San Francisco"",             ""OU"": ""Org Unit 1"",             ""OU"": ""Org Unit 2""         }     ] } And generate CA with defined options: bash cfssl gencert -initca ca-csr.json | cfssljson -bare ca - You\'ll get following files: ca-key.pem ca.csr ca.pem Note: Keep ca-key.pem file safely. This key allows to create any kind of certificates within your CA. Generate server certificate bash cfssl print-defaults csr > server.json Important: Values for server certificate are Common Name (CN) and hosts. We have to substitute them, with public ips. For example: json {     ""CN"": ""etcd-cluster"",     ""hosts"": [         ""domain-name"",         ""54.93.140.', '146"",         ""54.93.140.76"",         ""54.93.140.30"",         ""127.0.0.1""     ],     ""key"": {         ""algo"": ""ecdsa"",         ""size"": 256     },     ""names"": [         {             ""C"": ""US"",             ""L"": ""CA"",             ""ST"": ""San Francisco""         }     ] } Note: It\'s mandatory to include 127.0.0.1 in the hosts section as it acts as a loopback resolver. Now we are ready to generate server certificate and private key: bash cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=server server.json | cfssljson -bare server The following files are generated: server-key.pem server.csr server.pem Generate peer certificate bash', 'cfssl print-defaults csr > member-1.json Substitute CN and hosts values, for example: json {     ""CN"": ""member-1"",     ""hosts"": [       ""member-1"",       ""member-1.local"",       ""10.0.1.10"",       ""10.0.1.11"",       ""10.0.1.12"",       ""127.0.0.1""     ],     ""key"": {         ""algo"": ""ecdsa"",         ""size"": 256     },     ""names"": [         {             ""C"": ""US"",             ""L"": ""CA"",             ""ST"": ""San Francisco""         }     ] } Now we are ready to generate member-1 certificate and private key: bash cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=peer member-1.', '| cfssljson -bare member-1 The following files are generated: member-1-key.pem member-1.csr member-1.pem Repeat the above steps for each etcd member hostname. Generate client certificate bash cfssl print-defaults csr > client.json For client certificate we can ignore hosts values and set only Common Name (CN) to client value: json {     ""CN"": ""client"",     ""hosts"": [""""],     ""key"": {         ""algo"": ""ecdsa"",         ""size"": 256     },     ""names"": [         {             ""C"": ""US"",             ""L"": ""CA"",             ""ST"": ""San Francisco""         }     ] } Generate client certificate: bash cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=client client.json | cfssljson -bare client', 'The following files are generated: client-key.pem client.csr client.pem Download, Install & Configuring the ETCD Cluster Download the etcd binary in each of the boxes and and follow the steps below to configure the cluster: Download the etcd binary Download the binary of the etcd in each server. bash cd ~ wget https://github.com/etcd-io/etcd/releases/download/v3.1.20/etcd-v3.1.20-linux-amd64.tar.gz tar -zxvf etcd-v3.1.20-linux-amd64.tar.gz cd etcd-v3.1.20-linux-amd64/ sudo mv etcd etcdctl /usr/bin/ cd ~ rm -rf etcd-v3.1.20-linux-amd64* Copy the generated certificates. Copy the ca.pem,server.pem, server-key.pem, member-1.pem & member-1-key.', 'into member-1 server. bash mkdir -p /var/lib/etcd/cfssl cp ca.pem server.pem server-key.pem member-1.pem member-1-key.pem /var/lib/etcd/cfssl Similarly, copy the other member certificates to their respective servers. Create a service file for etcd. Create a service file in member-1 machine with the below content: ```bash echo "" [Unit] Description=etcd service Documentation=https://github.com/coreos/etcd [Service] User=root Type=notify ExecStart=/usr/bin/etcd \\  --name member-1 \\  --data-dir /var/lib/etcd \\  --initial-advertise-peer-urls https://10.0.1.10:2380 \\  --listen-peer-urls https://10.0.1.10:2380 \\  --listen-client-urls https://10.0.1.', '10:2379,https://127.0.0.1:2379 \\  --advertise-client-urls https://10.0.1.10:2379 \\  --initial-cluster-token etcd-cluster-1 \\  --initial-cluster member-1=https://10.0.1.10:2380,member-2=https://10.0.1.10:2380,member-3=https://10.0.1.10:2380 \\  --client-cert-auth --trusted-ca-file=/var/lib/etcd/cfssl/ca.pem \\  --cert-file=/var/lib/etcd/cfssl/server.pem --key-file=/var/lib/etcd/cfssl/server-key.pem \\  --peer-client-cert-auth --peer-trusted-ca-file=/var/lib/etcd/cfssl/ca.pem \\  --peer-cert-file=/var/lib/etcd/cfssl/member-1.', '--peer-key-file=/var/lib/etcd/cfssl/member-1-key.pem \\  --initial-cluster-state new Restart=on-failure RestartSec=5 [Install] WantedBy=multi-user.target "" > /lib/systemd/system/etcd.service `` **Note:** Ensure, you update theprivate-ipaddress with your respectiveips` address. Accordingly, reiterate the above step for member-2 and member-3 machines. Starting the cluster. Make sure the port2380 is open between the nodes, and port 2379 to the world. Reload the daemon and start the service. bash systemctl daemon-reload systemctl enable etcd systemctl start etcd.service Testing the Cluster To test the cluster, use the generated ca.pem, client.pem & client-key.pem. Replace the domain name with the specific domain or ""public ip"" and execute the below command. bash curl --cacert ca.', '--cert client.pem --key client-key.pem https://domain-name:2379/health You would get the below output. json {""health"": ""true""} Note: Ship the ca.pem, client.pem & client-key.pem files along with daemon, and follow the daemon configuration to connect between etcd and daemon. Setting up your own ETCD cluster      To set up your own ETCD cluster please follow the link here .     Certificates for ETCD      For snet all ETCD storage , required certificates are available at drive        For SNET Organisation, in order to renew the ETCD Client Certificates  Run the etcd-client-certificates-generation job. This will generate client-certificates in this path.     For other Organisations, follow the below steps to regenerate the etcd client certificates.  Download the cfssl & cfssljson using the below commands curl -s -L -o cfssl https://pkg.cfssl.org/R1.', '2/cfssl_linux-amd64 curl -s -L -o cfssl https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 Copy the ca.pem, ca-key.pem, ca-config.json & client.json that you previously used for generating the etcd certificates. Run the below command to generate the client certificates. ./cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=client.json | .', 'cfssljson -bare client'], ['Page settings layout: default keywords: comments: false  Get the Latest Binary Download the latest Daemon here SSL Configuration The SingularityNet Daemon is designed to be deployed as a sidecar proxy alongside the service on a given host. All communication to the daemon needs to be secured using SSL and can be achieved in the following ways * Set up the daemon behind an nginx server * Use SSL certificates. This guide walks thru the process of obtaining SSL certificates from Let\'s Encrypt Configuration The daemon needs to be configured for it to work with the corresponding AI service. For a detailed list of configurations available , please check here  ```json {  ""daemon_end_point"": ""0.0.0.0:8088"",  ""ipfs_end_point"": ""http://ipfs.singularitynet.io:80"",  ""passthrough_enabled"": true,  ""passthrough_endpoint"": ""http://localhost:3000"",  ""organization_id"": ""yourorganization"",', '""service_id"": ""yourserviceid"",  ""payment_channel_cert_path"": ""/home/adminuser/Downloads/ca.pem"",  ""payment_channel_ca_path"": ""/home/adminuser/Downloads/ca.pem"",  ""payment_channel_key_path"": ""/home/adminuser/Downloads/client-key.pem"",  ""blockchain_network_selected"": ""ropsten"",  ""ethereum_json_rpc_endpoint"": ""https://ropsten.infura.io/v3/"" } You could also build a default configuration for Daemon bysh $ ./build/snetd-linux-amd64 init  ``` Key Configurations   blockchain_network_selected    Should be main for production use. Other supported values are kovan,ropsten or local which are to be used for testing only    json    ""blockchain_network_selected"": ""main"",    ssl_cert and ssl_key    If you are using your own certificates (or from Let\'s Encrypt as described here) add the following two entries to the daemon config    json', '""ssl_cert"": ""/etc/letsencrypt/live/<daemon_domain>/fullchain.pem"",    ""ssl_key"": ""/etc/letsencrypt/live/<daemon_domain>/privkey.pem"",   passthrough_endpoint    This is the AI service end point to which the daemon will proxy all requests.    json    ""passthrough_endpoint"": ""http://localhost:3000"",   daemon_end_point    This is the endpoint on which the daemon listens for requests and should be in the <host>:<port> format. This address should be publically accessible    json    ""daemon_end_point"": ""0.0.0.0:7002"",    organization_id    ID of the organization (as set up on the SingularityNet platform) that this daemon belongs to.    json    ""organization_id"": ""snet"",    service_id', 'ID of the service (as set up on the SingularityNet platform) that this daemon is proxys requests for. The daemon will fetch configuration from the SingularityNet platform based on the organization_id and service_id json    ""service_id"": ""example-service"",    The daemon configuration page has all the available configurations Start Daemon sh ./snetd-linux-amd64 --config <config_file_name>'], ['Overview gRPC is a modern open source high performance RPC framework that can run in any environment. It can efficiently connect services in and across data centers with pluggable support for load balancing, tracing, health checking and authentication. It is also applicable in last mile of distributed computing to connect devices, mobile applications and browsers to backend services. By default, gRPC uses protocol buffers as the Interface Definition Language (IDL) for describing both the service interface and the structure of the payload messages. .gRPC Docs is the recommended starting point to understand how this works gRPC and SingularityNet Platform AI Services on the Singularitynet platform need to define their API using protocol buffers and expose a gRPC endpoint. This allows SingularityNET clients to determine the request/response schema programmatically. The first step in getting the AI service ready for the SingularityNet platform is to have a proto definition and expose a gRPC endpoint for it.', 'Once this is done, the service can be integrated with the SingulartiyNet Daemon. Samples  The example service is an example of a Python arthimetic service with gRPC endpoints and a proto definition. These guides are a good starting point to creating gRPC based services'], ['etcd Overview etcd is a distributed reliable key-value store having the following properties:  Simple: well-defined, user-facing API (gRPC) Secure: automatic TLS with optional client cert authentication Fast: benchmarked 10,000 writes/sec Reliable: properly distributed using Raft  etcd is written in Go and uses the Raft consensus algorithm to manage a highly-available replicated log. etcd and SingularityNet Platform etcd is used as storage to store context related to  * Payments * Free Call Usage at an organization level.', 'The section ETCD setup section details how to set up an etcd cluster'], ['Introduction to SingularityNET Marketplace The The SingularityNET Marketplace  is a decentralized application (DApp), which lists the available AI services and helps you to interact with those services through web interface abstracting all the complexity in invoking a service. It also processes payment for services (through MetaMask/General Wallet)  and conduct service ratings. Whenever transaction happens on Blockchain, an event is created. The marketplace monitors all those events. For example, if you publish a new organization, a new service, the marketplace receives an alert notification about published information in the Blockchain. The marketplace reads the organization metadata, the service metadata and stores this into its database. This application efficiently displays all the details quickly without relying on the slow performance of the Blockchain. The following image shows the contents from the marketplace.  The decentralized application (DApp) does the following: - Reads data from the on-chain Registry and pairs it with off-chain metadata.     This allows for searching, filtering, and discovering AI services.', 'Integrates the SingularityNET curation service, and displays from the registry.     Whenever an event comes from Blockchain, the details are stored in the local database, the review process is done on that data, and then when approved, the information is made available in the marketplace.     Note: Displays those services that have been vetted, and owners who have experienced due diligence and signed legal agreements that protects user and data privacy.   Displays custom UI components for interactions with AI services.     It enables you to quickly build the UI components and host the component on the platform, and also you can determine what inputs need to be chosen for service execution, and is the expected output, without understanding the complexity of knowing the gRPC protocol, the proto that is associated with the service and how to call the service and so on.   Integrates with Multi-Party Escrow, to allow consumers to pay for service usage;     Allows consumers to rate the utilized services.', ""Note: This rating services will be part of the SingularityNET's Reputation System (currently under development). Currently, it is very difficult to rate services on Blockchain. Therefore all rating mechanisms are performed off-chain and managed in the market place. So you can share your opinion and reviews at marketplace.   Captures usage metrics at a consumer level.   Note: Although, the SingularityNET platform is open and decentralized, the Marketplace is the SingularityNET Foundation's curated view. This allows the foundation to adhere to legal requirements of different legislative regions. Currently, the Marketplace and SingularityNET is in beta stage. For more information about the current status, refer to  current status page for changes, or follow the git-repo Marketplace Requirements If you are a service author, for the service to be visible to others and listed on the marketplace you must: 1.  Build and publish your service 2.  Use SSL with the snet-daemon."", ""Note: if you don't already have an SSL certificate for your domain, it is recommended you use certbot and letsencrypt . 3.  Fork the snet-dapp repo, build a react component as the user interface for your service, and submit a pull request.     Note: Identify the services on your networks, organization and service names being used. For more details, refer to dapp repo README.md. 4.  Last is some paperwork that we are still finalising, and we'll update this list when we have that. If you are itching to get your service listed, reach out to us via one of our community groups.     Note: your service can be published to SingularityNET without being listed on the marketplace, but your service may be less discoverable to potential customers if it is not listed.""], ['In this document we demonstrate that the client that communicates with SingularityNET services using the Multi-Party Escrow payment channels does not require to store the state of the payment channel. The client only needs to store its Ethereum identity.    The client can easily obtain the list of its payment channels (payment channels with ""sender==client"") from the Multi-Party Escrow (see EventChannelOpen). However, we need to take into account the situation in which the request to open the channel has been already sent, but not yet mined. This can happen when the client has sent this request and died (it ""lost"" its state). The client can request the last state of the given payment channel from the server. The server is not able to forge this state, because it was signed by the client (of course the client should check its own signature). The server is obviously interested in saving and sending the last state, otherwise it loses money.', ""We have a special gRPC method in the daemon which returns the state of the channel see.  The client receives the following information from the daemon: * current_nonce - current nonce of the payment channel. * current_signed_amount -  a last amount which were signed by client with current_nonce. If no messages were signed with the current_nonce, then this value is an empty byte string (b''), which we should interpret as 0. * current_signature - a last signature sent by the client with current_nonce, it could be absent (empty string) if no message was signed with current nonce. * (not implemented yet) oldnonce_signed_amount - last amount which was signed by client with nonce=current_nonce - 1. * (not implemented yet) oldnonce_signature - last signature sent by client with nonce = current_nonce - 1."", ""It should be noted that the two last values are not in the current version, and we need them only to calculate unspent_amount in the case that current_nonce != |Blockchain_nonce We should consider a complex situation where the server starts a close/reopen procedure for the channel. The client doesn't need to wait for a confirmation from the Blockchain, because it is not in the interest of the server to lie. At the same time, the server also doesn't need to wait for a confirmation from the Blockchain if he makes sure that the request is mined before expiration of the channel. Before considering all possible cases, let's define the following parameters * |Blockchain_nonce - nonce of the channel in the Blockchain * |Blockchain_value - value of the channel in the Blockchain We also assume that the daemon starts the close/reopen procedure only after the previous channelClaim request was mined. This means that the current_nonce, at maximum, is one point ahead of the |Blockchain_nonce."", ""We can easily relax this assumption if necessary.    In all cases we assume that the client can verify that it's own signature is authentic.   In all cases we are interested in two numbers: * Next amount which has to be signed (next_signed_amount), taking into account the price for the current call (price). This value can be easily calculated as we interpret current_signed_amount = b'' as 0.     * next_signed_amount = current_signed_amount + price * The amount of tokens which haven't been already spent (unspent_amount). Simple case current_nonce == |Blockchain_nonce  unspent_amount = |Blockchain_value - current_signed_amount  Complex case current_nonce != |Blockchain_nonce Taking into account our assumptions, we know that current_nonce = |Blockchain_nonce + 1. * unspent_amount = |Blockchain_value - oldnonce_signed_amount - current_signed_amount"", 'It should be noted that in this case the server could send us smaller oldnonce_signed_amount (not the actually last one which was used for channelClaim). In this case, the server can only make us believe that we have more money in the channel then we actually have. That means that one possible attack via unspent_amount is to make us believe that we have less tokens than we truly have, and therefore reject future calls (or force us to call channelAddFunds).'], ['Organization Metadata The organization metadata is the description of a SingularityNET Organization and is, by default, hosted on the SingularityNET IPFS cluster. In order to use a service, the client needs to know the following: - The Organization metadata - The Service metadata There are three ways of providing this metadata to the clients and the daemons: - Simple JSON file - IPFS hash that points to the JSON metadata - Name of service in the Registry The Name of service in the Registry, can be resolved to an IPFS hash, pointing to the metadata, using the Registry’s OrgMetadataURI method. Note: Only the Owner of the Organization can modify the metadata. Important: Client must check that the hash of the metadata corresponds to the IPFS hash. Otherwise, if the IPFS client is compromised, the client system can become vulnerable to attack. Note: By default, the snet-cli adheres to this verification. Description of Fields in metadata file', 'The following is the list of filed types and their description. - type : Describes of this is an Individual or a Company organization. - contacts : Stores the contacts related to an Organization, you can have multiple contacts. - contact_type : Describes the contact type , example support etc. - email_id : Email associated with this contact. - phone : Phone number associated with this contact. - assets : Used to refer to the image associated with an Organization. Image is uploaded on to ipfs and referenced here. - groups : Multiple groups can be associated with an organization, one payment type is associated with every group. - payment_address : Address of the Service provider who would receive the payment. - payment_channel_storage_type : Type of storage to manage payments (for example ETCD). - endpoints : Storage end points for the clients to connect. Metadata example ``` ""org_name"": ""snet"", ""org_id"": ""snet"", ""type"": ""individual"",     ""contacts"": [', '{             ""contact_type"": ""support"",             ""email_id"": ""abcd@abcdef.com"",             ""phone"": ""1234567890""         },         {             ""contact_type"": ""contact-us"",             ""email_id"": ""dummy@abcdef.com"",             ""phone"": ""1234567890""         }     ],     ""description"": {         ""description"": ""Describe your organization details here "",         ""short_description"": ""This is short description of your organization"",         ""url"": ""https://anyurlofyourorganization""     },     ""assets"": {         ""hero_image"": ""QmNW2jjz11enwbRrF1mJ2LdaQPeZVEtmKU8Uq7kpEkmXCc/hero_orgImage.png""     }, ""groups"": [     {     ""group_name"": ""default_group"",', '""group_id"": ""EoFmN3nvaXpf6ew8jJbIPVghE5NXfYupFF7PkRmVyGQ="",     ""payment"": {         ""payment_address"": ""0xd1C9246f6A15A86bae293a3E72F28C57Da6e1dCD"",         ""payment_expiration_threshold"": 100,         ""payment_channel_storage_type"": ""etcd"",         ""payment_channel_storage_client"": {             ""connection_timeout"": ""100s"",             ""request_timeout"": ""5s"",             ""endpoints"": [                 ""https://etcdendpoint:2379""             ]         }       }     }  ] } ``` This metadata file can be directly edited before publishing to IPFS, or manipulated by snet-cli through service subcommands that have the metadata-* prefix.'], ['Page settings layout: default keywords: intro concepts comments: false    Python 3.6+   Create a Virtual env   Node 8+ with npm   SNET CLI  libudev libusb 1.0    SNET Daemon   For example, installing the requirements using Ubuntu 18.04: ```sh sudo apt-get update sudo apt-get install wget git sudo apt-get install python3 python3-pip sudo apt-get install nodejs npm sudo apt-get install libudev-dev libusb-1.0-0-dev sudo pip3 install snet-cli #( installs snet-cli) sudo pip3 install snet-sdk #( this also installs snet-cli) !!! Get the latest snet-daemon from Github releases SNETD_VERSION=curl -s https://api.github.com/repos/singnet/snet-daemon/releases/latest | grep -oP \'""tag_name"": ""\\K(.*)(?="")\'', 'cd /tmp wget https://github.com/singnet/snet-daemon/releases/download/${SNETD_VERSION}/snet-daemon-${SNETD_VERSION}-linux-amd64.tar.gz tar -xvf snet-daemon-${SNETD_VERSION}-linux-amd64.tar.gz sudo mv snet-daemon-${SNETD_VERSION}-linux-amd64/snetd /usr/bin/snetd ```'], ['Creating ethereum identity There are many ways to create an ethereum identity. A few a listed below.  In all cases the private key has to be stored securely as thats the only way to access the corresponding account. Using snet-cli snet-cli is the command line utility to interact with the SIngularityNet platform. The following command can be used to create an identity sh snet identity create test-user key --private-key <PVT-KEY> --network mainnet See the CLI documentation for full details of actions the tool allows. Using Metamask Metamask is a browser extension for interacting with Blockchain enabled websites, such as marketplace.   Step 1. Metamask Metamask is a browser extension for interacting with Blockchain enabled websites, such as marketplace. Install Metamask from their website. Step 2. Create an Identity', 'In the initial startup, Metamask will prompt you to create an identity, which can be used in Blockchain transactions and for storing tokens. To learn more about this, watch the video uploaded on the website or read about how to use the extension on their website. What are the different networks? All real value transactions occur in either ""Main Ethereum Network"" or ""Mainnet Network"". The other available networks are for testing purposes, and the tokens on those networks are essentially value-less and are only useful for testing code and software. Note: SingularityNet began using  Kovan for testing, but this network is likely to be deprecated soon in favour of Ropsten network. Important The major releases will be over the main network. Beginning with the Beta testing in Feb/Mar 2019.  NOTE: Use the SingularityNET Marketplace in Mainnet Mode whenever you want to integrate an AI service into your software.', 'Use the SingularityNET Marketplace in Ropsten Mode whenever you want to test the platform as a developer. Do not integrate AI services from the Ropsten Network in your software, as their continuous availability is not guaranteed.  Ethereum Faucet (Ropsten Test Network Only) Ethereum Ropsten coins are free to claim and can be used to test the platform. Ropsten Ethereum is needed to cover the Gas costs associated with transactions on the platform. Users are required to visit a Ropsten Faucet, which is a per-request Ropsten Ethereum distribution hub. Users provide their Ropsten Ethereum wallet address from MetaMask to the faucet and it issues a set amount of Ropsten Ethereum to the requesting wallet. AGIX Faucet (Ropsten Test Network Only)', 'In order to have Ropsten AGIX to test the platform, users are required to visit the AGIX Faucet, which is a per-request Ropsten AGIX distribution hub. In this case, users provide their Ropsten Ethereum wallet addresses to the Faucet, and a set amount of Ropsten AGIX will be transferred to the requesting wallet. In order to receive these tokens, the user must log in via GitHub to access the AGIX Ropsten Faucet.'], ['Overview SingularityNET (SNET) is an open and decentralized network of AI services made accessible through the Blockchain. Developers publish their services to the SingularityNET network, where they can be used by anyone with an internet connection. Developers are able to charge for the use of their services using the native AGIX token. Services can span the entire gamut of offerings in artificial intelligence and machine learning. Services can provide inference or model training across myriad domains such as image/video, speech, text, time-series, bio-AI, network analysis, etc. The services can be as simple as wrapping a well-known algorithm such as A* path planning, a complete end-to-end solution for an industry problem, or a standalone AI application. Developers can also deploy autonomous AI agents that interoperate with other services on the network. The SingularityNET platform contains a number of critical components that work together to enable a decentralized network of AI services to flourish.', 'The core components are designed to allow for a functional, scalable, and extensible system. We arrived at the current architecture through a careful process, guided by a few key decisions governing Blockchain interactions, AI service integration, and abstraction and by the goal of building an AI marketplace that is both open and compliant with regulatory and legal requirements. First, we made the conscious choice to minimize our dependence on our current Blockchain, Ethereum. Both conceptual and practical issues motivated this decision. Conceptually, we desire to be Blockchain-agnostic and, if necessary, will consider building our own consensus algorithm based on reputation. The speed, reliability, and costs of Ethereum Blockchain interactions dictate that any scalable system built on top of it must minimize gas costs and the delays introduced by block-mining time.', ""These decisions are reflected in our use of tools to abstract away all Blockchain interactions (the daemon, CLI, and SDK) and in our use of a multi-party escrow contract and atomic unidirectional channels for payments. Second, on AI services integration, we wanted to abstract away as much of the network as possible, in order to reduce the learning curve and minimize the overhead associated with providing AI services via the network. This abstraction is achieved with a single flexible tool, the daemon, that will help us provide scalability, robustness, distribution, and management features to the entire community. Finally, to make our marketplace compliant with regulations without compromising on openness, we implemented it separately from our fully decentralized registry of AI services currently available on the Blockchain. Concepts and Components Here we've broken down the SingularityNET platform and network into its core components. The diagram below depicts the key components along with auxiliary components and their roles."", ""You can jump directly to the thing you'd like to know more about, or use the navigation on each page to read through them in turn.  The Request for AI Portal (RFAI): is a DApp through which end users and application developers can request specific AI services they would like added to the network and stake AGIX tokens as a reward for high-quality solutions.""], ['Organization Setup Overview An organization on the SingularityNet platform is a logical entity that groups together various services and the set of identities that can work on these services. The first step to setting up a service on the platform is to create an organization. All metadata that is common across services is stored at an organization level. The key attributes of an organization are * Owner      - This is an ethereum identity that represents the owner of the organization.      - The user with this identity has complete control of the organization and services under the organization.      - The user with this identity has alone can delete the organization from the SingularityNet platform     - The user with this identity can transfer ownership to another user   Members   These are a set of ethereum identities that can create and manage services This enables the organization owner to include additional team members to collaborate on the different services Users with this identity have complete control over all services but not on the organization    Groups', 'Groups provide a mechanism of having multiple instances of a service in a geographically distributed manner All service metadata can be managed at a group level A group very roughly maps to a region in AWS but unlike in AWS is not a pre-determined list. Service owners can define the number of groups that they want    Payment Storage  We use etcd for our payment storage which is defined at a group level Refer to etcd-setup on how to set up an etcd cluster    Payment Address  This is an ethereum identity to which all payments will be processed. This is defined at a group level The user that has this identity alone can withdraw funds from this wallet NOTE: This address does not need to be a member of the organization    Assets  Images for the Organization.  These images will be displayed on the SingularityNet Marketplace DApp    Contacts  Different contact details of the organization    Creating ethereum identity This section has details on creating an ethereum identity.', 'Publishing an organization using snet-cli This section gives a step by step guide on publishing an organization using the snet-cli'], ['Page settings layout: default keywords: intro concepts comments: false  Service The platform\'s primary reason for existence is to allow a diverse collection AI services to be bought and sold via a distributed marketplace. Anyone can publish the availability of their machine learning method, or integrated AI solution, and allow clients to interact with and pay for them directly. These services are primarily meant to be AI or machine learning related, but there is no intrinsic limitation to what type of service can be offered. Indeed, the foundation or the community may end up implementing utility and adaptor services (such as image conversion) to allow services be composed more easily. A ""service"" is defined through it\'s specification and it\'s metadata. Service Specification (Protocol Buffer Definition)  Services define their API using protocol buffers.  This allows SingularityNET clients to determine the request/response schema programmatically.  The first step in setting up a service on the SingularityNet Platform is to define the service definition via protocol buffers.', 'A sample proto file is available here  Service Metadata The service metadata is the off-chain description of a SingularityNET service and is, by default, hosted on the SingularityNET IPFS cluster. To use a service, the client needs to know the following: - The service metadata - The address of Multi-Party Escrow (MPE) contract Fortunately, the latter is included in the metadata.  The daemon which allows access to the service, needs information about the metadata to configure the payment systems. There are three ways of providing metadata details to the clients and the daemons: - Simple JSON file - IPFS hash that points to the JSON metadata - Name of service in the Registry - this can be resolved to an IPFS hash, pointing to the metadata, through the Registry’s getMetadataIPFSHash method.', 'Note: The client using the mpe_address from the metadata should not adhere to this as a primary source of information, for the sake of security. The client should check that this address corresponds to the expected mpe_address .  Important: Client must check that the hash of the metadata corresponds to the IPFS hash. Otherwise, If the IPFS client is compromised, the client system can become vulnerable to attack  Note: By default, the snet-cli adheres to this verification.  Note:  The service provider needs to publish the details about the service in the Blockchain. As a consumer, you may go the Blockchain or the Marketplace portal where the services are deployed. Details like Service the price of the service , image depicting / related to the service , service type, description, the endpoint and how to make a request. Please note that - Singularity platform works on gRPC. Whenever you need to call you need a protofile.', '- File management system such as IPFS stores the location of the hash and points to the associated protofile     The IPFS can include a file and the same file returns same hash.  Metadata Overview ``` {     ""version"": 1,     ""display_name"": ""Entity Disambiguation"",     ""encoding"": ""proto"",     ""service_type"": ""grpc"",     ""model_ipfs_hash"": ""Qmd21xqgX8fkU4fD2bFMNG2Q86wAB4GmGBekQfLoiLtXYv"",     ""mpe_address"": ""0x34E2EeE197EfAAbEcC495FdF3B1781a3b894eB5f"",     ""groups"": [         {             ""group_name"": ""default_group"",             ""free_calls"": 12,', '""free_call_signer_address"": ""0x7DF35C98f41F3Af0df1dc4c7F7D4C19a71Dd059F"",             ""daemon_address "": [""0x1234"", ""0x345""],             ""pricing"": [                 {                     ""price_model"": ""fixed_price"",                     ""price_in_cogs"": 1,                     ""default"": true                 }             ],             ""endpoints"": [                 ""https://tz-services-1.snet.sh:8005""             ],             ""group_id"": ""EoFmN3nvaXpf6ew8jJbIPVghE5NXfYupFF7PkRmVyGQ=""         }     ],     ""assets"": {', '""hero_image"": ""Qmb1n3LxPXLHTUMu7afrpZdpug4WhhcmVVCEwUxjLQafq1/hero_named-entity-disambiguation.png""     },     ""service_description"": {         ""url"": ""https://singnet.github.io/nlp-services-misc/users_guide/named-entity-disambiguation-service.html"",         ""description"": ""Provide further clearity regaridng entities named within a piece of text. For example, \\""Paris is the capital of France\\"", we would want to link \\""Paris\\"" to Paris the city not Paris Hilton in this case."",         ""short_description"": ""text of 180 chars""     },     ""contributors"": [             {                 ""name"": ""dummy dummy"",                 ""email_id"": ""dummy@dummy.io""             }         ] } ```', 'For more information about how to viewing the metadata using the python module, CLI documentation'], [], ['Page settings layout: default keywords: comments: false  IPFS The Inter-Planetary File System (IPFS) is a peer-to-peer network and a network protocol used to store and share data in a distributed file system. IPFS uses content-addressing to uniquely identify each file in a global namespace connecting all computing devices. Organization details and service details are stored in IPFS and the hash associated with them are stored in a Blockchain. Registry The SingularityNET Registry is an ERC-165–compliant smart contract on the Ethereum Blockchain that stores organizations, services, and type repositories. Registry provides all the information needed to find and interact with AI services on the platform, either by listing the information in full, or  when it is too long, by listing the IPFS hash. Smart Contract Contract: Contracts are smart programs or algorithms, executes when certain conditions are met successfully. MultipPartyEscrow Contract', 'An Escrow contract defines the conditional transaction between two transacting parties through an Escrow account. Channel A payment channel is a tool that enables off-chain transactions between parties without the delay imposed by Blockchain block formation and without compromising the transactional security. Daemon Daemon maintains the channel state off chain, so in order to  constrain operations involving gas cost (such as compensation or incentive or commission or any other facility charges levied) and allow transaction  between parties without imposing any delay by the Blockchain block formation times and compromising on transactional security. The SingularityNET daemon is an adapter that a service uses to interface with the SingularityNET platform. In software architecture lingo, the daemon is referred to sidecar proxy, — a process deployed next to a core application (the AI service, in this case) to abstract architectural details, such as logging and configuration, and the platform - interaction with smart contracts or even the decision to use the Ethereum Blockchain. SDK', 'SDK is a tool for AI customers to make calls to service. The SDK simplifies the process of integrating with SingularityNET services and provides tooling to automatically augment gRPC client stubs with the necessary authorizations.  The SDK is available in NodeJS, Python and Java languages. Snet-Cli The SingularityNET command line interface (CLI) is the primary tool for interacting with the platform’s smart contracts, managing deployed services, and managing funds. On-Chain & Off-Chain Transaction On-chain transactions refer to those crypto currency transactions which occur on the Blockchain - that is, on the records of the Blockchain - and remain dependent on the state of the Blockchain for their validity Off-chain transactions refer to those transactions occurring on a cryptocurrency network which move the value outside of the blockchain. Due to their zero/low cost, off-chain transactions are gaining popularity, especially among large participants. Signature Authorization given by the signer. Wallet/Address', 'Wallet is where you hold your crypto currencies , every wallet is associated to an address. Dapp The SingularityNET DApp is essentially a rich Registry explorer. It loads the Registry and generates UI for managing the  Services and Type Repositories registered in it. Metamask MetaMask is an internet browser extension that allows users to interact with the Ethereum Blockchain and its decentralized applications. MetaMask serves as your access portal for both the Ethereum Mainnet and Ropsten. AGIX AGIX is the proprietary cryptocurrency token used by the SingularityNET platform. SingularityNET (AGIX) is an Ethereum based token complying with ERC-20 standards. The AGIX token will be used to settle a transaction over the Blockchain. AGIX Token Tokens can be staked for voting rights and to become an Agent or spent on goods and services on the platform. Cogs It is the unit of measurement transacted between parties. ETCD', ""ETCD is a local database that stores all the events as table, when an event is triggered from Blockchain ETCD is also considered as a Deamon. ETCD was chosen because it is written in Go, and has out of the box embedded server support. This means that its nodes can be started and stopped by snet-daemon replicas. Gas and Gas Cost The Gas Limit is the maximum amount of Gas that a user is willing to pay for performing this action or confirming a transaction (a minimum of 21,000). The price of Gas (Gas Price) is the amount of Gwei that the user is willing to spend on each unit of Gas. Gas Strategy ( Slow , Medium and Fast) Ethereum gas price is a time based gas price strategy ('fast' ~1min, 'medium' ~5min or 'slow' ~60min) (defaults to session.default_gas_price). Infura"", 'Infura is a hosted Ethereum node cluster that lets your users run your application without requiring them to set up their own Ethereum node.'], ['Collaboration Once an organization has been set up its possible to add members to it. This provides an easy way to collaborate with other developers and also distribute responsibilities. Members of an organization can do the following * Create services * Manage regions for a service * Edit / Delete Services Members cannot perform any operation at an organization level.', 'Organization level activities such as publishing any changes to the organization etc can only be done by the owner']]","
The text provides an overview of the SingularityNET platform for decentralized AI services. It describes the key components like organizations, services, registry, channels, SDK, CLI, etc. It explains how services are defined using protocol buffers and metadata. It discusses how the daemon and multi-party escrow enable transactions. It describes concepts like on-chain/off-chain transactions, gas costs, wallets, DApp, and the AGIX token. It outlines how to create an organization, add members, publish services, make payments, etc. Overall, the text gives a high-level technical introduction to SingularityNET for publishers and consumers of AI services
"
5,docs/setup,"[[], ['Python 3.6+ Node 8+ with npm SNET CLI libudev libusb 1.0   SNET Daemon  For example, installing the requirements using Ubuntu 18.04: ```sh sudo apt-get update sudo apt-get install wget git sudo apt-get install python3 python3-pip sudo apt-get install nodejs npm sudo apt-get install libudev-dev libusb-1.0-0-dev sudo pip3 install snet-cli !!! Get the latest snet-daemon from Github releases SNETD_VERSION=curl -s https://api.github.com/repos/singnet/snet-daemon/releases/latest | grep -oP \'""tag_name"": ""\\K(.*)(?="")\' cd /tmp wget https://github.com/singnet/snet-daemon/releases/download/${SNETD_VERSION}/snet-daemon-${SNETD_VERSION}-linux-amd64.tar.gz', 'tar -xvf snet-daemon-${SNETD_VERSION}-linux-amd64.tar.gz sudo mv snet-daemon-${SNETD_VERSION}-linux-amd64/snetd /usr/bin/snetd ``` Setup environment variables (they are explained later in this tutorial as they\'re used): ```sh export ORGANIZATION_ID=""$USER""-org export ORGANIZATION_NAME=""The $USER\'s Organization"" export SERVICE_ID=example-service export SERVICE_NAME=""SNET Example Service"" export SERVICE_IP=127.0.0.1 export SERVICE_PORT=7000 export DAEMON_HOST=$SERVICE_IP export DAEMON_PORT=$SERVICE_PORT export USER_ID=$USER'], ['Step 1. MetaMask Metamask is a browser extension to interact with Blockchain enabled websites like our marketplace. Install Metamask now from their website. Step 2. Create an Identity On first start up, metamask should ask you to create an identity which will be used for Blockchain transactions and storing tokens.  NOTE: The seed phrase is like a pin code to your MetaMask account and helps you recover it in case you lose access to it. Never ever show, or give, this seed phrase to someone, and save it somewhere safe.  For complete instructions on how to use MetaMask, check their instructional video. After you create your wallet, you can transfer funds to it and start using the SingularityNET DApp on Mainnet! You can check our video tutorial to learn how to use the DApp! If you are interested in using the Ropsten network for testing the platform with testnet tokens, please continue reading the above steps. Step 3.', 'What are the different networks? Deploying decentralized applications on the Ethereum main network requires the use of real Ethereum coins. Real Ethereum coins are valuable. Developers want to test their software before launching on the Ethereum main network to minimize catastrophic consequences arising from oversights in coding. Thus, the Ethereum Test Networks allow developers to simulate how their DApps would perform, before launching in a more risky situation. SingularityNET previously used the Kovan and Ropsten network for the Alpha and Beta Test Net version of our platform, but we will now be switching to the Ethereum Mainnet. The Ropsten version of the marketplace will still be accessible for now for testing purposes but may be disabled in the future. The Ropsten network works with PoW (proof-of-work) and is more similar to the environment used in Ethereum’s main network. The Kovan Network will completely be disabled. You can change the Ethereum network on the top of the MetaMask extension.', 'NOTE: Use the SingularityNET Marketplace in Mainnet Mode whenever you want to integrate an AI service into your software. Use the SingularityNET Marketplace in Ropsten Mode whenever you want to test the platform as a developer. Do not integrate AI services from the Ropsten Network in your software, as their continuous availability is not guaranteed.  Step 4. Ethereum Faucet (Ropsten Test Network Only) Ethereum Ropsten coins are free to claim and can be used to test the platform. Ropsten Ethereum is needed to cover the Gas costs associated with transactions on the platform. Users are required to visit a Ropsten Faucet, which is a per-request Ropsten Ethereum distribution hub. Users provide their Ropsten Ethereum wallet address from MetaMask to the faucet and it issues a set amount of Ropsten Ethereum to the requesting wallet. Step 5. AGIX Faucet (Ropsten Test Network Only)', 'In order to have Ropsten AGIX to test the platform, users are required to visit the AGIX Faucet, which is a per-request Ropsten AGIX distribution hub. In this case, users provide their Ropsten Ethereum wallet addresses to the Faucet, and a set amount of Ropsten AGIX will be transferred to the requesting wallet. In order to receive these tokens, the user must log in via GitHub to access the AGIX Ropsten Faucet.'], [""If you want to configure your own environment, here is what you'll need. How to create a wallet Get some AGIX and ETH, and call a service""]]","The given text provides instructions for installing and setting up various requirements for using the SNET CLI and SNET Daemon, as well as configuring environment variables. It also explains how to install and use the MetaMask browser extension for interacting with Blockchain enabled websites. Additionally, it provides information on different Ethereum networks and how to obtain test tokens for testing purposes."
6,docs/ai-consumers,"[[""The SingularityNET command line interface (CLI) is the primary tool for interacting with the platform's smart contracts, managing deployed services, and managing funds. It is aimed at service providers. In the near future, it will be supplemented by a web-based dashboard and control panel. The CLI provides commands to interface with the Blockchain in the following ways: * Creating and managing identities; * Registering and managing the organizations, members, services, types, and tags on the SingularityNET Registry; * Claiming funds from customers using MPE and payment channels; * Reading and writing metadata and Protobuf specs about AI services (these are stored on IPFS, while basic service parameters can be fetched from Blockchain contracts); and * Connecting to different networks like local testnets, Kovan, Ropsten, and the Ethereum mainnet. The CLI also provides service development and deployment support."", 'It can set up new services by generating service metadata, Protobuf specs, and code templates provided by the SingularityNET Foundation. The CLI interacts with daemons for each service. Security-wise, the CLI follows the same guidelines as provided by Ethereum for storing the private keys. When user identities are created and registered with a client, the CLI safely stores the details on the local machine and retrieves them only when it needs to interact with the Blockchain.  The CLI requires and connects to four critical components: * User identity management. Involves user registration, managing identities and sessions, and locking/unlocking accounts for transacting with the Blockchain. This component is local to the machine where the CLI is run. * Sidecar proxy. Communicates to servers hosting AI services. * Registry contract. Deals with organizations, members, services, types, and tags. * MPE contract. Sends and receives funds and manages other functions related to payment channels; e.g., closing a channel or extending its expiry date.', 'This tool is used extensively in our tutorials and guides, to install it, follow the setup guide. See the CLI documentation for full details of actions the tool allows. Making a call to a SingularityNET service Install snet-cli sh pip3 install snet-cli #if not done already Set an identity sh snet identity create user-ropsten mnemonic --mnemonic ""YOUR MNEMONICS"" --network ropsten snet identity user-ropsten Deposit in Escrow and Create a Channel sh snet account balance # check balance (all tokens belongs to this idenity) snet account deposit 0.000001 # Deposit Token to MPE and Open a payment channel to the new service: snet channel open-init <org_id> <group_name> 0.000001 +2days # Now open a Channel and transfer AGIX in to the Channel Make a call to a Service JSON parameters', 'While protocol buffers are used for communication, call parameters are represented as JSON on the command line. There are three ways of passing this JSON: * via a cmdline parameter; * via JSON file; and * via stdin. For example, in this platform example we need to pass the following JSON as a parameter for the ""add"" method to our service: json {""a"": 10, ""b"": 32} We can use three ways: via cmdline parameter sh snet client call <org_id> <service_id> <group_name> add \'{""a"":10,""b"":32}\' via json file sh echo \'{""a"":10,""b"":32}\' > p.txt snet client call <org_id> <service_id> <group_name> add p.txt via stdin echo \'{""a"":10,""b"":32}\' | snet client call <org_id> <service_id> <group_name> add Modifiers', 'We\'ve implemented several modifiers for this JSON parameter in order to simplify passing big files and to have the possibility to pass binary data (and not only base64 encoded data). There are 3 possible modifiers: * file      - read from file; * b64encode - encode to base64; and * b64decode - decode from base64. For example, if you pass the following JSON as a parameter, then as an ""image"" parameter we will use the base64 encoded content of ""1.jpeg"" sh \'{""image_type"": ""jpg"", ""file@b64encode@image"": ""1.jpeg""}\' If we remove the b64encode modifier from the previous example, then we will pass 1.jpeg image in binary format without base64 encoding.'], ['../../tutorials/client/java/index.md'], ['The SingularityNET Registry is an ERC-165–compliant smart contract on the Ethereum Blockchain that stores organizations, services, and type repositories. AI developers use the Registry to announce details of their services, and consumers use the Registry to find the services they need. When a user searches for a service in the Marketplace DApp, it reads details of the services from the Registry, which also allows tagging of services and type repositories to enable searching and filtering. The Registry provides all the information needed to find and interact with AI services on the platform, either by listing the information in full or, when it is too long, by listing the IPFS hash. The source, ABI, and deployment information for the Registry is located in the singnet/platform-contracts repo. Interface The Registry interface, IRegistry, is a full specification of the functionality of the Registry. The Registry is published alongside its interface located in IRegistry.sol.', 'The interface contains natspec-compliant documentation on all functions and developers should import and target the interface instead of the implementation. The registry implements the interface and also fully supports ERC-165. Data Model The Registry stores four main pieces of data: Organizations, Services, Type Repositories, and Tags. It supports CRUD on all of these and contains a number of view functions for retrieving data. Organization An organization is an umbrella for services to be grouped under and is at the top of the Registry’s data hierarchy. Service developers can (and should) register an organization and then put all of their services underneath it. An organization registration record has a name, an owner address (in the identity sense), a collection of member addresses, a collection of services. Its Registry entry contains a name,members, and IPFS hash.', 'the IPFS hash is the link to the metadata file on IPFS , this file has all the necessary information about the recipient address for payment and the storage details to keep track of all off-chain channel state. Services and type repositories registered under a given organization are said to be owned by that organization. The list of members is a primitive access-management structure. Members of an organization cannot change the organization owner or delete the organization or even update the metadata, members can however create , update and delete services under an organization. Organization metadata is described in detail here. Service A service represents a single AI algorithm. Its Registry entry contains all the necessary information for a consumer to call that AI service. The entry contains a name, tags, and IPFS hash. The name is an identifier for discoverability, the tags help a customer find a service without knowing its name, and the IPFS hash is the link to the metadata file on IPFS.', 'DApps and smart contracts can use the listServicesForTag view function to discover Services. Contract Addresses Click here Service Metadata All service metadata is stored off-chain in IPFS for performance and gas-cost reasons. This metadata includes * basic information such as version number, service name, description, etc.; * code-level information for calling the service, such as encoding (protobuf or JSON) and request format (gRPC, JSON-RPC or process); * A list of daemon endpoints, aggregated into one or more groups; * pricing information; and * an IPFS hash for the service API model. * Service metata is described in detail here. Type Repository A type repository is a Registry entry where a service developer lists service metadata, such as the service model and the data types used. The entry contains a name, some tags, a path, and a URI.', 'The name and tags are for discoverability, the path is an optional identifier for the organization’s internal management, and the URI allows the client (whether an end user or an application making calls through the SingularityNET SDK) to find the metadata. DApps and smart contracts can use the listTypeRepositoriesForTag view function to discover AI services. The URI is an IPFS hash, and the hosting itself can be done by either SingularityNET, the service developer, or any IPFS pinning service, such as Infura. Tags Tags are completely optional but recommended for discoverability. Services and Type Repositories can be associated with tags by using the relevant Registry methods such as addTagToServiceRegistration. After that, the tags are displayed and searchable on the DApp. Thanks to a reverse index built into the Registry contract, other smart contracts can also search the Registry directly. This is the foundation for the “API of APIs” functionality discussed below.', 'DApp Integration The SingularityNET DApp is essentially a rich Registry explorer. It loads the Registry and generates UI for playing with the Services and Type Repositories registered in it. CLI Integration The SingularityNET CLI has all the tooling necessary to call any of the Registry methods. Please see theCLI documentation'], ['SDK in JAVA SDK in Python SDK in NodeJS  All SDKs provided adhere to the same design standard and strategy Note:  According  to the design pattern for the  SDK modules such as functionality, need to be available in all programming languages, such as Java, Python and NodeJS.  The SDK can include several default funding strategies for payment channels, but allows and supports the developer to implement funding strategies for payment channel of their own, to control over tokens and service payments. The SDK, in combination with the CLI, simplifies the process of fetching the latest service specification for dependent services, and compiles the proto definitions, so that the services can be invoked with minimal fuss. Java SDK is ready for usage on Java SE and Android platforms. Source code can be found at GitHub repo and artifacts are published at Jitpack repo. Java tutorial is available on SingularityNET dev portal.', ""Preliminary version of Android related notes and code examples are available at GitHub. Currently, a fully functional a preliminary version of a Python SDK is available, which forms the basis for the SDK tutorial, but has  some design improvements. Work is in process towards an SDK for Javascript, and intend to support other popular languages and welcome third party contributions for people's favourite languages. As these SDKs become stable the SDK tutorial will be periodically updated to to include details supporting each programming language.""], ['Page settings layout: default keywords: intro concepts comments: false  Service The platform\'s primary reason for existence is to allow a diverse collection AI services to be bought and sold via a distributed marketplace. Anyone can publish the availability of their machine learning method, or integrated AI solution, and allow clients to interact with and pay for them directly. These services are primarily meant to be AI or machine learning related, but there is no intrinsic limitation to what type of service can be offered. Indeed, the foundation or the community may end up implementing utility and adaptor services (such as image conversion) to allow services be composed more easily. A ""service"" is defined through it\'s specification and it\'s metadata. Service Specification (Protocol Buffer Definition)  Services define their API using protocol buffers.  This allows SingularityNET clients to determine the request/response schema programmatically.  The first step in setting up a service on the SingularityNet Platform is to define the service definition via protocol buffers.', 'A sample proto file is available here  Service Metadata The service metadata is the off-chain description of a SingularityNET service and is, by default, hosted on the SingularityNET IPFS cluster. To use a service, the client needs to know the following: - The service metadata - The address of Multi-Party Escrow (MPE) contract Fortunately, the latter is included in the metadata.  The daemon which allows access to the service, needs information about the metadata to configure the payment systems. There are three ways of providing metadata details to the clients and the daemons: - Simple JSON file - IPFS hash that points to the JSON metadata - Name of service in the Registry - this can be resolved to an IPFS hash, pointing to the metadata, through the Registry’s getMetadataIPFSHash method.', 'Note: The client using the mpe_address from the metadata should not adhere to this as a primary source of information, for the sake of security. The client should check that this address corresponds to the expected mpe_address .  Important: Client must check that the hash of the metadata corresponds to the IPFS hash. Otherwise, If the IPFS client is compromised, the client system can become vulnerable to attack  Note: By default, the snet-cli adheres to this verification.  Note:  The service provider needs to publish the details about the service in the Blockchain. As a consumer, you may go the Blockchain or the Marketplace portal where the services are deployed. Details like Service the price of the service , image depicting / related to the service , service type, description, the endpoint and how to make a request. Please note that - Singularity platform works on gRPC. Whenever you need to call you need a protofile.', '- File management system such as IPFS stores the location of the hash and points to the associated protofile     The IPFS can include a file and the same file returns same hash.  Metadata Overview ``` {     ""version"": 1,     ""display_name"": ""Entity Disambiguation"",     ""encoding"": ""proto"",     ""service_type"": ""grpc"",     ""model_ipfs_hash"": ""Qmd21xqgX8fkU4fD2bFMNG2Q86wAB4GmGBekQfLoiLtXYv"",     ""mpe_address"": ""0x34E2EeE197EfAAbEcC495FdF3B1781a3b894eB5f"",     ""groups"": [         {             ""group_name"": ""default_group"",             ""free_calls"": 12,', '""free_call_signer_address"": ""0x7DF35C98f41F3Af0df1dc4c7F7D4C19a71Dd059F"",             ""daemon_address "": [""0x1234"", ""0x345""],             ""pricing"": [                 {                     ""price_model"": ""fixed_price"",                     ""price_in_cogs"": 1,                     ""default"": true                 }             ],             ""endpoints"": [                 ""https://tz-services-1.snet.sh:8005""             ],             ""group_id"": ""EoFmN3nvaXpf6ew8jJbIPVghE5NXfYupFF7PkRmVyGQ=""         }     ],     ""assets"": {', '""hero_image"": ""Qmb1n3LxPXLHTUMu7afrpZdpug4WhhcmVVCEwUxjLQafq1/hero_named-entity-disambiguation.png""     },     ""service_description"": {         ""url"": ""https://singnet.github.io/nlp-services-misc/users_guide/named-entity-disambiguation-service.html"",         ""description"": ""Provide further clearity regaridng entities named within a piece of text. For example, \\""Paris is the capital of France\\"", we would want to link \\""Paris\\"" to Paris the city not Paris Hilton in this case."",         ""short_description"": ""text of 180 chars""     },     ""contributors"": [             {                 ""name"": ""dummy dummy"",                 ""email_id"": ""dummy@dummy.io""             }         ] } ```', 'For more information about how to viewing the metadata using the python module, CLI documentation'], [""This tool is used extensively in our tutorials and guides, to install it, follow the setup guide. See the CLI documentation for full details of actions the tool allows. Making a call to a SingularityNET service Step 1. Get some Ether Ether is used to pay for interactions on the block chain (known as gas). The transactions you make a call to SingularityNET are: - Transfer AGIX into the multi-party escrow account, - Create a payment channel for a service published in the SingularityNET registry, and - Transfer AGIX into the payment channel and set the timeout After that, you interact with the service directly and won't need to pay for further transactions unless you want to add more AGIX or extend the timeout for the payment channel. So how do you get Ether? The mainnet requires you to buy or mine it, but we're going to use a test net for now. Specifically Ropsten."", 'Luckily for test networks you can go to a faucet to request some Ether for free. To use the faucet you need to create a wallet, and then provide them with your wallet\'s public address. Step 2. Get some AGIX We provide a faucet to get AGIX for either Ropsten or Kovan networks You\'ll need a github account to authenticate, and there after you can request AGIX every 24 hours.  Set an identity sh snet identity create user-ropsten mnemonic --mnemonic ""YOUR MNEMONICS"" --network ropsten snet identity user-ropsten Deposit in Escrow and Create a Channel sh snet account balance # check balance (all tokens belongs to this idenity) snet account deposit 0.000001 # Deposit Token to MPE and Open a payment channel to the new service: snet channel open-init <org_id> <group_name> 0.', '000001 +2days # Now open a Channel and transfer AGIX in to the Channel Make a call to a Service JSON parameters While protocol buffers are used for communication, call parameters are represented as JSON on the command line. There are three ways of passing this JSON: * via a cmdline parameter; * via JSON file; and * via stdin. For example, in this platform example we need to pass the following JSON as a parameter for the ""add"" method to our service: json {""a"": 10, ""b"": 32} We can use three ways: via cmdline parameter sh snet client call <org_id> <service_id> <group_name> add \'{""a"":10,""b"":32}\' via json file sh echo \'{""a"":10,""b"":32}\' > p.txt snet client call <org_id> <service_id> <group_name> add p.txt via stdin', 'echo \'{""a"":10,""b"":32}\' | snet client call <org_id> <service_id> <group_name> add Modifiers We\'ve implemented several modifiers for this JSON parameter in order to simplify passing big files and to have the possibility to pass binary data (and not only base64 encoded data). There are 3 possible modifiers: * file      - read from file; * b64encode - encode to base64; and * b64decode - decode from base64. For example, if you pass the following JSON as a parameter, then as an ""image"" parameter we will use the base64 encoded content of ""1.jpeg"" sh \'{""image_type"": ""jpg"", ""file@b64encode@image"": ""1.jpeg""}\' If we remove the b64encode modifier from the previous example, then we will pass 1.jpeg image in binary format without base64 encoding.   Modifiers', 'We\'ve implemented several modifiers for this JSON parameter in order to simplify passing big files and to have the possibility to pass binary data (and not only base64 encoded data). There are 3 possible modifiers: * file      - read from file; * b64encode - encode to base64; and * b64decode - decode from base64. For example, if you pass the following JSON as a parameter, then as an ""image"" parameter we will use the base64 encoded content of ""1.jpeg"" sh \'{""image_type"": ""jpg"", ""file@b64encode@image"": ""1.jpeg""}\' If we remove the b64encode modifier from the previous example, then we will pass 1.jpeg image in binary format without base64 encoding.'], [""This tool is used extensively in our tutorials and guides, to install it, follow the setup guide.. See the CLI documentation for full details of actions the tool allows. Making a call to a SingularityNET service Step 1. Get some Ether Ether is used to pay for interactions on the block chain (known as gas). The transactions you make a call to SingularityNET are: - Transfer AGIX into the multi-party escrow account, - Create a payment channel for a service published in the SingularityNET registry, and - Transfer AGIX into the payment channel and set the timeout After that, you interact with the service directly and won't need to pay for further transactions unless you want add more AGIX or extend the timeout for the payment channel. So how do you get Ether? The mainnet requires you to buy or mine it, but we're going to use a test net for now. Specifically Ropsten."", 'Luckily for test networks you can go to a faucet to request some Ether for free. To use the faucet you need to create a wallet, and then provide them with your wallet\'s public address. Step 2. Get some AGIX We provide a faucet to get AGIX for either Ropsten or Kovan networks You\'ll need a github account to authenticate, and there after you can request AGIX every 24 hours.  Install snet-cli sh pip3 install snet-cli Set an identity sh snet identity create user-ropsten mnemonic --mnemonic ""YOUR MNEMONICS"" --network ropsten snet identity user-ropsten Deposit in Escrow and Create a Channel sh snet account balance # check balance (all tokens belongs to this idenity) snet account deposit 0.000001 # Deposit Token to MPE and Open a payment channel to the new service:', 'snet channel open-init <org_id> <group_name> 0.000001 +2days # Now open a Channel and transfer AGIX in to the Channel JSON parameters While protocol buffers are used for communication, call parameters are represented as JSON on the command line. There are three ways of passing this JSON: * via a cmdline parameter; * via JSON file; and * via stdin. For example, in this platform example we need to pass the following JSON as a parameter for the ""add"" method to our service, proto definition can be found here : json {""a"": 10, ""b"": 32} We can use three ways: For more details refer to the section  via cmdline parameter sh snet client call <org_id> <service_id> <group_name> add \'{""a"":10,""b"":32}\' via json file sh echo \'{""a"":10,""b"":32}\' > p.txt', 'snet client call <org_id> <service_id> <group_name> add p.txt via stdin ``` echo \'{""a"":10,""b"":32}\' | snet client call    add Modifiers We\'ve implemented several modifiers for this JSON parameter in order to simplify passing big files and to have the possibility to pass binary data (and not only base64 encoded data). There are 3 possible modifiers: * file      - read from file; * b64encode - encode to base64; and * b64decode - decode from base64. For example, if you pass the following JSON as a parameter, then as an ""image"" parameter we will use the base64 encoded content of ""1.jpeg"" sh \'{""image_type"": ""jpg"", ""file@b64encode@image"": ""1.jpeg""}\' If we remove the b64encode modifier from the previous example, then we will pass 1.', 'image in binary format without base64 encoding.'], ['Troubleshooting Common errors returned by the Daemon Free call limit has been exceeded. You have exceeded the number of permitted free calls. So, calls can now be done only using the paid mode alone  Rate limiting, too many requests to handle” The number of request has increased along with the rate limiting, either retry again later or configure your daemon for rate limiting  Unexpected payment type The supported payment types are free-call / escrow If the service is not available on Dapp If you see the service published on Blockchain , but not on Dapp , then it is very likely that the service is under curation  If you see a service on Dapp , but is shown as ""Not Available"", then it is very likely that the end point is temporarily down. You can use the contact-support for any questions Lost the private key to your general wallet You will not be able to link this wallet to an other organization , you can however', 'continue to use the funds deposited on existing channel or even Top up ( add more funds to your channel)'], ['Step 1. Metamask Metamask is a browser extension for interacting with B enabled websites, such as marketplace. Install Metamask now from their website. Step 2. Create an Identity In the initial startup, metamask should prompt you to create an identity which can be used in Blockchain transactions and for storing tokens. To learn more about this, watch the video uploaded on the website or  read about how to us the extensions. You can also create an identity using the snet-cli commands for further details click here editorconfig snet identity create [-h] [--mnemonic MNEMONIC] [--private-key PRIVATE_KEY]                      [--keystore-path KEYSTORE_PATH] [--network NETWORK]                      [--wallet-index WALLET_INDEX]                      IDENTITY_NAME IDENTITY_TYPE  Step 3. What are the different networks? All real value transactions occur in either ""Main Ethereum Network"" or ""Mainnet Network"".', 'The other available networks are for testing purposes, and the tokens on those networks are essentially value-less and are only useful for testing code and software. Note: SingularityNet began using  Kovan in order for testing, but this network is likely to be deprecated soon in favour of Ropsten network. Important The major releases will be over the main network. Beginning with the Beta testing in Feb/Mar 2019.  NOTE: Use the SingularityNET Marketplace in Mainnet Mode whenever you want to integrate an AI service into your software. Use the SingularityNET Marketplace in Ropsten Mode whenever you want to test the platform as a developer. Do not integrate AI services from the Ropsten Network in your software, as their continuous availability is not guaranteed.  Step 4. Ethereum Faucet (Ropsten Test Network Only) Ethereum Ropsten coins are free to claim and can be used to test the platform.', 'Ropsten Ethereum is needed to cover the Gas costs associated with transactions on the platform. Users are required to visit a Ropsten Faucet, which is a per-request Ropsten Ethereum distribution hub. Users provide their Ropsten Ethereum wallet address from MetaMask to the faucet and it issues a set amount of Ropsten Ethereum to the requesting wallet. Step 5. AGIX Faucet (Ropsten Test Network Only) In order to have Ropsten AGIX to test the platform, users are required to visit the AGIX Faucet, which is a per-request Ropsten AGIX distribution hub. In this case, users provide their Ropsten Ethereum wallet addresses to the Faucet, and a set amount of Ropsten AGIX will be transferred to the requesting wallet. In order to receive these tokens, the user must log in via GitHub to access the AGIX Ropsten Faucet.'], ['Calling a Service All complexity of invoking a service is abstracted from the users. For example it becomes easy for the user to Input the values that need to be sent and view the computed expected result in the Output field, even without knowing the complexity of the gRPC calls/generating signatures for authorization to call a  service.   Please note that the the Marketplace offers a free trial version, where registered users can access service(s) for a specified number of calls.   Once your freecalls are exhausted , you will need to pay for any new calls to the service. for this you need need a wallet, some ethers in your wallet , some AGIX in your wallet  You can either pay through Metamask or through a General wallet(paypal)  Select a Wallet -   Lets look at each of the wallet options in detail below Using Metamask Important: Metamask is a plugin which is used by the SingularityNET platform.', 'This extension, allows you to perform the following in the context of the marketplace:  Transfer AGIX funds into escrow,  Setup payment channels to enable calls to any of the listed services.  As a first step you will need to Authorize the Dapp to connect to your metamask account - Authorize Metamask -  Depositing tokens from Metamask to the Escrow Wallet. Steps 1.  Let start by depositing some tokens from Metamask to the Singularity Escrow Wallet. So you can pay for service 2.  On the Home page click on Account link 3.  Confirm you have sufficient balance in your Metamask Wallet 4.  In your Account details, check the Total Balance, This is the number AGIX token you have in Metamask wallet 5.  In the Manage your Escrow account section, Enter the amount of money you want to deposit to the Escrow wallet 6.  Click Deposit.', 'A Metamask Window should pop-up. If it Metamask Window does not pop-up, click on the Metamask icon on the top of your browser. 7.  Check the transaction and click confirm. 8.  Wait for the transactions to be mined. 9.  This is two step transactions; you will need to confirm both steps.(Gas fee and Total) 10. Wait for the transactions to be mined again 11. Confirmation message show that the token has been deposited to the Escrow wallet  12. You might need to refresh if your token still appears as authorized. If you dont have money on Escrow account, you will be asked to Deposit into Escrow  Now click on Deposit You need to confirm every Blockchain transaction when using metamask as your mode of payment  Based on the number of calls you wish to invoke ,select the option and the channel will be  funded accordingly', ""Once the funds are in the channel, you are all set to invoke the service ! Using General Wallet Select the 'General Wallet' Option  To call a service  View a list of service from the home page. Filter the list by using the search text box. Look for  image recognition service Click on Demo.      This will take you to the corresponding service details page.  If you are using General Wallet and you have sufficient funds , you will see the continue button    Now you have the access to the invoke section of the service      The interface will change according to the input need for each service. Choose a Method to identify the service -  An Image After setting-up all that you need,  click the Invoke button. If you are using Metamask , then the transaction will need to be signed again using metamask before invoking  Wait for the response You are now eligible to write a review"", 'You can now continue to use the Service till you have sufficient funds before the expiry date of the channel claim back the reserved fund  Go the Account page     If there is any expired channel it displays under the Expired Channel Details section Select the channel you want to claim Click Claim Channel Confirm this transaction on Metamask Wait for it to mined     Displays the message confirming that funds have been successfully claimed.  Once you do this, the payment channel you claimed is unlisted.  Withdraw tokens from Escrow wallet to Metamask  Go to the Account page In theManage your Escrow account section, select  Withdraw Confirm that you have sufficient funds in the Escrow wallet. Enter the money you want to withdraw and click Withdraw Confirm this transaction on the Metamask Wait for it to be mined     A message displays that the withdraw has been successful Refresh the page to see the balance is updated.', ""You will be able to see the token back in to your Metamask wallet.   Marketplace Requirements If you are a service author, need the service to be visible to others and listed on the marketplace you must: 1.  Build and publish your service  2.  Use SSL with the snet-daemon.      Note: if you don't already have an SSL certificate for your domain, it is recommend you use certbot and letsencrypt . 3.  Fork the snet-dapp repo, build a react component as the user interface for your service, and submit a pull request.      Note: Identify the services on your networks, organization and service names being used. For more details, refer to dapp repo README.md. 4.  Last is some paperwork that we are still finalising, and we'll update this list when we have that. If you are itching to get your service listed, reach out to us via one of our community groups."", 'Note that your service can be published to SingularityNET without being listed on the marketplace, but your service may be less discoverable to potential customers if it is not listed.'], ['Introduction to MPE An Escrow contract defines the conditional transaction between two transacting parties through an Escrow account.  The Multi-party Escrow (MPE) smart contract API and the payment channel together enable payments in the SingularityNet platform with a minimal number of on-Blockchain interactions between AI Consumers and AI service providers. The MPE contract comprises two main functions, which includes:  A wallet with a deposit and withdraw function.   A set of the simple (“atomic”) unidirectional payment channels between clients and service providers and support functions for controlling these channels. Note: Any one can deposit and withdraw their AGIX tokens into a Multi-Party Escrow, (which have not been escrowed at the moment).   What is Payment Channel? Whenever the sender and the receiver enter into an contract, a channel is created. A payment channel is a tool that enables off-chain transactions between parties without the delay imposed by Blockchain block formation and without compromising the transactional security.', 'Atomic unidirectional payment channel If you are familiar with the concept of payment channels, ignore this section. The core logical building block of the Multi-Party Escrow is a simple (“Atomic”) unidirectional payment channel. To learn more about the details of how to implement the Escrow contract for unidirectional payment channel, click on this link SimpleEscrow.sol file here.  It is understood that the payment channel is on the Blockchain. So, in order to prevent direct updating on the Blockchain regularly, the payment channel state is maintained in the storage. Daemon maintains the channel state off chain as block operations involve gas cost and are slow between parties without imposing any delay by the Blockchain block formation times and compromising on transactional security.  Let us consider the simple unidirectional payment channel, the main logic is as follows:  The sender creates an Escrow contract with a given expiration date, and funds it with a desired amount of tokens.', 'The sender then needs to send a small amount of tokens to the recipient each time (to the recipient) with signed authorization The recipient must verify whether the signed authorization and the amount required is correct, and that amount specified does not exceed the funds being escrowed. The channel nonce is incremented, whenever a claim happens, Actually, the channel is not closed and the task can still continue off line, but a new nonce need to be used. The sender can perform the following: Can collect all funds remaining after the expiration date.   -or- Extend the expiration date and add funds to the contract at any moment in time.    Note: The receiver can withdraw from the channel (same as claim) only using the authorized amount by the sender.  Whenever a signature is made on a certain format which should be signed by the private key of Kevin, Jack then verifies whether the signature was authentic to Kevin, based on the agreed format.  MPE Use cases Consider the following', '- Kevin  - is our Client  Consumer/Buyer  - Jack - is our Service Provider/Seller If Kevin is buying services from the Kevin, they both need to enter in to a formal agreement with each other.A channel is created. Note: Each channel is unique to a combination of client identity (sender), service identity (recipient),Organization Id and the daemon group identity.   Kevin deposits tokens to the Multi-Party Escrow account and uses this as a wallet for their AGIX tokens.  Kevin creates and opens a Payment Channel. Note: Kevin is the sender of tokens and Jack is the receiver of tokens. Every channel created has a unique ID, which begins from 0.    Kevin funds the channel. Kevin suggests Jack to deposit a bare amount ( cost of the service) and mentions that the amount can never been withdrawn for a predetermined period of time. This period is configurable.', 'Based on how much Jack wants to use a service , Jack deposits the amount in to the channel accordingly, so if the cost is 1 cog, and Jack needs to use it 10 times, he will deposit 10 cogs. Nonce is always zero when you create the channel for the first time.     Note: Unless and until Jack authorises, the Kevin cannot withdraw the money.     Kevin and Jack come in to agreement to perform operation Off chain. The daemon manages the off chain state of the channel.   Kevin needs to authorize using the signature (using his private key to sign) to let Jack withdraw Jack verifies the following Signature is authentic; Amount of AGIX tokens specified is correct (last Authorized Amount from Kevin + Cost of the Service being called) ; Amount does not exceed the value of the channel Channel is not very close to expiring or has expired.   Kevin makes a call; Jack now sends the signed authorization to Kevin to “withdraw”.', 'The effective balance is 1. Jack can now make a claim with the amount authorized.     Note: Nonce increments to 1, when claim is performed.  Diagram showcasing how Kevin and Jack Communicate   State management of the channel  Kevin (Buyer) and Jack (Service provider) enter into a contract for the first time, they create a channel details in the Blockchain is as follows:   |Channel ID       | 1       |The channel ID created is 1 on Chain| |---------------------|-------- |----------------------------------| |Nonce            | 0       |Initially the Nonce is 0| |Full amount      | 100 Cogs|Amount Kevin has put into the channel is 100 Cogs| |Authorized Amount| 0       |The Authorized amount is zero, because no services has been used for the first time.| |Signature        | Nil     |No signature is required to be sent.|', 'Kevin makes a call and authorizes for 1 cog to Kevin, (assuming the cost of the service is 1 cog) ,the status of the channel is now maintained offchain by the storage mechanism used by Daemon :  |Channel ID       | 1       |The channel ID 1 is now updated off chain| |-------------------- |-------- |----------------------------------| |Nonce            | 0       |Initially the Nonce is 0| |Full amount      | 100 Cogs|Amount Kevin has put into the channel is 100 Cogs| |Authorized Amount| 1       |The Authorized amount is zero.| |Signature        | 1       |No signature is required to be sent.|  Kevin makes a call and authorizes for 2 cogs, to Kevin, now the status changes as follows:  |Channel ID       | 1       |The channel ID 1 is now updated off chain| |---------------------|---------|----------------------------------|', '|Nonce            | 0       |Initially the Nonce is 0| |Full amount      | 100 Cogs|Amount Kevin has put into the channel is 100 Cogs| |Authorized Amount| 2 Cogs  |The Authorized amount is two.| |Signature        | 2 Cogs  |Signature is required for two.|  Jack makes a claim using the signature from Jack, this transaction is considered on-chain transaction.  please note the effective balance in Blockchain for this channel is now 98 and its nonce is 1,The same channel state is updated as follows even in the off chain state:  |Channel ID       | 1       |The channel ID created is 1| |---------------------|---------|----------------------------------| |Nonce            | 1       |Initially the Nonce was 0 but now it is 1| |Full amount      | 98 Cogs|Amount signed by Jack was for two cogs.', 'The full amount in the channel is 98.| |Authorized Amount| 0       |The Authorized amount is two.| |Signature        | 0       |No signature is required to be sent| Note: Claims are always on-chain transaction and the Nonce gets incremented when claims are made.  The same process follows for future calls authorizations of cogs. Postponing the Expiration Time of the Channel With the following functions the client can postpone the expiration time of the channel and can add funds to the channel at any time and can also claim all funds from the channel after the expiration time is reached. function channelExtend(uint256 channel_id, uint256 new_expiration); function channelAddFunds(uint256 channel_id, uint256 amount); function channelExtendAndAddFunds(uint256 channel_id, uint256 new_expiration, uint256 amount); function channelClaimTimeout(uint256 channel_id); Claiming your funds back after Expiration', 'The Sender can claim the funds after the expiry date function channelClaimTimeout(uint256 channel_id); How the recipient Claims funds from the Channel With the following function, the recipient can claim funds from the channel function channelClaim(uint256 channelId, uint256 amount, uint8 v, bytes32 r, bytes32 s, bool isSendback) It should be noted that v, r, s are parts of the signature. The recipent should present the signature for the following message [MPEContractAdress, channelId, nonce, amount]. It should be noted that [MPEContractAdress, channel_id, nonce] is the full ID of the ""atomic"" channel. The recipient has two possibilities: * (is_sendback==true) - ""close"" the channel and send the remainder back to the sender. * (is_sendback==false) - ""close/reopen"".', ""We transfer the claimed amount to the recipient, but instead of sending the remainder back to the sender we simple change the nonce of the channel. By doing this we close the old atomic channel [MPEContractAdress, channel_id, old_nonce] and open the new one [MPEContractAdress, channel_id, new_nonce]. Remarks  The service provider can use the same Ethereum address for all payment groups or can use a different address. In any case, the daemons very rarely need to send an on-chain transaction. This means that we actually don't need to provide the daemons with direct access to the private key. Instead, a centralized server could sign the transactions from the daemons (in some cases it even can be done in semi-manual manner by the service owner). We call such a server a treasurer server. In the current implementation, the client signs off-chain authorization messages with the signer's private key."", ""This means that the client doesn't necessarily need to sign transactions with his Ethereum identity. Instead, he can use other key pairs. The server does not need to wait for a confirmation from the Blockchain after it sends on-chain requests to close/reopen channels (channelClaim). It can inform the client that the nonce of the channel has changed, and it can start accepting calls from the client with a new nonce. It can be shown that it is secure for both the client and the server if the transaction is accepted by the Blockchain before the expiration date of the channel. Similarly, the client doesn't need to wait for a confirmation from the Blockchain after sending the channelExtendAndAddFunds call. It makes the Multi-Party Escrow functional, even on a very slow Ethereum network.   The nonce in the channel prevents a race between the channelExtendAndAddFunds and channelClaim. If the client sends the channelExtendAndAddFunds request and at the same time the"", 'server sends a channelClaim request, they can continue to work without receiving confirmation from the Blockchain. In this case it also does not matter which request will be accepted first (as channelClaim can only change the nonce, and cannot create a new Payment Channel structure).  Contract Addresses Click here MPE Stateless Client The Client does not have to maintain the state of the last amount it had signed  The client can request the last state of the given payment channel from the server.     * The server is not able to forge this state, because it was signed by the client (of course the client should check its own signature).     * The server is obviously interested in saving and sending the last state, otherwise it loses money. This section describes how the client communicates with the SingularityNET services using the Multi-Party Escrow payment channels without storing state of the payment channel.  The client needs to store the Ethereum identity as follows: 1.', 'The client obtains the list of payment channels (payment channels with ""sender==client"") from the Multi-Party Escrow (see EventChannelOpen).      Considering the situation in which the request to open the channel had been sent, but not yet mined. This can occur when the client request has not received any acknowledgement or the session is disconnected (it ""lost"" its state). 2.  The client requests the last state of the given payment channel from the server  The server can never duplicate the state of the payment channel signed by the client (off course the client should check its own signature). The server saves and sends the last state, otherwise the money lost.  Note: A unique gRPC method is available in the daemon helps return the state of the channel (see: https://github.com/singnet/snet-cli/blob/master/snet_cli/resources/proto/state_service.proto).', ""The client does not necessarily require a special call request to know the last state of the channel from the daemon.  The daemon can return the state of the channel in the response to any non-authorized call. The client receives the following information from the daemon:  current_nonce Current nonce of the payment channel. current_signed_amount   Last amount which were signed by client with current_nonce. If no messages were signed with the current_nonce, then this value is an empty byte string (b''), which we should interpret as 0. **current_signature **   Last signature sent by the client with current_nonce, it could be absent (empty string) if no message was signed with current nonce. oldnonce_signed_amount last amount which was signed by client with nonce=current_nonce - 1. oldnonce_signature last signature sent by client with nonce = current_nonce - 1."", 'Note: The two last values are not available in current version, if implemented, can calculate the unspent_amount in the case that current_nonce != |Blockchain_nonce. Example Assume that the server performs a close/reopen procedure for the channel. The client can proceed without confirmation from the Blockchain, because the server does not need to be dependent, or the client ensures that the request is mined before expiration of the channel. Before considering the above scenario, define the following parameters - |Blockchain_nonce - nonce of the channel in the Blockchain - |Blockchain_value - value of the channel in the Blockchain It is known that the daemon starts the close/reopen procedure only after the previous channelClaim request was mined. This means that the current_nonce, at maximum, is one point ahead of the |Blockchain_nonce. In each case, the client can verify their signature is authentic and considers the following two numbers:', ""Next amount which has to be signed (next_signed_amount), taking into account the price for the current call (price). This value can be easily calculated as we interpret current_signed_amount = b'' as 0. next_signed_amount = current_signed_amount + price   The amount of tokens which haven't been already spent (unspent_amount).  Simple case current_nonce == |Blockchain_nonce - unspent_amount = |Blockchain_value - current_signed_amount Complex casecurrent_nonce != |Blockchain_nonce Taking into account our assumptions, we know that current_nonce = |Blockchain_nonce + 1. - unspent_amount = |Blockchain_value - oldnonce_signed_amount - current_signed_amount"", 'Note: The server can send smaller oldnonce_signed_amount (not the actually last one which was used for channelClaim), But the server trust that the money available is actually more in the channel, which means that a likely attack has occurred through unspent_amount, which lead us  believe that there are less tokens than the actuals, and therefore the future calls need be rejected instantly (or force us to call channelAddFunds).'], ['Introduction to AGIX Tokens The AGIX Token is an ERC-20 token, which is hosted on the Ethereum Blockchain. SingularityNET uses the AGIX Token for any paid calls to a service. To learn more about how to obtain Kovan or Ropsten Testnet AGIX, click on the link here. Testnet AGIX vs Mainnet AGIX If you are unfamiliar with  Ethereum, it might be hard to understand between Testnet and Mainnet tokens.  However, to understand the different network tokens, you can follow principles listed below: * Testnet tokens are used to test software applications with, try out demos, or in our case the Beta. * Mainnet tokens are used for officially deployed software. * Testnet tokens never have a monetary value. * Mainnet tokens could have a monetary value. * Both tokens can be used to add extra utility to the software.', 'We only use Kovan and Ropsten Testnet AGIX and the current beta stage.  To learn more about  Mainnet AGIX Token (to be used in a later stage) refer to this link here with the address 0x8eb24319393716668d768dcec29356ae9cffe285.  NOTE Currently, AGIX token is traded on some exchanges, and also the speculative secondary trading is considered against the ethics of AGIX token and SingularityNET project. Therefore, it is not recommended to exchange trading in any manner.  AGIX Faucet To understand how automated faucet is used in distribution of Kovan and Ropsten Testnet AGIX Tokens, click on the link here. Use GitHub account to login and type in the Ethereum address to receive the AGIX token. Ensure this address belongs Kovan Ethereum Address.  Note: You can request for 10 AGIX token every 24 hours.', 'In order to add the Kovan Testnet AGIX, you may need the following details: * Symbol: AGIX * Decimals: 8 * Kovan Token Address: 0x3b226ff6aad7851d3263e53cb7688d13a07f6e81'], ['SingularityNET’s Decentralized AI Marketplace Integration with PayPal The integration of SingularityNET’s decentralized AI marketplace with PayPal represents a significant step in the direction of wide adoption of the platform. It makes it easier for more AI users to leverage the platform, thus increasing the likelihood that data scientists and developers will feel incentivized to consider SingularityNET a viable alternative pathway to monetize their expertise. This integration represents a large opportunity for SingularityNET and our community. How to use service by paying through PayPal  Go to the Marketplace portal Pay for service through your Paypal account     If you dont have a wallet , the application will create a wallet and a channel for you.     The application will then deposit the equivalent AGIX tokens in to channel. Now you can make a call now - The Dapp components hide all the complexity on making these calls.', 'For more details refer to the page'], ['Why support for Training on platform ? Currently all calls on the market place dapp are Inference call SingularityNET is solving this difficulty for AI systems on the Platform and Marketplace by allowing developers to offer multiple training models of their algorithm. The end-user can pick whether it wants to use the model trained on chest x-rays or the one trained on dental x-rays. The end-user can even provide their own training data to create a unique training model specifically suited to their exact data. This multi-model opportunity will allow developers to offer flexible, trainable, and customizable AI’s through our decentralized Marketplace, to better serve AI consumers - and enable access to high-quality AI services for all. This Platform upgrade is well underway, with functionality added to the Platform daemon already. The next step will be to upgrade the SDK, Marketplace front-end, publisher, and other systems to support multi-model AIs and model training calls. Please note:The Model Is stored at the AI developers end', 'Daemon / platform only controls metadata of the  model Id and who has access to these models and the status of these models  MetaData of Model -  CREATE/UPDATE/DELETE/GETDETAILS AI consumer can call any of the below from marketplace dapp/ platform componetns like SDKs/snet-cli  Please note that calls made for any change on metadata of the model is free. Platform gives you a tools to ONLY to update the metadata associated with the model  metadata of a model  Create model Service Request to create a model, please note as part of MVP1, there will not be any workflows associated with model request approval Here all the complexity of creating a training is abstracted from the users. It become easy for the user to create and edit their trainings.   If the training is available inside the model then the Models tab will appear.   The first step in requesting a custom model is to create a project.', 'The REQUEST A NEW MODEL button will help the users to create the model. The models you create in this project inherit the name of the project. Once the REQUEST A NEW MODEL button is clicked it will open a new window where the user can enter the details.  AI consumers , will pass the below details    list of addresses that can access this model ( applicable if model is not public)    if model is public    Description of the model   In return the AI conusmer will get back a model ID  The available training models are displayed under the training method drop down box.  Training a model Once the model is created , AI consumer can invoke training methods , of course the expectation here is to pass the model Id as part of the request  training methods are identified by special method annotations ,  just like any other method calls training calls  will be chargable , please not how the trainig  input is passed is very specific to the method being trained !!!', 'For example it can be a link to a public folder of images / music / or a plain input of many texts    Please note this is entirely in control of the AI developer and expose services on how to receive data to train models    The onus of Storing the actual Model and training it is the responsibility of the AI developer   AI developer can mark  training methods ( a method is marked as a trainign method through method level options from GRPC) , this way the AI developer has full control on the request message to the trainign methods .   AI consumer will pay for training a methods, AI developer needs to define these methods as part of the service proto !! UpdateModelAccess AI consumer can add/remove addresses associated with a given model , can also make this public from private and viceversa. Existing model Service Important: Metamask is a plugin which is used by the SingularityNET platform. This plugin allows the user to connect with the existing models.', 'Under the existing model, it will provide the details regarding the models created with model name, model Id, model description, status, access and the last update details. Edit model Service The Edit button provide a new scope to change the details in the existing models.  Delete model Service AI consumer had created and can request that the model be deleted. The delete button provide a service to delete the models.  GetModelStatus Pass the model Id and get back the training status of this model  GetAllAccessibleModels An AI consumer can always call back this method to determine the list of models associated to a given address , this can be used while making inference calls , the AI consumer can pick the model of their choice if multiple models are available  Complete process video'], ['Introduction to SingularityNET Marketplace The The SingularityNET Marketplace  is a decentralized application (DApp), which lists the available AI services and helps you to interact with those services through web interface abstracting all the complexity in invoking a service. It also processes payment for services (through MetaMask/General Wallet)  and conduct service ratings. Whenever transaction happens on Blockchain, an event is created. The marketplace monitors all those events.  For example, if you publish a new organization, a new service, the marketplace receives an alert notification about published information in the Blockchain. The marketplace reads the organization metadata, the service metadata and the stores this into its database. This application efficiently displays all the details quickly without relying on the slow performance of the Blockchain The following image shows the contents from the marketplace.    The decentralized application (DApp) does the following: - Reads data from the on-chain Registry and pairs it with off-chain metadata.', 'This allows for searching, filtering, and discovering AI services.   Integrates the SingularityNET curation service, and displays from the registry.     Whenever an event comes from Blockchain, the details are stored in the local database, the review process is done on that data, and then when approved, the information is made available in the marketplace.      Note: Displays those services that have been vetted, and owners who have experienced due diligence and signed legal agreements that protects user and data privacy.   Displays custom UI components for interactions with AI services.     It enables you to quickly build the UI components and host the component on the platform, and also you can determine what inputs need to be chosen for service execution, and is the expected output, without understanding the complexity of knowing the gRPC protocol, the proto that is associated with the service and how to call the service and so on.   Integrates with Multi-Party Escrow, to allow consumers to pay for service usage;', ""Allows consumers to rate about the utilized services     Note: This rating services will be part of the SingularityNET's Reputation System (currently under development). Currently, it is very difficult to rate services on Blockchain. Therefore all rating mechanism are performed off chain and managed in the market place. So you can share your opinion and reviews at marketplace.   Captures usage metrics at a consumer level.   Note: Although, the SingularityNET platform is open and decentralized, the Marketplace is the SingularityNET Foundation's curated view. This allows the foundation to adhere to legal requirements of different legislative regions. Currently, the Marketplace and SingularityNET is in beta stage."", 'For more information about the current status, refer to  current status page for changes, or follow the git-repo'], ['Organization Metadata The organization metadata is the description of a SingularityNET Organization and is, by default, hosted on the SingularityNET IPFS cluster. In order to use a service, the client needs to know the following: - The Organization metadata - The Service metadata There are three ways of providing this metadata to the clients and the daemons: - Simple JSON file - IPFS hash that points to the JSON metadata - Name of service in the Registry      The Name of service in the Registry, can be resolved to an IPFS hash, pointing to the metadata, using the Registry’s OrgMetadataURI method.      Note: Only the Owner of the Organization can modify the metadata. Important: Client must check that the hash of the metadata corresponds to the IPFS hash. Otherwise, If the IPFS client is compromised, the client system can become vulnerable to attack Note: By default, the snet-cli adheres to this verification.', 'Description of Fields in metadata file The following is the list of filed types and their description. type : Describes of this is an Individual or a Company organization contacts : Stores the contacts related to an Organization , you can have multiple contacts contact_type : Describes the contact type , example support etc; email_id : Email associated with this contact phone : Phone number associated with this contact assets : used to refer to the image associated with an Organization. Image is uploaded on to ipfs and referenced here. groups : Multiple groups can be associated with an organization, one payment type is associated with every group. payment_address : Address of the Service provider who would receive the payment payment_channel_storage_type : Type of storage to manage payments ( For Example ETCD ) endpoints : Storage end points for the clients to connect. Metadata example ``` ""org_name"": ""snet"", ""org_id"": ""snet"",  ""type"": ""individual"",     ""contacts"": [         {', '""contact_type"": ""support"",             ""email_id"": ""abcd@abcdef.com"",             ""phone"": ""1234567890""         },         {             ""contact_type"": ""contact-us"",             ""email_id"": ""dummy@abcdef.com"",             ""phone"": ""1234567890""         }     ],     ""description"": {         ""description"": ""Describe your organization details here "",         ""short_description"": ""This is short description of your organization"",         ""url"": ""https://anyurlofyourorganization""     },     ""assets"": {         ""hero_image"": ""QmNW2jjz11enwbRrF1mJ2LdaQPeZVEtmKU8Uq7kpEkmXCc/hero_orgImage.png""     }, ""groups"": [     {     ""group_name"": ""default_group"",', '""group_id"": ""EoFmN3nvaXpf6ew8jJbIPVghE5NXfYupFF7PkRmVyGQ="",     ""payment"": {         ""payment_address"": ""0xd1C9246f6A15A86bae293a3E72F28C57Da6e1dCD"",         ""payment_expiration_threshold"": 100,         ""payment_channel_storage_type"": ""etcd"",         ""payment_channel_storage_client"": {             ""connection_timeout"": ""100s"",             ""request_timeout"": ""5s"",             ""endpoints"": [                 ""https://etcdendpoint:2379""             ]         }       }     }  ]  } ``` This metadata file can be directly edited before publishing to IPFS, or manipulated by snet-cli through service subcommands that have the metadata-* prefix.'], ['Page settings layout: default keywords: intro concepts comments: false    Python 3.6+   Create a Virtual env   Node 8+ with npm   SNET CLI  libudev libusb 1.0    SNET Daemon   For example, installing the requirements using Ubuntu 18.04: ```sh sudo apt-get update sudo apt-get install wget git sudo apt-get install python3 python3-pip sudo apt-get install nodejs npm sudo apt-get install libudev-dev libusb-1.0-0-dev sudo pip3 install snet-cli #( Install snet-cli) sudo pip3 install snet-sdk #( this also installs snet-cli) !!! Get the latest snet-daemon from Github releases SNETD_VERSION=curl -s https://api.github.com/repos/singnet/snet-daemon/releases/latest | grep -oP \'""tag_name"": ""\\K(.*)(?="")\'', 'cd /tmp wget https://github.com/singnet/snet-daemon/releases/download/${SNETD_VERSION}/snet-daemon-${SNETD_VERSION}-linux-amd64.tar.gz tar -xvf snet-daemon-${SNETD_VERSION}-linux-amd64.tar.gz sudo mv snet-daemon-${SNETD_VERSION}-linux-amd64/snetd /usr/bin/snetd ```'], ['Overview SingularityNET (SNET) is an open and decentralized network of AI services made accessible through the Blockchain. Developers publish their services to the SingularityNET network, and anyone on the network can be use the service using the internet connection.  Developers can charge for the usage of their services using the native AGIX token. Services can span the entire gamut of offerings in artificial intelligence and machine learning. Services can provide inference or model training across myriad domains such as image/video, speech, text, time-series, bio-AI, network analysis, etc. The services can be as simple as wrapping a well-known algorithm such as A* path planning, a complete end-to-end solution for an industry problem, or a standalone AI application. Developers can also deploy autonomous AI agents that interoperate with other services on the network. The SingularityNET platform contains a number of critical components that work together to enable a decentralized network of AI services to flourish.', 'The core components are designed to allow for a functional, scalable, and extensible system.  We arrived at the current architecture through a careful process, guided by a few key decisions governing Blockchain interactions, AI service integration, abstraction and by the goal of building an AI marketplace that is open and compliant with regulatory and legal requirements. Firstly, we made the conscious choice to minimize our dependence on our current Blockchain, Ethereum. Both conceptual and practical issues motivated this decision. Conceptually, we desire to be Blockchain-agnostic and, if necessary, will consider building our own consensus algorithm based on reputation. The speed, reliability, and costs of Ethereum Blockchain interactions dictate that any scalable system built on top of it must minimize gas costs and the delays introduced by block-mining time.', 'These decisions are reflected in our use of tools to abstract away all Blockchain interactions (the daemon, CLI, and SDK) and in our use of a multi-party escrow contract and atomic unidirectional channels for payments. Secondly, on AI services integration, we wanted to abstract away as much of the network as possible, in order to reduce the learning curve and minimize the overhead associated with providing AI services via the network. This abstraction is achieved with a single flexible tool, the daemon, that will help us provide scalability, robustness, distribution, and management features to the entire community. Finally, to make our marketplace compliant with regulations without compromising on openness, we implemented it separately from our fully decentralized registry of AI services currently available on the Blockchain. Concepts and Components The SingularityNET platform and network are shown as core components. The following diagram shows the key components,  associated auxiliary components and corresponding roles.', 'You can quickly jump to a particular page or use the navigation on the page to read through them.  The Request for AI Portal (RFAI): is a DApp through which end users and application developers request specific AI services they want added to the network and reward AGIX tokens as a reward for high-quality solutions.'], [""snetd, the SingularityNET daemon, provides an API to call service methods using multi-party escrow contract payment channels. To call a published service's method, the client sends payment details via gRPC metadata, as described in the section gRPC metadata. The server will return one of the gRPC error codes in response. There are two situations where the client may want to get the payment channel state from the service: an IncorrectNonce in response, or when starting an service interaction for the first time. The payment channel state can be retrieved via the payment channel state API. A sequence diagram of a typical client/service interaction can be found in the Sequence of Calls section. gRPC metadata To pass payment data to the server when making a request, the client fills in the following gRPC metadata fields:"", 'snet-payment-type - payment protocol type; currently ""escrow"" is the only supported value, it means that MultiPartyEscrow (MPE) contract is used for payments; snet-payment-channel-id - id of the payment channel in MPE contract (decimal number string) snet-payment-channel-nonce - nonce of the payment channel (decimal number string) snet-payment-channel-amount - payment amount authorized by the client (decimal number string) snet-payment-channel-signature-bin - client payment signature (65 bytes in base64)  Using decimal numbers Some values are represented as decimal numbers printed to a string. The reason is that by their nature, these values are incremental counters. Representing them as uint256 value in hex string requires sending 64 bytes for a relatively small value. To make the representation more compact and clear, we have decided to keep them as decimal number represented as strings.', 'The client should expect that this number can be as big as uint256, so the best type to represent such values in code is BigInteger. Binary data encoding gRPC supports sending binary data in metadata fields. To use this feature, the metadata key should have a -bin postfix. The caller should pass values for such keys as a byte array casted to string (some implementations may allow passing byte arrays without casting). The gRPC library encodes such values using base64. Click to see what the gRPC documentation says about this for reference. gRPC error codes The SingularityNET daemon uses both standard and custom gRPC error codes to provide client with information when an error occurrs. In the case that the service itself returns an error, it will be passed to the client without transformation. gRPC error codes: - Unauthenticated - payment details are incorrect; - IncorrectNonce (custom code 1000) - payment nonce is incorrect, possible', 'reason is that service provider claimed funds and incremented the channel nonce; - FailedPrecondition - call cannot be done because another call is in progress   or rate restriction is applied; - InvalidArgument - payment details format is incorrect; - Internal - unexpected error, daemon state is incorrect or some subsystem is   unavailable, the service provider needs to resolve the issue; Full list of expected error messages: - Unauthenticated:   - ""payment signature is not valid""   - ""payment is not signed by channel signer""   - ""payment channel is near to be expired, expiration time: %v, current block: %v, expiration threshold: %v""   - ""not enough tokens on payment channel, channel amount: %v, payment amount: %v""   - ""payment channel \\""%v\\"" not found""   - ""income %d does not equal to price %d"" - IncorrectNonce:', '- ""incorrect payment channel nonce, latest: %v, sent: %v"" - FailedPrecondition:   - ""another transaction on channel: %v is in progress"" - InvalidArgument:   - ""missing metadata""   - ""unexpected \\""snet-payment-type\\"", value: \\""%v\\""""   - ""incorrect format \\""%v\\"": \\""%v\\""""   - ""incorrect binary key name \\""%v\\""""   - ""missing \\""%v\\""""   - ""too many values for key \\""%v\\"": %v"" Payment Channel State API The client can get the latest payment channel state from the service using PaymentChannelStateService via gRPC. See state_service.proto for the API description. Sequence of Calls Sequence diagram of calls during client/daemon interaction:'], ['Select any AI service from here. Click ""Install and run"" Click ""Node.js"" Download integration files  Requirements to run the downloaded AI service | Language     | Download               | | ------------ | ---------------------- | | Node JS 12.X | https://nodejs.org/en/ | Step 1. Install dependencies sh npm install Then update .env with your keys Update aiService.js with the following points:  Please validate the import statements of the service and the messages on the top. Update method getServiceClient with correct client from the grpc_pb.js file Initialize the request object and the set the required input values on method exampleService  Example aiService.js configured for example service ```sh import dotenv from ""dotenv""; import SnetSDK, { DefaultPaymentStrategy } from ""snet-sdk""; /*  * 1: Update the import paths for service and message grpc stubs  / import service from ""./grpc_stubs/example_service_grpc_pb"";', 'import messages from ""./grpc_stubs/example_service_pb""; import config from ""./config""; dotenv.config(); const sdk = new SnetSDK(config); const orgId = ""replace_with_actual_org_id""; const serviceId = ""replace_with_actual_service_id""; const groupName = ""default_group""; const paymentStrategy = new DefaultPaymentStrategy(100); let tokenToMakeFreeCall = process.env.FREE_CALL_TOKEN   ? process.env.FREE_CALL_TOKEN.toUpperCase()   : """"; tokenToMakeFreeCall = Boolean(tokenToMakeFreeCall)   ? tokenToMakeFreeCall.startsWith(""0X"")     ? tokenToMakeFreeCall     : 0X${tokenToMakeFreeCall}   : """"; const serviceClientOptions = {   tokenToMakeFreeCall,   tokenExpirationBlock: process.env.TOKEN_EXPIRATION_BLOCK,   email: process.env.EMAIL,   disableBlockchainOperations: false,   concurrency: true, }; const closeConnection = () => {   sdk.', '3.currentProvider.connection &&     sdk.web3.currentProvider.connection.close(); }; export const getServiceClient = async () => {   try {     const serviceClient = await sdk.createServiceClient(       orgId,       serviceId,       /*        * 2: Use Correct Client from the grpc_pb.js file        /       service.CalculatorClient,       groupName,       paymentStrategy,       serviceClientOptions     );     return serviceClient;   } catch (error) {     console.log(""service client create error"", error);   } }; const exampleService = async (serviceClientWithToken) => {   console.log(""service is invoked"");   let serviceClient = serviceClientWithToken;   try {     if (!serviceClient) {       serviceClient = await getServiceClient();     }     /      * 3: Initialize the request object and the set the required input values      */     const request = new messages.Numbers();     request.setA(20);', 'request.setB(10);     /      * Invoke service methods      /     console.log(""created request"");     return new Promise((resolve, reject) => {       /        * 4: Change the method name according to your service        /       serviceClient.service.add(request, (err, result) => {         console.log(""service call error"", err);         if (err) {           return reject(err);         }     resolve(result.getValue());   }); });  } catch (error) {     console.log(""promise error"", error);     throw error;   } }; export default exampleService; ``` Step 2. Invoke AI service sh', 'npm run start'], ['Page settings layout: default keywords: comments: false  The Inter-Planetary File System (IPFS) is a peer-to-peer network and a network protocol used to store and share data in a distributed file system. IPFS uses content-addressing to uniquely identify each file in a global namespace connecting all computing devices. Organization details and service details are stored in IPFS and the hash associated with them are stored in a Blockchain. Registry The SingularityNET Registry is an ERC-165–compliant smart contract on the Ethereum Blockchain that stores organizations, services, and type repositories. Registry provides all the information needed to find and interact with AI services on the platform, either by listing the information in full, or  when it is too long, by listing the IPFS hash. Smart Contract Contract: Contracts are smart programs or algorithms, executes when certain conditions are met successfully. MultipPartyEscrow Contract', 'An Escrow contract defines the conditional transaction between two transacting parties through an Escrow account. Channel A payment channel is a tool that enables off-chain transactions between parties without the delay imposed by Blockchain block formation and without compromising the transactional security. Daemon Daemon maintains the channel state off chain, so in order to  constrain operations involving gas cost (such as compensation or incentive or commission or any other facility charges levied) and allow transaction  between parties without imposing any delay by the Blockchain block formation times and compromising on transactional security. The SingularityNET daemon is an adapter that a service uses to interface with the SingularityNET platform. In software architecture lingo, the daemon is referred to sidecar proxy, — a process deployed next to a core application (the AI service, in this case) to abstract architectural details, such as logging and configuration, and the platform - interaction with smart contracts or even the decision to use the Ethereum Blockchain.  SDK', 'SDK is a tool for AI customers to make calls to service. The SDK simplifies the process of integrating with SingularityNET services and provides tooling to automatically augment gRPC client stubs with the necessary authorizations.  The SDK is available in NodeJS, Python and Java languages. Snet-Cli The SingularityNET command line interface (CLI) is the primary tool for interacting with the platform’s smart contracts, managing deployed services, and managing funds.  On-Chain & Off-Chain Transaction On-chain transactions refer to those crypto currency transactions which occur on the Blockchain - that is, on the records of the Blockchain - and remain dependent on the state of the Blockchain for their validity  Off-chain transactions refer to those transactions occurring on a cryptocurrency network which move the value outside of the blockchain. Due to their zero/low cost, off-chain transactions are gaining popularity, especially among large participants Signature Authorization given by the signer.   Wallet/Address', 'Wallet is where you hold your crypto currencies , every wallet is associated to an address.  Dapp The SingularityNET DApp is essentially a rich Registry explorer. It loads the Registry and generates UI for managing the  Services and Type Repositories registered in it. Metamask MetaMask is an internet browser extension that allows users to interact with the Ethereum Blockchain and its decentralized applications. MetaMask serves as your access portal for both the Ethereum Mainnet and Ropsten. AGIX AGIX is the proprietary cryptocurrency token used by the SingularityNET platform. SingularityNET (AGIX) is an Ethereum based token complying with ERC-20 standards. The AGIX token will be used to settle a transaction over the Blockchain.  AGIX Token Tokens can be staked for voting rights and to become an Agent or spent on goods and services on the platform. Cogs It is the unit of measurement transacted between parties.  ETCD', ""ETCD is a local database that store all the events as table, when an event is triggered from Blockchain ETCD is also considered as a Deamon. ETCD was chosen because it is written in Go, and has out of the box embedded server support. This means that its nodes can be started and stopped by snet-daemon replicas Gas and Gas Cost The Gas Limit is the maximum amount of Gas that a user is willing to pay for performing this action or confirming a transaction (a minimum of 21,000). The price of Gas (Gas Price) is the amount of Gwei that the user is willing to spend on each unit of Gas  Gas Strategy ( Slow , Medium and Fast) Ethereum gas price is a time based gas price strategy ('fast' ~1min, 'medium' ~5min or 'slow' ~60min) (defaults to session.default_gas_price). Infura Infura"", 'Infura is a hosted Ethereum node cluster that lets your users run your application without requiring them to set up their own Ethereum node.']]","The SingularityNET Marketplace is a decentralized application (DApp) that lists available AI services and allows users to interact with those services through a web interface. It abstracts away the complexity of invoking a service and handles payment processing and service ratings. The Marketplace integrates with the SingularityNET daemon, which provides an API for calling service methods using multi-party escrow contract payment channels. The marketplace also integrates with IPFS for storing organization and service metadata. The SingularityNET Registry is an ERC-165-compliant smart contract on the Ethereum Blockchain that stores organizations, services, and type repositories. The SingularityNET CLI is the primary tool for interacting with the platform's smart contracts, managing deployed services, and managing funds. The SDK provides tooling to simplify integration with SingularityNET services and automatically augment gRPC client stubs with necessary authorizations."
7,docs/platform-concepts,"[[""layout: default keywords: agix token comments: false extralink box extralink:     title: All Docs     title_url: '/docs'     external_url: true     description: Find an overview of our full documentation here. Newsletter dev_news: true Micro navigation micro_nav: true  SingularityNET uses the AGIX Token for its marketplace. The AGIX Token is an ERC-20 token hosted on the Ethereum Blockchain. Right now, we are in the beta phase of the SingularityNET Marketplace. That means that you will need to use Kovan or Ropsten Testnet AGIX to work with our tools. You can get Kovan or Ropsten Testnet AGIX by following the instructions here. Testnet AGIX vs Mainnet AGIX For those new to Ethereum, it may be a bit confusing what exactly the difference between Testnet and Mainnet tokens are. In principle, you can distinguish them as follows:"", '* Testnet tokens are used to test software applications with, try out demos, or in our case the Beta. * Mainnet tokens are used for officially deployed software. * Testnet tokens never have a monetary value. * Mainnet tokens could have a monetary value. * Both tokens can be used to add extra utility to the software. Since we are currently in the Beta stage, we only use Kovan and Ropsten Testnet AGIX. You can find our Mainnet AGIX Token (to be used in a later stage) here with the address 0x8eb24319393716668d768dcec29356ae9cffe285.  NOTE While we are aware that the AGIX token is currently being traded on some exchanges, we do not encourage or facilitate this exchange trading in any manner. Speculative secondary trading is against the spirit of the AGIX token and SingularityNET project.', 'We strongly discourage speculative secondary trading and officially ask AGIX token holders to act accordingly.  AGIX Faucet We have an automated faucet for distributing Kovan and Ropsten Testnet AGIX Tokens here. You will need to login using your GitHub account and input the Ethereum address where you want to receive the AGIX token. Make sure this address is a Kovan Ethereum Address. You can request 10 AGIX token every 24 hours. In order to add the Kovan Testnet AGIX you may need the following details: * Symbol: AGIX * Decimals: 8 * Kovan Token Address: 0x3b226ff6aad7851d3263e53cb7688d13a07f6e81 You can request Kovan or Ropsten Testnet Ether here.'], [], ['SingularityNET (SNET) is an open and decentralized network of AI services made accessible through the Blockchain. Developers publish their services to the SingularityNET network, where they can be used by anyone with an internet connection. Developers are able to charge for the use of their services using the native AGIX token. Services can span the entire gamut of offerings in artificial intelligence and machine learning. Services can provide inference or model training across myriad domains such as image/video, speech, text, time-series, bio-AI, network analysis, etc. The services can be as simple as wrapping a well-known algorithm such as A* path planning, a complete end-to-end solution for an industry problem, or a standalone AI application. Developers can also deploy autonomous AI agents that interoperate with other services on the network. The SingularityNET platform contains a number of critical components that work together to enable a decentralized network of AI services to flourish.', 'The core components are designed to allow for a functional, scalable, and extensible system. We arrived at the current architecture through a careful process, guided by a few key decisions governing Blockchain interactions, AI service integration, and abstraction and by the goal of building an AI marketplace that is both open and compliant with regulatory and legal requirements. First, we made the conscious choice to minimize our dependence on our current Blockchain, Ethereum. Both conceptual and practical issues motivated this decision. Conceptually, we desire to be Blockchain-agnostic and, if necessary, will consider building our own consensus algorithm based on reputation. The speed, reliability, and costs of Ethereum Blockchain interactions dictate that any scalable system built on top of it must minimize gas costs and the delays introduced by block-mining time.', ""These decisions are reflected in our use of tools to abstract away all Blockchain interactions (the daemon, CLI, and SDK) and in our use of a multi-party escrow contract and atomic unidirectional channels for payments. Second, on AI services integration, we wanted to abstract away as much of the network as possible, in order to reduce the learning curve and minimize the overhead associated with providing AI services via the network. This abstraction is achieved with a single flexible tool, the daemon, that will help us provide scalability, robustness, distribution, and management features to the entire community. Finally, to make our marketplace compliant with regulations without compromising on openness, we implemented it separately from our fully decentralized registry of AI services currently available on the Blockchain. Concepts and Components Here we've broken down the SingularityNET platform and network into its core components. The diagram below depicts the key components along with auxiliary components and their roles."", ""You can jump directly to the thing you'd like to know more about, or use the navigation on each page to read through them in turn.""], ['There are three pieces of software and tooling to assist service developers and clients integrating with SingularityNET services. snet-cli and the SDK are important for both users of SNET and service authors. The SingularityNET daemon, snetd, is only of concern for people wanting to publish and host SNET services. There are more parts to the ecosystem of software that make the SingularityNET platform work, but these are only needed if you are doing development on the platform itself. Full details are in the development guide.']]","The text provides information about SingularityNET and its use of the AGIX Token for its marketplace. It explains the difference between Testnet and Mainnet tokens and states that currently, only Kovan and Ropsten Testnet AGIX tokens are being used. It also mentions an AGIX Faucet for distributing Testnet AGIX tokens. The text further describes SingularityNET as an open and decentralized network of AI services accessible through the Blockchain. It discusses the services offered, the platform's architecture, and the core components of the SingularityNET platform."
8,docs/development,"[['NOTE: You can find the script files for this example on Github here  DESCRIPTION  install_and_start.sh - install and setup everything and start a local network and IPFS run_service.sh - register and start a simple service (one payment group one endpoint) run_client.sh  - make a call to the service run_treasurer.sh - run treasurer server in order to see list of claimed channels, and claim your channels  Test should be run on a clean environment in the given order. Run tests in docker container Install everything ```sh I. Download example scripts and make sure that scripts are in the current directory. git clone https://github.com/singnet/dev-portal cd dev-portal/docs/all/mpe/front-to-back-examples/scripts/example1 II. Run ubuntu:latest docker container and ""mount"" ./ to /example1 docker run -v pwd:/example1 -it ubuntu:latest III.', 'Now you are inside a docker container. We will install everything. . /example1/for_docker/install_all.sh ``` Create docker image with everything installed (optional) At this point you can ""commit"" your docker container.  Open new terminal on your main system (without closing your docker container!) Using ""docker ps"" your get ""container id"" of your running container. Type ""docker commit  $USER/snet_example1""    After this you will be able to use $USER/snet_example1 instead of ubuntu:latest (without running install_all.sh) ```sh you should be inside example1 directory cd dev-portal/docs/all/mpe/front-to-back-examples/scripts/example1 docker run -v pwd:/example1 -it $USER/snet_example1 ``` Register and run example service ```sh reset environment . /example1/for_docker/reset_environment.sh register your service . /example1/run_service.sh', '``` Run client After running the service, the terminal will not return to you, so you will need to open a second terminal in your container.  You should open new terminal in your main system. You should get ""container id"" of your running container by typing ""docker ps"" You should type ""docker exec -it  bash"".  And your can run your client ```sh . /example1/run_client.sh it should print ""42.0"" ``` Run treasurer sh . /example1/run_treasurer.'], ['NOTE: You can find the script files for this example on Github here  DESCRIPTION The second example of running and using a JSON-RPC service: (https://github.com/singnet/example-service)  install_and_start.sh - (exactly the same as in the first example) install and setup everything and start local network and IPFS run_service.sh - register and start simple service (one payment group one endpoint) run_client.sh  - make a call to the service run_treasurer.sh - (exactly the same as in the first example) run treasurer server in order to see list of claimed channels, and claim your channels  Test should be run on clean environment in the given order.'], ['You can find script for this example and instruction how to run it inside a docker here (example 1). We will demonstrate the following:  from the server side: How to publish your service (in MPE payment system) How to configure your daemon(s)  How to claim the funds from the server side using ""treasurer server""   from the client side:  How to open the payment channel How to make calls using MPE payment system  Preparation Please start by following the tutorial How to Build and Deploy SingularityNET Locally. The following example can also be executed on the kovan test net, but you will need to make sure that your organization name has not already been taken and you should probably also use another account to collect payments from the client side (see the KOVAN warnings below). For our local network we assume we have the following accounts ```sh', ""First Address (snet identity): 0x592E3C0f3B038A0D673F19a18a773F993d4b2610 Second Address (service)     : 0x3b2b3C2e2E7C93db335E69D827F3CC4bC2A2A2cB ``` In order to get exactly these addresses you should run ganache with the following mnemonics: 'gauge enact biology destroy normal tunnel slight slide wide sauce ladder produce'. WARNING: NEVER GIVE YOUR PERSONAL MNEMONICS TO ANYONE! IT IS LIKE A PIN CODE. THESE ACCOUNTS HAVE SPECIFICALLY BEEN CREATED FOR DEMONSTRATION PURPOSES AND ARE THEREFORE THROWAWAY ACCOUNTS."", 'NEVER TRANSFER ANYTHING TO THESE EXAMPLE ACCOUNTS THAT IS OF VALUE TO YOU OR THAT YOU DO NOT WANT TO LOSE! NEVER SHARE YOUR PRIVATE KEY WITH ANYONE! THE PRIVATE KEYS FOUND IN THIS TUTORIAL ARE CONNECTED TO EMPTY ACCOUNTS AND ARE FOR DEMONSTRATION PURPOSES ONLY! Service Provider: Configuring, Registering, and Starting a Service Starting the service (without a daemon) We will use a Basic_Template service that you can find here. ```sh $SINGNET_REPOS is the path from tutorial, but it could be any directory cd $SINGNET_REPOS git clone https://github.com/singnet/example-service.git cd example-service build protobuf . buildproto.sh python3 run_example_service.py --no-daemon ``` It will start the service at port 7003. Register your service in the registry Prepare your metadata in service_metadata.json.', 'We will register the second ganache identity (0x3b2b3C2e2E7C93db335E69D827F3CC4bC2A2A2cB) as a recipient wallet. (KOVAN) On the KOVAN network you might want to choose another wallet. ```sh cd $SINGNET_REPOS cd example-service snet service metadata-init service/service_spec Example1 --encoding proto --service-type grpc --group-name default_group snet service metadata-set-fixed-price default_group 0.1 snet service metadata-add-endpoints default_group localhost:8080 ``` Create an organization with name ""testo"" and organization id ""testo"", and publish the service with service id ""tests"". (KOVAN) On KOVAN you probably will need to choose another name for your organization. ```sh snet organization metadata-init testo testo individual', 'snet organization metadata-add-description --description ""Describe your organization details here "" --short-description  ""This is short description of your organization"" --url ""https://anyurlofyourorganization"" snet organization add-group default_group 0x3b2b3C2e2E7C93db335E69D827F3CC4bC2A2A2cB http://127.0.0.1:2379 snet organization  create testo --org-id testo -y snet service publish testo tests -y ``` Configure and start the daemon Preparation We assume that the executable file for the daemon is placed in $SINGNET_REPOS/snet-daemon/build/snetd-linux-amd64 ```sh You could start the daemon from any directory We will use directory of the service cd $SINGNET_REPOS cd example-service ../../../..', 'net-daemon/build/snetd-linux-amd64 is a path to daemon we make a link for simplicity (service is already running) ln -s ../snet-daemon/build/snetd-linux-amd64 snetd if it is not the first time you run this test, and state of blockchain was reset, you should reset the state of etcd storage as well rm -rf storage-1.etcd ``` Make a configuration file for the daemon Please note , we are using the local etcd set up here  ```sh cd $SINGNET_REPOS cd dnn-model-services/Services/gRPC/Basic_Template/ cat > snetd.config.json << EOF {    ""ETHEREUM_JSON_RPC_ENDPOINT"": ""http://localhost:8545"",    ""PASSTHROUGH_ENABLED"": true,    ""PASSTHROUGH_ENDPOINT"": ""http://localhost:7003"",', '""REGISTRY_ADDRESS_KEY"": ""0x4e74fefa82e83e0964f0d9f53c68e03f7298a8b2"",    ""DAEMON_END_POINT"": ""localhost:8080"",    ""IPFS_END_POINT"": ""http://localhost:5002"",    ""ORGANIZATION_ID"": ""testo"",    ""SERVICE_ID"": ""tests"",    ""log"": {    ""level"": ""debug"",    ""output"": {    ""type"": ""stdout""       }    }    ""payment_channel_storage_server"": {            ""id"": ""storage-1"",            ""host"" : ""127.0.0.1"",            ""client_port"": 2379,            ""peer_port"": 2380,            ""token"": ""unique-token"",            ""cluster"": ""storage-1=http://127.0.0.1:2380"",            ""enabled"": true    }', ""} EOF ``` Run the daemon In order to run the daemon we use the following command: sh ./snetd-linux-amd64 We are now quickly going to look at what will happen next on the client side when someone wants to buy our service. After that section, we will go through some more steps relevant to the server side. Service Buyer: Buying a Service from the Client Side Open the payment channel with service provider (KOVAN) For the KOVAN network you should make sure that you use the right names for organization and services. ```sh create identity in snet-cli (probably you've already done it) snet identity create snet-user rpc --network local snet identity snet-user deposit 100.1 AGIX to MPE wallet snet account deposit 100.1 -y open channel with our service (organization=testo service_name=tests)"", ""channel with channel_id=0 should be created and initialized after this call snet channel open-init testo default_group 42 +20days -y ``` Make a call using stateless logic We are going to make a call using stateless logic see this page for more information. This means that the client does not need to store any information, except for the channel_id of the payment channel which it wants to use. The client can get the list of the payment channels from the blockchain log or from the blockchain itself. However, this operation is quite slow, so the client cannot do this at each call. The most important thing is that we will be able to use this function in the case of a catastrophic recovery. First, let's request from the blockchain the list of all open channels: ```sh take the list of channels from blockchain (from events!) snet channel print-all-filter-sender ```"", 'We should have one channel with the recipient=0x3b2b3C2e2E7C93db335E69D827F3CC4bC2A2A2cB, and we should have 42 AGIX in it. In order to make an actual call, the channel should be initialized (meaning: protobuf should be compiled). Let\'s check the list of initialized channels: sh snet channel print-initialized Now we can make a call. ```sh we make call using stateless logic with the following arguments org_id       = testo service_id   = tests protobuf_method  = add parameters       = \'{""a"":10,""b"":32}\' snet client call testo tests default_group add \'{""a"":10,""b"":32}\' ``` We can make a call using this state, and we can repeat this call until we spend all the tokens in the channel.', 'There are no on-chain transactions here yet. sh snet client call testo tests default_group mul \'{""a"":6,""b"":7}\' snet client call testo tests default_group add \'{""a"":10,""b"":32}\' Service Provider: Claiming the Channel with a Treasurer Server The service provider can use the same Ethereum address for all payment groups or she/he can use a different address. In any case, the daemons don\'t need to send any on-chain transaction. This means that we actually don\'t need to provide the daemons with direct access to the private key. Instead, a centralized server could sign the transactions from the daemons. We call such a server a treasurer server. In the current version trearurer server logic is implemented via snet-cli. ```sh Service has second ganache idendity (--wallet-index 1) Print list of unclaimed channels and total sum of unclaimed funds', 'snet treasurer print-unclaimed --endpoint localhost:8080 --wallet-index 1 balance before claim snet account balance --account 0x3b2b3C2e2E7C93db335E69D827F3CC4bC2A2A2cB claim all channels snet treasurer claim-all --endpoint localhost:8080  --wallet-index 1 -y balance after claim snet account balance --account 0x3b2b3C2e2E7C93db335E69D827F3CC4bC2A2A2cB ``` The following logic when we ran the treasurer server: * The treasurer server asks the etcd to send the latest state of the channel, and increments the nonce of the channel. * Daemon(s) can continue to work with the client without any confirmation from the treasurer or Blockchain.', '* The treasurer sends on-chain transactions to claim funds and increases the nonce of the channel (close/reopen channel).'], ['This tutorial describes the process of launching a fully functional local SingularityNET environment. You can publish services, call them and have full control over a local Blockchain network for development and testing. Install prerequisites This document describes the process of the environment setup in Ubuntu 18.04. Some commands can be different under other linux distributions.  TIP: Here you can find an instruction how to run SingularityNet platform locally inside a docker container, and how to run simple front-to-back example in it.  Go toolset  Go 1.10+ Dep 0.4.1+ Go Protobuf Compiler Golint  Part of the code is written in Go language so you need a set of tools to compile Go code and manage Go dependencies. sudo apt-get install golang go-dep golang-goprotobuf-dev golint NodeJS toolset  NodeJS 8+ NPM', 'Truffle and Ganache are used to develop and test Ethereum contracts so NodeJS development tools are required. sudo apt-get install nodejs npm IPFS IPFS is used to keep RPC models of the services which are published via SingularityNET platform. Follow instructions here to download and install IPFS. Following steps expects that ipfs is installed and can be run from the command line. Python toolset  Python 3.6.5 Pip  Part of the code is written in Python so you need a Python interpreter and Pip as python package manager. sudo apt-get install python3 python3-pip Other  libudev libusb 1.0  sudo apt-get install libudev-dev libusb-1.0-0-dev Deploy local environment Setup Go building environments Go compiler expects that the path to the workspace is exported as GOPATH variable. SINGNET_REPOS is exported to simplify change directory commands below. sh', 'mkdir -p singnet/src/github.com/singnet cd singnet mkdir log export GOPATH=`pwd` export SINGNET_REPOS=${GOPATH}/src/github.com/singnet export PATH=${GOPATH}/bin:${PATH} Deploy local IPFS instance IPFS is used by SingularityNET to keep published services RPC models. For local test environment we will setup a private local IPFS instance. Initialize IPFS data folder: sh export IPFS_PATH=$GOPATH/ipfs ipfs init Remove all default IPFS bootstrap instances from default IPFS configuration (see IPFS private network). sh ipfs bootstrap rm --all Change IPFS API and Gateway ports because they intersect with default example-service and snet-daemon ports. sh ipfs config Addresses.API /ip4/127.0.0.1/tcp/5002 ipfs config Addresses.Gateway /ip4/0.0.0.', '0/tcp/8081 Compile platform contracts Clone platform-contracts repository: sh cd $SINGNET_REPOS git clone https://github.com/singnet/platform-contracts cd platform-contracts Install dependencies and Ganache using NPM: sh npm install npm install ganache-cli Compile contracts using Truffle: sh ./node_modules/.bin/truffle compile Setup snet command line interface Clone snet-cli repository: sh cd $SINGNET_REPOS git clone https://github.com/singnet/snet-cli cd snet-cli Install Blockchain dependencies and snet-cli package in development mode. ```sh you need python 3.6 here, with python 3.5 you will get an error ./scripts/Blockchain install pip3 install -e . ``` Build snet-daemon Clone snet-daemon repository: sh cd $SINGNET_REPOS', ""git clone https://github.com/singnet/snet-daemon cd snet-daemon Build snet-daemon: sh ./scripts/install # install dependencies ./scripts/build linux amd64  # build project Start environment and finalize snet configuration Start local IPFS instance Start IPFS daemon: sh ipfs daemon >$GOPATH/log/ipfs.log 2>&1 & Start local Ethereum network Start a local Ethereum network. Pass mnemonic to produce a deterministic Blockchain environment: accounts, private keys and behavior. sh cd $SINGNET_REPOS/platform-contracts ./node_modules/.bin/ganache-cli --mnemonic 'gauge enact biology destroy normal tunnel slight slide wide sauce ladder produce' >$GOPATH/log/ganache.log 2>&1 & Accounts and private keys printed by Ganache will be used in next steps. Deploy contracts using Truffle. sh ./node_modules/.bin/truffle migrate --network local"", 'npm run package-npm Contract addresses printed after deployment will be used to setup snet. Truffle deploys contracts using the first account of the test network. As SingularityNETToken contract is deployed using this account, this account\'s balance keeps all of SingularityNET tokens issued during deployment. Other contracts deployed are Registry and MultiPartyEscrow. Registry keeps the list of organization and published services, and MultiPartyEscrow is a part of our payment system. Configure snet-cli for local environment ```sh run snet command  for the first time to create default config: snet add local Ethereum network to the snet configuration with the name ""local"". snet network create local http://localhost:8545 Create First identity (snet-user = first ganache identity) snet identity create snet-user rpc --network local switch to snet-user (we will switch automatically to local network) snet identity snet-user', 'switch to local ipfs endpoint snet set  default_ipfs_endpoint http://localhost:5002 Configure contract addresses for local network (for kovan addresess are already configured!) snet set current_singularitynettoken_at 0x6e5f20669177f5bdf3703ec5ea9c4d4fe3aabd14 snet set current_registry_at            0x4e74fefa82e83e0964f0d9f53c68e03f7298a8b2 snet set current_multipartyescrow_at    0x5c7a4290f6f8ff64c69eeffdfafc8644a4ec3a4e'], [""This documentation is intended for developers who want to work on the SingularityNET platform itself. While we'll happily engage with constructive suggestions for improvement, if you're submitting a substantial change of how things work you'd be best off submitting an issue with your proposal to see if it aligns with the direction we're planning to take SingularityNET in.  Deploying a local development instance of SingularityNET Full multiparty escrow example - #1a Full multiparty escrow example - #1b Full multiparty escrow example - #2""]]","The given text provides instructions for installing and setting up various scripts for running and using a JSON-RPC service. It includes steps for installing dependencies, running docker containers, registering and starting services, making calls to the service, and running a treasurer server to claim channels. The text also mentions the use of SingularityNET platform, Ethereum contracts, and IPFS. It provides specific commands and addresses for each step."
